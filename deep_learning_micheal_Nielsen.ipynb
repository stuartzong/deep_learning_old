{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link to Michael Nielsen webpage: http://neuralnetworksanddeeplearning.com/\n",
    "# this needs python2.7, some part not compatible with python3, i have worked to make it work in python3\n",
    "# i ran this on devbox01, which has GeForce GTX TITAN X GUPS\n",
    "# run this in this directory: /projects/trans_scratch/validations/workspace/szong/deep_learning/neural-networks-and-deep-learning/src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add this package path to system path so that python can find them\n",
    "import sys\n",
    "sys.path.append('/projects/trans_scratch/validations/workspace/szong/deep_learning/neural-networks-and-deep-learning/src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist_loader\n",
    "import network\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/da_workspace/software/miniconda/envs/dlpy3/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x7ffb02e8ba58>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'GeForce GTX TITAN X'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU\n",
    "import torch\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.current_device()\n",
    "torch.cuda.device(0)\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(784, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(784, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data is a list of list of tuple of \n",
    "len(training_data)\n",
    "type(training_data)\n",
    "# training_data\n",
    "training_data[0][0].shape\n",
    "training_data[0][1].shape\n",
    "\n",
    "training_data[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input format is list of tuples, every tuple has 784x1 np array (img input), 10x1 np array (labels, 0-9 depending on the array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = network.Network([784, 30, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[784, 30, 10]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.sizes \n",
    "# neural network sizes: 3 layers, input layer 784 neurons, output 10 neurons, and 2nd layer 30 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.weights[0].shape\n",
    "#these are the weights for the 2nd layer 30 neurons, each input neuron has a weight, total of 784 input neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 30)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.weights[1].shape\n",
    "#3rd layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.biases[0].shape\n",
    "# 1 bias for each 2nd layer neurons, 30 in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.biases[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I suspect this is not using gpus at all judging from the speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 9415 / 10000\n",
      "Epoch 1: 9427 / 10000\n",
      "Epoch 2: 9458 / 10000\n",
      "Epoch 3: 9443 / 10000\n",
      "Epoch 4: 9443 / 10000\n",
      "Epoch 5: 9488 / 10000\n",
      "Epoch 6: 9476 / 10000\n",
      "Epoch 7: 9461 / 10000\n",
      "Epoch 8: 9491 / 10000\n",
      "Epoch 9: 9470 / 10000\n",
      "Epoch 10: 9501 / 10000\n",
      "Epoch 11: 9453 / 10000\n",
      "Epoch 12: 9476 / 10000\n",
      "Epoch 13: 9501 / 10000\n",
      "Epoch 14: 9485 / 10000\n",
      "Epoch 15: 9490 / 10000\n",
      "Epoch 16: 9472 / 10000\n",
      "Epoch 17: 9495 / 10000\n",
      "Epoch 18: 9513 / 10000\n",
      "Epoch 19: 9483 / 10000\n",
      "Epoch 20: 9459 / 10000\n",
      "Epoch 21: 9471 / 10000\n",
      "Epoch 22: 9484 / 10000\n",
      "Epoch 23: 9501 / 10000\n",
      "Epoch 24: 9489 / 10000\n",
      "Epoch 25: 9489 / 10000\n",
      "Epoch 26: 9504 / 10000\n",
      "Epoch 27: 9471 / 10000\n",
      "Epoch 28: 9489 / 10000\n",
      "Epoch 29: 9503 / 10000\n",
      "Epoch 0: 9506 / 10000\n",
      "Epoch 1: 9469 / 10000\n",
      "Epoch 2: 9499 / 10000\n"
     ]
    }
   ],
   "source": [
    "%timeit net.SGD(training_data, 30, 10, 3.0, test_data=test_data) # stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it is important to choose the right hyper parameters, for example learning rate eta, layers and neurons in each layer. use mini batches to speed up the process. this is called stochastic gradient descend. epoches is the number of iterations we run the learning over the entire training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "increase the neurons to 100 from 30,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = network.Network([784, 10]) # try only two layer net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 5671 / 10000\n",
      "Epoch 1: 5696 / 10000\n",
      "Epoch 2: 5747 / 10000\n",
      "Epoch 3: 5741 / 10000\n",
      "Epoch 4: 5741 / 10000\n",
      "Epoch 5: 5784 / 10000\n",
      "Epoch 6: 5766 / 10000\n",
      "Epoch 7: 5783 / 10000\n",
      "Epoch 8: 5799 / 10000\n",
      "Epoch 9: 5811 / 10000\n",
      "Epoch 10: 5834 / 10000\n",
      "Epoch 11: 5830 / 10000\n",
      "Epoch 12: 5822 / 10000\n",
      "Epoch 13: 5822 / 10000\n",
      "Epoch 14: 5832 / 10000\n",
      "Epoch 15: 5854 / 10000\n",
      "Epoch 16: 5841 / 10000\n",
      "Epoch 17: 5848 / 10000\n",
      "Epoch 18: 5847 / 10000\n",
      "Epoch 19: 5871 / 10000\n",
      "Epoch 20: 5846 / 10000\n",
      "Epoch 21: 5857 / 10000\n",
      "Epoch 22: 5832 / 10000\n",
      "Epoch 23: 5861 / 10000\n",
      "Epoch 24: 5888 / 10000\n",
      "Epoch 25: 5880 / 10000\n",
      "Epoch 26: 5894 / 10000\n",
      "Epoch 27: 5890 / 10000\n",
      "Epoch 28: 5891 / 10000\n",
      "Epoch 29: 5870 / 10000\n"
     ]
    }
   ],
   "source": [
    "net.SGD(training_data, 30, 10, 3.0, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_baseline():\n",
    "    training_data, validation_data, test_data = mnist_loader.load_data()\n",
    "    # train\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(training_data[0], training_data[1])\n",
    "    # test\n",
    "    predictions = [int(a) for a in clf.predict(test_data[0])]\n",
    "    num_correct = sum(int(a == y) for a, y in zip(predictions, test_data[1]))\n",
    "    print \"Baseline classifier using an SVM.\"\n",
    "    print \"%s of %s values correct.\" % (num_correct, len(test_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gzip open file '../data/mnist.pkl.gz', mode 'rb' at 0x7f0cc29faf60 0x7f0cc2a7bfd0>\n",
      "Baseline classifier using an SVM.\n",
      "9435 of 10000 values correct.\n"
     ]
    }
   ],
   "source": [
    "svm_baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use $w^l_{jk}$ to denote the weight for the connection from the kthkth neuron in the (l−1)th(l−1)th layer to the jthjth neuron in the lthlth laye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use network2: improved accuracy by using cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import network2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gzip open file '../data/mnist.pkl.gz', mode 'rb' at 0x7f0cbbff6b70 0x7f0cbbfea210>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = network2.Network([784, 30, 10], cost=network2.CrossEntropyCost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.large_weight_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on evaluation data: 9105 / 10000\n",
      "\n",
      "Epoch 1 training complete\n",
      "Accuracy on evaluation data: 9261 / 10000\n",
      "\n",
      "Epoch 2 training complete\n",
      "Accuracy on evaluation data: 9321 / 10000\n",
      "\n",
      "Epoch 3 training complete\n",
      "Accuracy on evaluation data: 9327 / 10000\n",
      "\n",
      "Epoch 4 training complete\n",
      "Accuracy on evaluation data: 9377 / 10000\n",
      "\n",
      "Epoch 5 training complete\n",
      "Accuracy on evaluation data: 9383 / 10000\n",
      "\n",
      "Epoch 6 training complete\n",
      "Accuracy on evaluation data: 9390 / 10000\n",
      "\n",
      "Epoch 7 training complete\n",
      "Accuracy on evaluation data: 9434 / 10000\n",
      "\n",
      "Epoch 8 training complete\n",
      "Accuracy on evaluation data: 9406 / 10000\n",
      "\n",
      "Epoch 9 training complete\n",
      "Accuracy on evaluation data: 9457 / 10000\n",
      "\n",
      "Epoch 10 training complete\n",
      "Accuracy on evaluation data: 9423 / 10000\n",
      "\n",
      "Epoch 11 training complete\n",
      "Accuracy on evaluation data: 9461 / 10000\n",
      "\n",
      "Epoch 12 training complete\n",
      "Accuracy on evaluation data: 9475 / 10000\n",
      "\n",
      "Epoch 13 training complete\n",
      "Accuracy on evaluation data: 9463 / 10000\n",
      "\n",
      "Epoch 14 training complete\n",
      "Accuracy on evaluation data: 9450 / 10000\n",
      "\n",
      "Epoch 15 training complete\n",
      "Accuracy on evaluation data: 9471 / 10000\n",
      "\n",
      "Epoch 16 training complete\n",
      "Accuracy on evaluation data: 9448 / 10000\n",
      "\n",
      "Epoch 17 training complete\n",
      "Accuracy on evaluation data: 9460 / 10000\n",
      "\n",
      "Epoch 18 training complete\n",
      "Accuracy on evaluation data: 9473 / 10000\n",
      "\n",
      "Epoch 19 training complete\n",
      "Accuracy on evaluation data: 9448 / 10000\n",
      "\n",
      "Epoch 20 training complete\n",
      "Accuracy on evaluation data: 9468 / 10000\n",
      "\n",
      "Epoch 21 training complete\n",
      "Accuracy on evaluation data: 9484 / 10000\n",
      "\n",
      "Epoch 22 training complete\n",
      "Accuracy on evaluation data: 9469 / 10000\n",
      "\n",
      "Epoch 23 training complete\n",
      "Accuracy on evaluation data: 9486 / 10000\n",
      "\n",
      "Epoch 24 training complete\n",
      "Accuracy on evaluation data: 9463 / 10000\n",
      "\n",
      "Epoch 25 training complete\n",
      "Accuracy on evaluation data: 9480 / 10000\n",
      "\n",
      "Epoch 26 training complete\n",
      "Accuracy on evaluation data: 9465 / 10000\n",
      "\n",
      "Epoch 27 training complete\n",
      "Accuracy on evaluation data: 9486 / 10000\n",
      "\n",
      "Epoch 28 training complete\n",
      "Accuracy on evaluation data: 9503 / 10000\n",
      "\n",
      "Epoch 29 training complete\n",
      "Accuracy on evaluation data: 9493 / 10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [9105,\n",
       "  9261,\n",
       "  9321,\n",
       "  9327,\n",
       "  9377,\n",
       "  9383,\n",
       "  9390,\n",
       "  9434,\n",
       "  9406,\n",
       "  9457,\n",
       "  9423,\n",
       "  9461,\n",
       "  9475,\n",
       "  9463,\n",
       "  9450,\n",
       "  9471,\n",
       "  9448,\n",
       "  9460,\n",
       "  9473,\n",
       "  9448,\n",
       "  9468,\n",
       "  9484,\n",
       "  9469,\n",
       "  9486,\n",
       "  9463,\n",
       "  9480,\n",
       "  9465,\n",
       "  9486,\n",
       "  9503,\n",
       "  9493],\n",
       " [],\n",
       " [])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.SGD(training_data, 30, 10, 0.5, evaluation_data=test_data, monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "demonstate generalization problems. overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Cost on training data: 0.158647893203\n",
      "Accuracy on evaluation data: 9490 / 10000\n",
      "\n",
      "Epoch 1 training complete\n",
      "Cost on training data: 0.111898428845\n",
      "Accuracy on evaluation data: 9505 / 10000\n",
      "\n",
      "Epoch 2 training complete\n",
      "Cost on training data: 0.101550696152\n",
      "Accuracy on evaluation data: 9503 / 10000\n",
      "\n",
      "Epoch 3 training complete\n",
      "Cost on training data: 0.0931279807174\n",
      "Accuracy on evaluation data: 9505 / 10000\n",
      "\n",
      "Epoch 4 training complete\n",
      "Cost on training data: 0.0875255105109\n",
      "Accuracy on evaluation data: 9500 / 10000\n",
      "\n",
      "Epoch 5 training complete\n",
      "Cost on training data: 0.0840352147014\n",
      "Accuracy on evaluation data: 9508 / 10000\n",
      "\n",
      "Epoch 6 training complete\n",
      "Cost on training data: 0.0782014530866\n",
      "Accuracy on evaluation data: 9490 / 10000\n",
      "\n",
      "Epoch 7 training complete\n",
      "Cost on training data: 0.0747591911063\n",
      "Accuracy on evaluation data: 9497 / 10000\n",
      "\n",
      "Epoch 8 training complete\n",
      "Cost on training data: 0.0727841914096\n",
      "Accuracy on evaluation data: 9496 / 10000\n",
      "\n",
      "Epoch 9 training complete\n",
      "Cost on training data: 0.0689878678357\n",
      "Accuracy on evaluation data: 9492 / 10000\n",
      "\n",
      "Epoch 10 training complete\n",
      "Cost on training data: 0.0662129868262\n",
      "Accuracy on evaluation data: 9495 / 10000\n",
      "\n",
      "Epoch 11 training complete\n",
      "Cost on training data: 0.0643688358105\n",
      "Accuracy on evaluation data: 9489 / 10000\n",
      "\n",
      "Epoch 12 training complete\n",
      "Cost on training data: 0.0621623527278\n",
      "Accuracy on evaluation data: 9498 / 10000\n",
      "\n",
      "Epoch 13 training complete\n",
      "Cost on training data: 0.0597811977765\n",
      "Accuracy on evaluation data: 9496 / 10000\n",
      "\n",
      "Epoch 14 training complete\n",
      "Cost on training data: 0.0570343132773\n",
      "Accuracy on evaluation data: 9489 / 10000\n",
      "\n",
      "Epoch 15 training complete\n",
      "Cost on training data: 0.0544023878892\n",
      "Accuracy on evaluation data: 9478 / 10000\n",
      "\n",
      "Epoch 16 training complete\n",
      "Cost on training data: 0.0520277784733\n",
      "Accuracy on evaluation data: 9485 / 10000\n",
      "\n",
      "Epoch 17 training complete\n",
      "Cost on training data: 0.0509067589684\n",
      "Accuracy on evaluation data: 9486 / 10000\n",
      "\n",
      "Epoch 18 training complete\n",
      "Cost on training data: 0.0490403246874\n",
      "Accuracy on evaluation data: 9492 / 10000\n",
      "\n",
      "Epoch 19 training complete\n",
      "Cost on training data: 0.0480059308141\n",
      "Accuracy on evaluation data: 9480 / 10000\n",
      "\n",
      "Epoch 20 training complete\n",
      "Cost on training data: 0.046542356522\n",
      "Accuracy on evaluation data: 9484 / 10000\n",
      "\n",
      "Epoch 21 training complete\n",
      "Cost on training data: 0.0457401759735\n",
      "Accuracy on evaluation data: 9479 / 10000\n",
      "\n",
      "Epoch 22 training complete\n",
      "Cost on training data: 0.0446319384615\n",
      "Accuracy on evaluation data: 9487 / 10000\n",
      "\n",
      "Epoch 23 training complete\n",
      "Cost on training data: 0.0440274157785\n",
      "Accuracy on evaluation data: 9490 / 10000\n",
      "\n",
      "Epoch 24 training complete\n",
      "Cost on training data: 0.043243133804\n",
      "Accuracy on evaluation data: 9493 / 10000\n",
      "\n",
      "Epoch 25 training complete\n",
      "Cost on training data: 0.0423057279054\n",
      "Accuracy on evaluation data: 9494 / 10000\n",
      "\n",
      "Epoch 26 training complete\n",
      "Cost on training data: 0.0414456848543\n",
      "Accuracy on evaluation data: 9488 / 10000\n",
      "\n",
      "Epoch 27 training complete\n",
      "Cost on training data: 0.0406058272181\n",
      "Accuracy on evaluation data: 9488 / 10000\n",
      "\n",
      "Epoch 28 training complete\n",
      "Cost on training data: 0.039889559192\n",
      "Accuracy on evaluation data: 9482 / 10000\n",
      "\n",
      "Epoch 29 training complete\n",
      "Cost on training data: 0.0391090993879\n",
      "Accuracy on evaluation data: 9490 / 10000\n",
      "\n",
      "Epoch 30 training complete\n",
      "Cost on training data: 0.0382972681996\n",
      "Accuracy on evaluation data: 9482 / 10000\n",
      "\n",
      "Epoch 31 training complete\n",
      "Cost on training data: 0.0378149360181\n",
      "Accuracy on evaluation data: 9478 / 10000\n",
      "\n",
      "Epoch 32 training complete\n",
      "Cost on training data: 0.0371018487952\n",
      "Accuracy on evaluation data: 9480 / 10000\n",
      "\n",
      "Epoch 33 training complete\n",
      "Cost on training data: 0.0364543919918\n",
      "Accuracy on evaluation data: 9486 / 10000\n",
      "\n",
      "Epoch 34 training complete\n",
      "Cost on training data: 0.0359190345881\n",
      "Accuracy on evaluation data: 9478 / 10000\n",
      "\n",
      "Epoch 35 training complete\n",
      "Cost on training data: 0.0353662805735\n",
      "Accuracy on evaluation data: 9478 / 10000\n",
      "\n",
      "Epoch 36 training complete\n",
      "Cost on training data: 0.0348440591346\n",
      "Accuracy on evaluation data: 9476 / 10000\n",
      "\n",
      "Epoch 37 training complete\n",
      "Cost on training data: 0.0342604793236\n",
      "Accuracy on evaluation data: 9473 / 10000\n",
      "\n",
      "Epoch 38 training complete\n",
      "Cost on training data: 0.0337778045054\n",
      "Accuracy on evaluation data: 9481 / 10000\n",
      "\n",
      "Epoch 39 training complete\n",
      "Cost on training data: 0.0332334672116\n",
      "Accuracy on evaluation data: 9474 / 10000\n",
      "\n",
      "Epoch 40 training complete\n",
      "Cost on training data: 0.0328119721284\n",
      "Accuracy on evaluation data: 9472 / 10000\n",
      "\n",
      "Epoch 41 training complete\n",
      "Cost on training data: 0.0323263990685\n",
      "Accuracy on evaluation data: 9475 / 10000\n",
      "\n",
      "Epoch 42 training complete\n",
      "Cost on training data: 0.0319580167414\n",
      "Accuracy on evaluation data: 9474 / 10000\n",
      "\n",
      "Epoch 43 training complete\n",
      "Cost on training data: 0.0315370922924\n",
      "Accuracy on evaluation data: 9475 / 10000\n",
      "\n",
      "Epoch 44 training complete\n",
      "Cost on training data: 0.0311005344129\n",
      "Accuracy on evaluation data: 9476 / 10000\n",
      "\n",
      "Epoch 45 training complete\n",
      "Cost on training data: 0.0306948193176\n",
      "Accuracy on evaluation data: 9474 / 10000\n",
      "\n",
      "Epoch 46 training complete\n",
      "Cost on training data: 0.0303166242525\n",
      "Accuracy on evaluation data: 9466 / 10000\n",
      "\n",
      "Epoch 47 training complete\n",
      "Cost on training data: 0.0299077486354\n",
      "Accuracy on evaluation data: 9471 / 10000\n",
      "\n",
      "Epoch 48 training complete\n",
      "Cost on training data: 0.029521195155\n",
      "Accuracy on evaluation data: 9476 / 10000\n",
      "\n",
      "Epoch 49 training complete\n",
      "Cost on training data: 0.0291335005037\n",
      "Accuracy on evaluation data: 9473 / 10000\n",
      "\n",
      "Epoch 50 training complete\n",
      "Cost on training data: 0.0287291854901\n",
      "Accuracy on evaluation data: 9474 / 10000\n",
      "\n",
      "Epoch 51 training complete\n",
      "Cost on training data: 0.028410354322\n",
      "Accuracy on evaluation data: 9470 / 10000\n",
      "\n",
      "Epoch 52 training complete\n",
      "Cost on training data: 0.0280167299242\n",
      "Accuracy on evaluation data: 9469 / 10000\n",
      "\n",
      "Epoch 53 training complete\n",
      "Cost on training data: 0.027714558359\n",
      "Accuracy on evaluation data: 9463 / 10000\n",
      "\n",
      "Epoch 54 training complete\n",
      "Cost on training data: 0.0273464312903\n",
      "Accuracy on evaluation data: 9469 / 10000\n",
      "\n",
      "Epoch 55 training complete\n",
      "Cost on training data: 0.0269667278128\n",
      "Accuracy on evaluation data: 9467 / 10000\n",
      "\n",
      "Epoch 56 training complete\n",
      "Cost on training data: 0.0266903156421\n",
      "Accuracy on evaluation data: 9469 / 10000\n",
      "\n",
      "Epoch 57 training complete\n",
      "Cost on training data: 0.0263579710918\n",
      "Accuracy on evaluation data: 9467 / 10000\n",
      "\n",
      "Epoch 58 training complete\n",
      "Cost on training data: 0.0260671753632\n",
      "Accuracy on evaluation data: 9465 / 10000\n",
      "\n",
      "Epoch 59 training complete\n",
      "Cost on training data: 0.0257163626399\n",
      "Accuracy on evaluation data: 9467 / 10000\n",
      "\n",
      "Epoch 60 training complete\n",
      "Cost on training data: 0.0253791732331\n",
      "Accuracy on evaluation data: 9466 / 10000\n",
      "\n",
      "Epoch 61 training complete\n",
      "Cost on training data: 0.025079322091\n",
      "Accuracy on evaluation data: 9465 / 10000\n",
      "\n",
      "Epoch 62 training complete\n",
      "Cost on training data: 0.0247219102115\n",
      "Accuracy on evaluation data: 9465 / 10000\n",
      "\n",
      "Epoch 63 training complete\n",
      "Cost on training data: 0.0244331127043\n",
      "Accuracy on evaluation data: 9467 / 10000\n",
      "\n",
      "Epoch 64 training complete\n",
      "Cost on training data: 0.0241391426081\n",
      "Accuracy on evaluation data: 9468 / 10000\n",
      "\n",
      "Epoch 65 training complete\n",
      "Cost on training data: 0.0239201426995\n",
      "Accuracy on evaluation data: 9465 / 10000\n",
      "\n",
      "Epoch 66 training complete\n",
      "Cost on training data: 0.0236117381187\n",
      "Accuracy on evaluation data: 9466 / 10000\n",
      "\n",
      "Epoch 67 training complete\n",
      "Cost on training data: 0.0232492762796\n",
      "Accuracy on evaluation data: 9466 / 10000\n",
      "\n",
      "Epoch 68 training complete\n",
      "Cost on training data: 0.0229810622478\n",
      "Accuracy on evaluation data: 9463 / 10000\n",
      "\n",
      "Epoch 69 training complete\n",
      "Cost on training data: 0.0227087093078\n",
      "Accuracy on evaluation data: 9465 / 10000\n",
      "\n",
      "Epoch 70 training complete\n",
      "Cost on training data: 0.0224254025745\n",
      "Accuracy on evaluation data: 9468 / 10000\n",
      "\n",
      "Epoch 71 training complete\n",
      "Cost on training data: 0.0221673757429\n",
      "Accuracy on evaluation data: 9466 / 10000\n",
      "\n",
      "Epoch 72 training complete\n",
      "Cost on training data: 0.0219288513721\n",
      "Accuracy on evaluation data: 9463 / 10000\n",
      "\n",
      "Epoch 73 training complete\n",
      "Cost on training data: 0.0217135424755\n",
      "Accuracy on evaluation data: 9471 / 10000\n",
      "\n",
      "Epoch 74 training complete\n",
      "Cost on training data: 0.0214147947269\n",
      "Accuracy on evaluation data: 9465 / 10000\n",
      "\n",
      "Epoch 75 training complete\n",
      "Cost on training data: 0.0211979897125\n",
      "Accuracy on evaluation data: 9469 / 10000\n",
      "\n",
      "Epoch 76 training complete\n",
      "Cost on training data: 0.0209711540743\n",
      "Accuracy on evaluation data: 9465 / 10000\n",
      "\n",
      "Epoch 77 training complete\n",
      "Cost on training data: 0.0207291507365\n",
      "Accuracy on evaluation data: 9468 / 10000\n",
      "\n",
      "Epoch 78 training complete\n",
      "Cost on training data: 0.0204888352949\n",
      "Accuracy on evaluation data: 9467 / 10000\n",
      "\n",
      "Epoch 79 training complete\n",
      "Cost on training data: 0.0203561565878\n",
      "Accuracy on evaluation data: 9466 / 10000\n",
      "\n",
      "Epoch 80 training complete\n",
      "Cost on training data: 0.020076877251\n",
      "Accuracy on evaluation data: 9467 / 10000\n",
      "\n",
      "Epoch 81 training complete\n",
      "Cost on training data: 0.0198989917619\n",
      "Accuracy on evaluation data: 9467 / 10000\n",
      "\n",
      "Epoch 82 training complete\n",
      "Cost on training data: 0.0196628343671\n",
      "Accuracy on evaluation data: 9466 / 10000\n",
      "\n",
      "Epoch 83 training complete\n",
      "Cost on training data: 0.0194646610355\n",
      "Accuracy on evaluation data: 9468 / 10000\n",
      "\n",
      "Epoch 84 training complete\n",
      "Cost on training data: 0.0192786567957\n",
      "Accuracy on evaluation data: 9465 / 10000\n",
      "\n",
      "Epoch 85 training complete\n",
      "Cost on training data: 0.0190876510808\n",
      "Accuracy on evaluation data: 9463 / 10000\n",
      "\n",
      "Epoch 86 training complete\n",
      "Cost on training data: 0.018952335433\n",
      "Accuracy on evaluation data: 9463 / 10000\n",
      "\n",
      "Epoch 87 training complete\n",
      "Cost on training data: 0.0187074602525\n",
      "Accuracy on evaluation data: 9465 / 10000\n",
      "\n",
      "Epoch 88 training complete\n",
      "Cost on training data: 0.0185854972972\n",
      "Accuracy on evaluation data: 9465 / 10000\n",
      "\n",
      "Epoch 89 training complete\n",
      "Cost on training data: 0.0183738904479\n",
      "Accuracy on evaluation data: 9462 / 10000\n",
      "\n",
      "Epoch 90 training complete\n",
      "Cost on training data: 0.0182365665352\n",
      "Accuracy on evaluation data: 9464 / 10000\n",
      "\n",
      "Epoch 91 training complete\n",
      "Cost on training data: 0.0180361527134\n",
      "Accuracy on evaluation data: 9463 / 10000\n",
      "\n",
      "Epoch 92 training complete\n",
      "Cost on training data: 0.017904157756\n",
      "Accuracy on evaluation data: 9462 / 10000\n",
      "\n",
      "Epoch 93 training complete\n",
      "Cost on training data: 0.017725699783\n",
      "Accuracy on evaluation data: 9460 / 10000\n",
      "\n",
      "Epoch 94 training complete\n",
      "Cost on training data: 0.0175695641341\n",
      "Accuracy on evaluation data: 9460 / 10000\n",
      "\n",
      "Epoch 95 training complete\n",
      "Cost on training data: 0.0174201683886\n",
      "Accuracy on evaluation data: 9461 / 10000\n",
      "\n",
      "Epoch 96 training complete\n",
      "Cost on training data: 0.0172816703175\n",
      "Accuracy on evaluation data: 9460 / 10000\n",
      "\n",
      "Epoch 97 training complete\n",
      "Cost on training data: 0.0171321687334\n",
      "Accuracy on evaluation data: 9462 / 10000\n",
      "\n",
      "Epoch 98 training complete\n",
      "Cost on training data: 0.0169842550452\n",
      "Accuracy on evaluation data: 9463 / 10000\n",
      "\n",
      "Epoch 99 training complete\n",
      "Cost on training data: 0.0168477405097\n",
      "Accuracy on evaluation data: 9461 / 10000\n",
      "\n",
      "Epoch 100 training complete\n",
      "Cost on training data: 0.0167147970346\n",
      "Accuracy on evaluation data: 9463 / 10000\n",
      "\n",
      "Epoch 101 training complete\n",
      "Cost on training data: 0.0165943559558\n",
      "Accuracy on evaluation data: 9460 / 10000\n",
      "\n",
      "Epoch 102 training complete\n",
      "Cost on training data: 0.0164426823984\n",
      "Accuracy on evaluation data: 9463 / 10000\n",
      "\n",
      "Epoch 103 training complete\n",
      "Cost on training data: 0.0163153214482\n",
      "Accuracy on evaluation data: 9459 / 10000\n",
      "\n",
      "Epoch 104 training complete\n",
      "Cost on training data: 0.0161921762421\n",
      "Accuracy on evaluation data: 9459 / 10000\n",
      "\n",
      "Epoch 105 training complete\n",
      "Cost on training data: 0.0160728119272\n",
      "Accuracy on evaluation data: 9461 / 10000\n",
      "\n",
      "Epoch 106 training complete\n",
      "Cost on training data: 0.0159351014647\n",
      "Accuracy on evaluation data: 9460 / 10000\n",
      "\n",
      "Epoch 107 training complete\n",
      "Cost on training data: 0.0158454713383\n",
      "Accuracy on evaluation data: 9461 / 10000\n",
      "\n",
      "Epoch 108 training complete\n",
      "Cost on training data: 0.0157004416192\n",
      "Accuracy on evaluation data: 9462 / 10000\n",
      "\n",
      "Epoch 109 training complete\n",
      "Cost on training data: 0.0155739834842\n",
      "Accuracy on evaluation data: 9460 / 10000\n",
      "\n",
      "Epoch 110 training complete\n",
      "Cost on training data: 0.0154637714528\n",
      "Accuracy on evaluation data: 9459 / 10000\n",
      "\n",
      "Epoch 111 training complete\n",
      "Cost on training data: 0.0153454742623\n",
      "Accuracy on evaluation data: 9461 / 10000\n",
      "\n",
      "Epoch 112 training complete\n",
      "Cost on training data: 0.0152208753668\n",
      "Accuracy on evaluation data: 9457 / 10000\n",
      "\n",
      "Epoch 113 training complete\n",
      "Cost on training data: 0.0151080800045\n",
      "Accuracy on evaluation data: 9458 / 10000\n",
      "\n",
      "Epoch 114 training complete\n",
      "Cost on training data: 0.014997780061\n",
      "Accuracy on evaluation data: 9456 / 10000\n",
      "\n",
      "Epoch 115 training complete\n",
      "Cost on training data: 0.0148776590832\n",
      "Accuracy on evaluation data: 9456 / 10000\n",
      "\n",
      "Epoch 116 training complete\n",
      "Cost on training data: 0.0147588550407\n",
      "Accuracy on evaluation data: 9456 / 10000\n",
      "\n",
      "Epoch 117 training complete\n",
      "Cost on training data: 0.0146391284554\n",
      "Accuracy on evaluation data: 9457 / 10000\n",
      "\n",
      "Epoch 118 training complete\n",
      "Cost on training data: 0.0145161493051\n",
      "Accuracy on evaluation data: 9454 / 10000\n",
      "\n",
      "Epoch 119 training complete\n",
      "Cost on training data: 0.0143906243664\n",
      "Accuracy on evaluation data: 9456 / 10000\n",
      "\n",
      "Epoch 120 training complete\n",
      "Cost on training data: 0.014278881079\n",
      "Accuracy on evaluation data: 9453 / 10000\n",
      "\n",
      "Epoch 121 training complete\n",
      "Cost on training data: 0.0141403121481\n",
      "Accuracy on evaluation data: 9455 / 10000\n",
      "\n",
      "Epoch 122 training complete\n",
      "Cost on training data: 0.0140336379536\n",
      "Accuracy on evaluation data: 9454 / 10000\n",
      "\n",
      "Epoch 123 training complete\n",
      "Cost on training data: 0.0139109944942\n",
      "Accuracy on evaluation data: 9455 / 10000\n",
      "\n",
      "Epoch 124 training complete\n",
      "Cost on training data: 0.0137972037947\n",
      "Accuracy on evaluation data: 9454 / 10000\n",
      "\n",
      "Epoch 125 training complete\n",
      "Cost on training data: 0.0137021113293\n",
      "Accuracy on evaluation data: 9453 / 10000\n",
      "\n",
      "Epoch 126 training complete\n",
      "Cost on training data: 0.0135925536743\n",
      "Accuracy on evaluation data: 9458 / 10000\n",
      "\n",
      "Epoch 127 training complete\n",
      "Cost on training data: 0.0134977278287\n",
      "Accuracy on evaluation data: 9450 / 10000\n",
      "\n",
      "Epoch 128 training complete\n",
      "Cost on training data: 0.0134112653047\n",
      "Accuracy on evaluation data: 9452 / 10000\n",
      "\n",
      "Epoch 129 training complete\n",
      "Cost on training data: 0.0133155679621\n",
      "Accuracy on evaluation data: 9452 / 10000\n",
      "\n",
      "Epoch 130 training complete\n",
      "Cost on training data: 0.0132169596203\n",
      "Accuracy on evaluation data: 9456 / 10000\n",
      "\n",
      "Epoch 131 training complete\n",
      "Cost on training data: 0.013137614684\n",
      "Accuracy on evaluation data: 9454 / 10000\n",
      "\n",
      "Epoch 132 training complete\n",
      "Cost on training data: 0.013052383957\n",
      "Accuracy on evaluation data: 9452 / 10000\n",
      "\n",
      "Epoch 133 training complete\n",
      "Cost on training data: 0.0129632454616\n",
      "Accuracy on evaluation data: 9451 / 10000\n",
      "\n",
      "Epoch 134 training complete\n",
      "Cost on training data: 0.0128687075124\n",
      "Accuracy on evaluation data: 9454 / 10000\n",
      "\n",
      "Epoch 135 training complete\n",
      "Cost on training data: 0.0127863239548\n",
      "Accuracy on evaluation data: 9454 / 10000\n",
      "\n",
      "Epoch 136 training complete\n",
      "Cost on training data: 0.0127071592461\n",
      "Accuracy on evaluation data: 9455 / 10000\n",
      "\n",
      "Epoch 137 training complete\n",
      "Cost on training data: 0.012620151814\n",
      "Accuracy on evaluation data: 9454 / 10000\n",
      "\n",
      "Epoch 138 training complete\n",
      "Cost on training data: 0.0125370279175\n",
      "Accuracy on evaluation data: 9453 / 10000\n",
      "\n",
      "Epoch 139 training complete\n",
      "Cost on training data: 0.0124623873105\n",
      "Accuracy on evaluation data: 9452 / 10000\n",
      "\n",
      "Epoch 140 training complete\n",
      "Cost on training data: 0.0123875022645\n",
      "Accuracy on evaluation data: 9453 / 10000\n",
      "\n",
      "Epoch 141 training complete\n",
      "Cost on training data: 0.0123094226652\n",
      "Accuracy on evaluation data: 9454 / 10000\n",
      "\n",
      "Epoch 142 training complete\n",
      "Cost on training data: 0.0122402598113\n",
      "Accuracy on evaluation data: 9456 / 10000\n",
      "\n",
      "Epoch 143 training complete\n",
      "Cost on training data: 0.0121602972067\n",
      "Accuracy on evaluation data: 9454 / 10000\n",
      "\n",
      "Epoch 144 training complete\n",
      "Cost on training data: 0.0120788078998\n",
      "Accuracy on evaluation data: 9452 / 10000\n",
      "\n",
      "Epoch 145 training complete\n",
      "Cost on training data: 0.0120091491882\n",
      "Accuracy on evaluation data: 9454 / 10000\n",
      "\n",
      "Epoch 146 training complete\n",
      "Cost on training data: 0.0119311065499\n",
      "Accuracy on evaluation data: 9454 / 10000\n",
      "\n",
      "Epoch 147 training complete\n",
      "Cost on training data: 0.0118629296749\n",
      "Accuracy on evaluation data: 9455 / 10000\n",
      "\n",
      "Epoch 148 training complete\n",
      "Cost on training data: 0.0117873640018\n",
      "Accuracy on evaluation data: 9453 / 10000\n",
      "\n",
      "Epoch 149 training complete\n",
      "Cost on training data: 0.011718175556\n",
      "Accuracy on evaluation data: 9456 / 10000\n",
      "\n",
      "Epoch 150 training complete\n",
      "Cost on training data: 0.0116513460665\n",
      "Accuracy on evaluation data: 9455 / 10000\n",
      "\n",
      "Epoch 151 training complete\n",
      "Cost on training data: 0.0115870673386\n",
      "Accuracy on evaluation data: 9455 / 10000\n",
      "\n",
      "Epoch 152 training complete\n",
      "Cost on training data: 0.0115179486871\n",
      "Accuracy on evaluation data: 9455 / 10000\n",
      "\n",
      "Epoch 153 training complete\n",
      "Cost on training data: 0.0114647244887\n",
      "Accuracy on evaluation data: 9453 / 10000\n",
      "\n",
      "Epoch 154 training complete\n",
      "Cost on training data: 0.011398984202\n",
      "Accuracy on evaluation data: 9452 / 10000\n",
      "\n",
      "Epoch 155 training complete\n",
      "Cost on training data: 0.0113284248011\n",
      "Accuracy on evaluation data: 9450 / 10000\n",
      "\n",
      "Epoch 156 training complete\n",
      "Cost on training data: 0.011261340143\n",
      "Accuracy on evaluation data: 9456 / 10000\n",
      "\n",
      "Epoch 157 training complete\n",
      "Cost on training data: 0.0112075415755\n",
      "Accuracy on evaluation data: 9456 / 10000\n",
      "\n",
      "Epoch 158 training complete\n",
      "Cost on training data: 0.0111388603628\n",
      "Accuracy on evaluation data: 9453 / 10000\n",
      "\n",
      "Epoch 159 training complete\n",
      "Cost on training data: 0.0110760527182\n",
      "Accuracy on evaluation data: 9455 / 10000\n",
      "\n",
      "Epoch 160 training complete\n",
      "Cost on training data: 0.011016849701\n",
      "Accuracy on evaluation data: 9454 / 10000\n",
      "\n",
      "Epoch 161 training complete\n",
      "Cost on training data: 0.0109572302355\n",
      "Accuracy on evaluation data: 9455 / 10000\n",
      "\n",
      "Epoch 162 training complete\n",
      "Cost on training data: 0.0109003832527\n",
      "Accuracy on evaluation data: 9454 / 10000\n",
      "\n",
      "Epoch 163 training complete\n",
      "Cost on training data: 0.0108516543865\n",
      "Accuracy on evaluation data: 9453 / 10000\n",
      "\n",
      "Epoch 164 training complete\n",
      "Cost on training data: 0.0107921475431\n",
      "Accuracy on evaluation data: 9454 / 10000\n",
      "\n",
      "Epoch 165 training complete\n",
      "Cost on training data: 0.010736536001\n",
      "Accuracy on evaluation data: 9452 / 10000\n",
      "\n",
      "Epoch 166 training complete\n",
      "Cost on training data: 0.0106761212995\n",
      "Accuracy on evaluation data: 9452 / 10000\n",
      "\n",
      "Epoch 167 training complete\n",
      "Cost on training data: 0.010622401468\n",
      "Accuracy on evaluation data: 9452 / 10000\n",
      "\n",
      "Epoch 168 training complete\n",
      "Cost on training data: 0.0105701707399\n",
      "Accuracy on evaluation data: 9452 / 10000\n",
      "\n",
      "Epoch 169 training complete\n",
      "Cost on training data: 0.010515425377\n",
      "Accuracy on evaluation data: 9453 / 10000\n",
      "\n",
      "Epoch 170 training complete\n",
      "Cost on training data: 0.0104657840553\n",
      "Accuracy on evaluation data: 9450 / 10000\n",
      "\n",
      "Epoch 171 training complete\n",
      "Cost on training data: 0.0104093008567\n",
      "Accuracy on evaluation data: 9450 / 10000\n",
      "\n",
      "Epoch 172 training complete\n",
      "Cost on training data: 0.0103693373846\n",
      "Accuracy on evaluation data: 9450 / 10000\n",
      "\n",
      "Epoch 173 training complete\n",
      "Cost on training data: 0.0103071150819\n",
      "Accuracy on evaluation data: 9451 / 10000\n",
      "\n",
      "Epoch 174 training complete\n",
      "Cost on training data: 0.0102587554455\n",
      "Accuracy on evaluation data: 9450 / 10000\n",
      "\n",
      "Epoch 175 training complete\n",
      "Cost on training data: 0.0102072605702\n",
      "Accuracy on evaluation data: 9450 / 10000\n",
      "\n",
      "Epoch 176 training complete\n",
      "Cost on training data: 0.0101634090756\n",
      "Accuracy on evaluation data: 9450 / 10000\n",
      "\n",
      "Epoch 177 training complete\n",
      "Cost on training data: 0.0101090560827\n",
      "Accuracy on evaluation data: 9449 / 10000\n",
      "\n",
      "Epoch 178 training complete\n",
      "Cost on training data: 0.0100628060189\n",
      "Accuracy on evaluation data: 9448 / 10000\n",
      "\n",
      "Epoch 179 training complete\n",
      "Cost on training data: 0.0100151421086\n",
      "Accuracy on evaluation data: 9448 / 10000\n",
      "\n",
      "Epoch 180 training complete\n",
      "Cost on training data: 0.00996893210272\n",
      "Accuracy on evaluation data: 9450 / 10000\n",
      "\n",
      "Epoch 181 training complete\n",
      "Cost on training data: 0.00992281122677\n",
      "Accuracy on evaluation data: 9451 / 10000\n",
      "\n",
      "Epoch 182 training complete\n",
      "Cost on training data: 0.00987633431397\n",
      "Accuracy on evaluation data: 9450 / 10000\n",
      "\n",
      "Epoch 183 training complete\n",
      "Cost on training data: 0.00982366600682\n",
      "Accuracy on evaluation data: 9450 / 10000\n",
      "\n",
      "Epoch 184 training complete\n",
      "Cost on training data: 0.00977393322642\n",
      "Accuracy on evaluation data: 9449 / 10000\n",
      "\n",
      "Epoch 185 training complete\n",
      "Cost on training data: 0.00972813191808\n",
      "Accuracy on evaluation data: 9450 / 10000\n",
      "\n",
      "Epoch 186 training complete\n",
      "Cost on training data: 0.00968032599954\n",
      "Accuracy on evaluation data: 9448 / 10000\n",
      "\n",
      "Epoch 187 training complete\n",
      "Cost on training data: 0.00963643957248\n",
      "Accuracy on evaluation data: 9447 / 10000\n",
      "\n",
      "Epoch 188 training complete\n",
      "Cost on training data: 0.00958652614733\n",
      "Accuracy on evaluation data: 9446 / 10000\n",
      "\n",
      "Epoch 189 training complete\n",
      "Cost on training data: 0.0095400204516\n",
      "Accuracy on evaluation data: 9448 / 10000\n",
      "\n",
      "Epoch 190 training complete\n",
      "Cost on training data: 0.00949446648673\n",
      "Accuracy on evaluation data: 9445 / 10000\n",
      "\n",
      "Epoch 191 training complete\n",
      "Cost on training data: 0.00944477076766\n",
      "Accuracy on evaluation data: 9445 / 10000\n",
      "\n",
      "Epoch 192 training complete\n",
      "Cost on training data: 0.0093981808132\n",
      "Accuracy on evaluation data: 9445 / 10000\n",
      "\n",
      "Epoch 193 training complete\n",
      "Cost on training data: 0.00935422345203\n",
      "Accuracy on evaluation data: 9443 / 10000\n",
      "\n",
      "Epoch 194 training complete\n",
      "Cost on training data: 0.00930862722572\n",
      "Accuracy on evaluation data: 9443 / 10000\n",
      "\n",
      "Epoch 195 training complete\n",
      "Cost on training data: 0.00926550914851\n",
      "Accuracy on evaluation data: 9444 / 10000\n",
      "\n",
      "Epoch 196 training complete\n",
      "Cost on training data: 0.00922054914412\n",
      "Accuracy on evaluation data: 9444 / 10000\n",
      "\n",
      "Epoch 197 training complete\n",
      "Cost on training data: 0.0091801259153\n",
      "Accuracy on evaluation data: 9442 / 10000\n",
      "\n",
      "Epoch 198 training complete\n",
      "Cost on training data: 0.00913604776514\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 199 training complete\n",
      "Cost on training data: 0.00909369874378\n",
      "Accuracy on evaluation data: 9441 / 10000\n",
      "\n",
      "Epoch 200 training complete\n",
      "Cost on training data: 0.00905348329723\n",
      "Accuracy on evaluation data: 9441 / 10000\n",
      "\n",
      "Epoch 201 training complete\n",
      "Cost on training data: 0.00901432174854\n",
      "Accuracy on evaluation data: 9444 / 10000\n",
      "\n",
      "Epoch 202 training complete\n",
      "Cost on training data: 0.00897318286743\n",
      "Accuracy on evaluation data: 9441 / 10000\n",
      "\n",
      "Epoch 203 training complete\n",
      "Cost on training data: 0.00893230446152\n",
      "Accuracy on evaluation data: 9442 / 10000\n",
      "\n",
      "Epoch 204 training complete\n",
      "Cost on training data: 0.00889381592526\n",
      "Accuracy on evaluation data: 9442 / 10000\n",
      "\n",
      "Epoch 205 training complete\n",
      "Cost on training data: 0.00885499190889\n",
      "Accuracy on evaluation data: 9442 / 10000\n",
      "\n",
      "Epoch 206 training complete\n",
      "Cost on training data: 0.00882261885555\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 207 training complete\n",
      "Cost on training data: 0.00878170810715\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 208 training complete\n",
      "Cost on training data: 0.00874489898248\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 209 training complete\n",
      "Cost on training data: 0.00870624428548\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 210 training complete\n",
      "Cost on training data: 0.0086707357727\n",
      "Accuracy on evaluation data: 9438 / 10000\n",
      "\n",
      "Epoch 211 training complete\n",
      "Cost on training data: 0.00863542592069\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 212 training complete\n",
      "Cost on training data: 0.00859869139714\n",
      "Accuracy on evaluation data: 9438 / 10000\n",
      "\n",
      "Epoch 213 training complete\n",
      "Cost on training data: 0.00856311109725\n",
      "Accuracy on evaluation data: 9441 / 10000\n",
      "\n",
      "Epoch 214 training complete\n",
      "Cost on training data: 0.00852698730393\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 215 training complete\n",
      "Cost on training data: 0.00849255674067\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 216 training complete\n",
      "Cost on training data: 0.00845785375572\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 217 training complete\n",
      "Cost on training data: 0.00842605160247\n",
      "Accuracy on evaluation data: 9441 / 10000\n",
      "\n",
      "Epoch 218 training complete\n",
      "Cost on training data: 0.00839093713252\n",
      "Accuracy on evaluation data: 9441 / 10000\n",
      "\n",
      "Epoch 219 training complete\n",
      "Cost on training data: 0.00835663955786\n",
      "Accuracy on evaluation data: 9441 / 10000\n",
      "\n",
      "Epoch 220 training complete\n",
      "Cost on training data: 0.00832364059765\n",
      "Accuracy on evaluation data: 9441 / 10000\n",
      "\n",
      "Epoch 221 training complete\n",
      "Cost on training data: 0.00829018136628\n",
      "Accuracy on evaluation data: 9442 / 10000\n",
      "\n",
      "Epoch 222 training complete\n",
      "Cost on training data: 0.00825805025488\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 223 training complete\n",
      "Cost on training data: 0.00822521690169\n",
      "Accuracy on evaluation data: 9442 / 10000\n",
      "\n",
      "Epoch 224 training complete\n",
      "Cost on training data: 0.0081927466721\n",
      "Accuracy on evaluation data: 9442 / 10000\n",
      "\n",
      "Epoch 225 training complete\n",
      "Cost on training data: 0.00816155388873\n",
      "Accuracy on evaluation data: 9441 / 10000\n",
      "\n",
      "Epoch 226 training complete\n",
      "Cost on training data: 0.00813117884099\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 227 training complete\n",
      "Cost on training data: 0.00809811347498\n",
      "Accuracy on evaluation data: 9441 / 10000\n",
      "\n",
      "Epoch 228 training complete\n",
      "Cost on training data: 0.00806629956225\n",
      "Accuracy on evaluation data: 9441 / 10000\n",
      "\n",
      "Epoch 229 training complete\n",
      "Cost on training data: 0.00803574447485\n",
      "Accuracy on evaluation data: 9442 / 10000\n",
      "\n",
      "Epoch 230 training complete\n",
      "Cost on training data: 0.00800431035857\n",
      "Accuracy on evaluation data: 9443 / 10000\n",
      "\n",
      "Epoch 231 training complete\n",
      "Cost on training data: 0.00797426067753\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 232 training complete\n",
      "Cost on training data: 0.00794174220078\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 233 training complete\n",
      "Cost on training data: 0.00791147886913\n",
      "Accuracy on evaluation data: 9442 / 10000\n",
      "\n",
      "Epoch 234 training complete\n",
      "Cost on training data: 0.00788095166483\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 235 training complete\n",
      "Cost on training data: 0.00785198956147\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 236 training complete\n",
      "Cost on training data: 0.00781998550667\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 237 training complete\n",
      "Cost on training data: 0.00779086937727\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 238 training complete\n",
      "Cost on training data: 0.00776000141165\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 239 training complete\n",
      "Cost on training data: 0.0077303334673\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 240 training complete\n",
      "Cost on training data: 0.00769977878594\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 241 training complete\n",
      "Cost on training data: 0.00766973758061\n",
      "Accuracy on evaluation data: 9438 / 10000\n",
      "\n",
      "Epoch 242 training complete\n",
      "Cost on training data: 0.0076410108223\n",
      "Accuracy on evaluation data: 9438 / 10000\n",
      "\n",
      "Epoch 243 training complete\n",
      "Cost on training data: 0.00761065702263\n",
      "Accuracy on evaluation data: 9438 / 10000\n",
      "\n",
      "Epoch 244 training complete\n",
      "Cost on training data: 0.00758069177617\n",
      "Accuracy on evaluation data: 9438 / 10000\n",
      "\n",
      "Epoch 245 training complete\n",
      "Cost on training data: 0.00755106795216\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 246 training complete\n",
      "Cost on training data: 0.00752084233338\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 247 training complete\n",
      "Cost on training data: 0.00749167233541\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 248 training complete\n",
      "Cost on training data: 0.0074612320135\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 249 training complete\n",
      "Cost on training data: 0.00743183713038\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 250 training complete\n",
      "Cost on training data: 0.00740131321738\n",
      "Accuracy on evaluation data: 9442 / 10000\n",
      "\n",
      "Epoch 251 training complete\n",
      "Cost on training data: 0.0073708976845\n",
      "Accuracy on evaluation data: 9442 / 10000\n",
      "\n",
      "Epoch 252 training complete\n",
      "Cost on training data: 0.0073404202712\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 253 training complete\n",
      "Cost on training data: 0.00731079084849\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 254 training complete\n",
      "Cost on training data: 0.00727837118248\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 255 training complete\n",
      "Cost on training data: 0.00724731292922\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 256 training complete\n",
      "Cost on training data: 0.00721491653813\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 257 training complete\n",
      "Cost on training data: 0.00718379450181\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 258 training complete\n",
      "Cost on training data: 0.00715203055237\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 259 training complete\n",
      "Cost on training data: 0.00712114683364\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 260 training complete\n",
      "Cost on training data: 0.00709025228221\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 261 training complete\n",
      "Cost on training data: 0.00706012352552\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 262 training complete\n",
      "Cost on training data: 0.00702972055333\n",
      "Accuracy on evaluation data: 9438 / 10000\n",
      "\n",
      "Epoch 263 training complete\n",
      "Cost on training data: 0.00700081798151\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 264 training complete\n",
      "Cost on training data: 0.006971011984\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 265 training complete\n",
      "Cost on training data: 0.00694186489759\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 266 training complete\n",
      "Cost on training data: 0.0069135602162\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 267 training complete\n",
      "Cost on training data: 0.00688552794868\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 268 training complete\n",
      "Cost on training data: 0.00685896809521\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 269 training complete\n",
      "Cost on training data: 0.00683076613719\n",
      "Accuracy on evaluation data: 9438 / 10000\n",
      "\n",
      "Epoch 270 training complete\n",
      "Cost on training data: 0.00680370490069\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 271 training complete\n",
      "Cost on training data: 0.00677790805486\n",
      "Accuracy on evaluation data: 9438 / 10000\n",
      "\n",
      "Epoch 272 training complete\n",
      "Cost on training data: 0.00675086907778\n",
      "Accuracy on evaluation data: 9438 / 10000\n",
      "\n",
      "Epoch 273 training complete\n",
      "Cost on training data: 0.00672412852066\n",
      "Accuracy on evaluation data: 9438 / 10000\n",
      "\n",
      "Epoch 274 training complete\n",
      "Cost on training data: 0.00669752866716\n",
      "Accuracy on evaluation data: 9437 / 10000\n",
      "\n",
      "Epoch 275 training complete\n",
      "Cost on training data: 0.00667203686859\n",
      "Accuracy on evaluation data: 9438 / 10000\n",
      "\n",
      "Epoch 276 training complete\n",
      "Cost on training data: 0.00664667398206\n",
      "Accuracy on evaluation data: 9438 / 10000\n",
      "\n",
      "Epoch 277 training complete\n",
      "Cost on training data: 0.00662169027911\n",
      "Accuracy on evaluation data: 9437 / 10000\n",
      "\n",
      "Epoch 278 training complete\n",
      "Cost on training data: 0.00659653005451\n",
      "Accuracy on evaluation data: 9437 / 10000\n",
      "\n",
      "Epoch 279 training complete\n",
      "Cost on training data: 0.00657134791004\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 280 training complete\n",
      "Cost on training data: 0.00654631849303\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 281 training complete\n",
      "Cost on training data: 0.00652156446824\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 282 training complete\n",
      "Cost on training data: 0.00649736006262\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 283 training complete\n",
      "Cost on training data: 0.006473490813\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 284 training complete\n",
      "Cost on training data: 0.00644934669238\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 285 training complete\n",
      "Cost on training data: 0.0064264284704\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 286 training complete\n",
      "Cost on training data: 0.00640255231025\n",
      "Accuracy on evaluation data: 9438 / 10000\n",
      "\n",
      "Epoch 287 training complete\n",
      "Cost on training data: 0.0063794289953\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 288 training complete\n",
      "Cost on training data: 0.00635676214814\n",
      "Accuracy on evaluation data: 9440 / 10000\n",
      "\n",
      "Epoch 289 training complete\n",
      "Cost on training data: 0.00633386436442\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 290 training complete\n",
      "Cost on training data: 0.00631154309145\n",
      "Accuracy on evaluation data: 9438 / 10000\n",
      "\n",
      "Epoch 291 training complete\n",
      "Cost on training data: 0.00628909883184\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 292 training complete\n",
      "Cost on training data: 0.00626640235139\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 293 training complete\n",
      "Cost on training data: 0.00624557837629\n",
      "Accuracy on evaluation data: 9437 / 10000\n",
      "\n",
      "Epoch 294 training complete\n",
      "Cost on training data: 0.00622266131673\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 295 training complete\n",
      "Cost on training data: 0.00620124149415\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 296 training complete\n",
      "Cost on training data: 0.00617963353533\n",
      "Accuracy on evaluation data: 9439 / 10000\n",
      "\n",
      "Epoch 297 training complete\n",
      "Cost on training data: 0.00615891100221\n",
      "Accuracy on evaluation data: 9438 / 10000\n",
      "\n",
      "Epoch 298 training complete\n",
      "Cost on training data: 0.00613763388306\n",
      "Accuracy on evaluation data: 9438 / 10000\n",
      "\n",
      "Epoch 299 training complete\n",
      "Cost on training data: 0.00611737045815\n",
      "Accuracy on evaluation data: 9438 / 10000\n",
      "\n",
      "Epoch 300 training complete\n",
      "Cost on training data: 0.00609599221159\n",
      "Accuracy on evaluation data: 9438 / 10000\n",
      "\n",
      "Epoch 301 training complete\n",
      "Cost on training data: 0.00607530059536\n",
      "Accuracy on evaluation data: 9437 / 10000\n",
      "\n",
      "Epoch 302 training complete\n",
      "Cost on training data: 0.00605524574261\n",
      "Accuracy on evaluation data: 9437 / 10000\n",
      "\n",
      "Epoch 303 training complete\n",
      "Cost on training data: 0.00603453819134\n",
      "Accuracy on evaluation data: 9437 / 10000\n",
      "\n",
      "Epoch 304 training complete\n",
      "Cost on training data: 0.00601503426118\n",
      "Accuracy on evaluation data: 9437 / 10000\n",
      "\n",
      "Epoch 305 training complete\n",
      "Cost on training data: 0.00599435336795\n",
      "Accuracy on evaluation data: 9437 / 10000\n",
      "\n",
      "Epoch 306 training complete\n",
      "Cost on training data: 0.00597456442483\n",
      "Accuracy on evaluation data: 9437 / 10000\n",
      "\n",
      "Epoch 307 training complete\n",
      "Cost on training data: 0.0059546562921\n",
      "Accuracy on evaluation data: 9437 / 10000\n",
      "\n",
      "Epoch 308 training complete\n",
      "Cost on training data: 0.0059351532435\n",
      "Accuracy on evaluation data: 9436 / 10000\n",
      "\n",
      "Epoch 309 training complete\n",
      "Cost on training data: 0.00591564075326\n",
      "Accuracy on evaluation data: 9436 / 10000\n",
      "\n",
      "Epoch 310 training complete\n",
      "Cost on training data: 0.00589607359934\n",
      "Accuracy on evaluation data: 9436 / 10000\n",
      "\n",
      "Epoch 311 training complete\n",
      "Cost on training data: 0.005877484926\n",
      "Accuracy on evaluation data: 9437 / 10000\n",
      "\n",
      "Epoch 312 training complete\n",
      "Cost on training data: 0.00585808435905\n",
      "Accuracy on evaluation data: 9435 / 10000\n",
      "\n",
      "Epoch 313 training complete\n",
      "Cost on training data: 0.00583894596666\n",
      "Accuracy on evaluation data: 9435 / 10000\n",
      "\n",
      "Epoch 314 training complete\n",
      "Cost on training data: 0.0058196879745\n",
      "Accuracy on evaluation data: 9435 / 10000\n",
      "\n",
      "Epoch 315 training complete\n",
      "Cost on training data: 0.00580115390188\n",
      "Accuracy on evaluation data: 9435 / 10000\n",
      "\n",
      "Epoch 316 training complete\n",
      "Cost on training data: 0.00578262799599\n",
      "Accuracy on evaluation data: 9435 / 10000\n",
      "\n",
      "Epoch 317 training complete\n",
      "Cost on training data: 0.00576384784905\n",
      "Accuracy on evaluation data: 9435 / 10000\n",
      "\n",
      "Epoch 318 training complete\n",
      "Cost on training data: 0.00574560755586\n",
      "Accuracy on evaluation data: 9435 / 10000\n",
      "\n",
      "Epoch 319 training complete\n",
      "Cost on training data: 0.00572720402739\n",
      "Accuracy on evaluation data: 9436 / 10000\n",
      "\n",
      "Epoch 320 training complete\n",
      "Cost on training data: 0.00570853325659\n",
      "Accuracy on evaluation data: 9435 / 10000\n",
      "\n",
      "Epoch 321 training complete\n",
      "Cost on training data: 0.00569047701284\n",
      "Accuracy on evaluation data: 9435 / 10000\n",
      "\n",
      "Epoch 322 training complete\n",
      "Cost on training data: 0.00567257427654\n",
      "Accuracy on evaluation data: 9435 / 10000\n",
      "\n",
      "Epoch 323 training complete\n",
      "Cost on training data: 0.00565450482624\n",
      "Accuracy on evaluation data: 9435 / 10000\n",
      "\n",
      "Epoch 324 training complete\n",
      "Cost on training data: 0.0056367593236\n",
      "Accuracy on evaluation data: 9435 / 10000\n",
      "\n",
      "Epoch 325 training complete\n",
      "Cost on training data: 0.00561899951226\n",
      "Accuracy on evaluation data: 9435 / 10000\n",
      "\n",
      "Epoch 326 training complete\n",
      "Cost on training data: 0.00560148344101\n",
      "Accuracy on evaluation data: 9435 / 10000\n",
      "\n",
      "Epoch 327 training complete\n",
      "Cost on training data: 0.00558454373939\n",
      "Accuracy on evaluation data: 9435 / 10000\n",
      "\n",
      "Epoch 328 training complete\n",
      "Cost on training data: 0.00556676442603\n",
      "Accuracy on evaluation data: 9436 / 10000\n",
      "\n",
      "Epoch 329 training complete\n",
      "Cost on training data: 0.00554950636661\n",
      "Accuracy on evaluation data: 9436 / 10000\n",
      "\n",
      "Epoch 330 training complete\n",
      "Cost on training data: 0.00553225830405\n",
      "Accuracy on evaluation data: 9436 / 10000\n",
      "\n",
      "Epoch 331 training complete\n",
      "Cost on training data: 0.00551498338902\n",
      "Accuracy on evaluation data: 9436 / 10000\n",
      "\n",
      "Epoch 332 training complete\n",
      "Cost on training data: 0.0054979682822\n",
      "Accuracy on evaluation data: 9435 / 10000\n",
      "\n",
      "Epoch 333 training complete\n",
      "Cost on training data: 0.0054810877786\n",
      "Accuracy on evaluation data: 9435 / 10000\n",
      "\n",
      "Epoch 334 training complete\n",
      "Cost on training data: 0.00546434530291\n",
      "Accuracy on evaluation data: 9435 / 10000\n",
      "\n",
      "Epoch 335 training complete\n",
      "Cost on training data: 0.00544795875728\n",
      "Accuracy on evaluation data: 9434 / 10000\n",
      "\n",
      "Epoch 336 training complete\n",
      "Cost on training data: 0.0054309569612\n",
      "Accuracy on evaluation data: 9433 / 10000\n",
      "\n",
      "Epoch 337 training complete\n",
      "Cost on training data: 0.00541405210313\n",
      "Accuracy on evaluation data: 9433 / 10000\n",
      "\n",
      "Epoch 338 training complete\n",
      "Cost on training data: 0.00539749483956\n",
      "Accuracy on evaluation data: 9433 / 10000\n",
      "\n",
      "Epoch 339 training complete\n",
      "Cost on training data: 0.00538118983753\n",
      "Accuracy on evaluation data: 9433 / 10000\n",
      "\n",
      "Epoch 340 training complete\n",
      "Cost on training data: 0.00536457825435\n",
      "Accuracy on evaluation data: 9433 / 10000\n",
      "\n",
      "Epoch 341 training complete\n",
      "Cost on training data: 0.00534835781693\n",
      "Accuracy on evaluation data: 9433 / 10000\n",
      "\n",
      "Epoch 342 training complete\n",
      "Cost on training data: 0.00533177540049\n",
      "Accuracy on evaluation data: 9433 / 10000\n",
      "\n",
      "Epoch 343 training complete\n",
      "Cost on training data: 0.00531531168894\n",
      "Accuracy on evaluation data: 9434 / 10000\n",
      "\n",
      "Epoch 344 training complete\n",
      "Cost on training data: 0.00529889388831\n",
      "Accuracy on evaluation data: 9433 / 10000\n",
      "\n",
      "Epoch 345 training complete\n",
      "Cost on training data: 0.00528269217879\n",
      "Accuracy on evaluation data: 9433 / 10000\n",
      "\n",
      "Epoch 346 training complete\n",
      "Cost on training data: 0.00526640780863\n",
      "Accuracy on evaluation data: 9433 / 10000\n",
      "\n",
      "Epoch 347 training complete\n",
      "Cost on training data: 0.00525010872746\n",
      "Accuracy on evaluation data: 9434 / 10000\n",
      "\n",
      "Epoch 348 training complete\n",
      "Cost on training data: 0.00523418597776\n",
      "Accuracy on evaluation data: 9434 / 10000\n",
      "\n",
      "Epoch 349 training complete\n",
      "Cost on training data: 0.00521812055418\n",
      "Accuracy on evaluation data: 9434 / 10000\n",
      "\n",
      "Epoch 350 training complete\n",
      "Cost on training data: 0.00520202132941\n",
      "Accuracy on evaluation data: 9434 / 10000\n",
      "\n",
      "Epoch 351 training complete\n",
      "Cost on training data: 0.00518611624478\n",
      "Accuracy on evaluation data: 9434 / 10000\n",
      "\n",
      "Epoch 352 training complete\n",
      "Cost on training data: 0.00517043549685\n",
      "Accuracy on evaluation data: 9434 / 10000\n",
      "\n",
      "Epoch 353 training complete\n",
      "Cost on training data: 0.00515461576641\n",
      "Accuracy on evaluation data: 9434 / 10000\n",
      "\n",
      "Epoch 354 training complete\n",
      "Cost on training data: 0.00513914287607\n",
      "Accuracy on evaluation data: 9434 / 10000\n",
      "\n",
      "Epoch 355 training complete\n",
      "Cost on training data: 0.00512368877898\n",
      "Accuracy on evaluation data: 9434 / 10000\n",
      "\n",
      "Epoch 356 training complete\n",
      "Cost on training data: 0.00510850311271\n",
      "Accuracy on evaluation data: 9434 / 10000\n",
      "\n",
      "Epoch 357 training complete\n",
      "Cost on training data: 0.00509349548914\n",
      "Accuracy on evaluation data: 9434 / 10000\n",
      "\n",
      "Epoch 358 training complete\n",
      "Cost on training data: 0.00507837005584\n",
      "Accuracy on evaluation data: 9434 / 10000\n",
      "\n",
      "Epoch 359 training complete\n",
      "Cost on training data: 0.00506375718743\n",
      "Accuracy on evaluation data: 9433 / 10000\n",
      "\n",
      "Epoch 360 training complete\n",
      "Cost on training data: 0.00504883841607\n",
      "Accuracy on evaluation data: 9434 / 10000\n",
      "\n",
      "Epoch 361 training complete\n",
      "Cost on training data: 0.00503422282344\n",
      "Accuracy on evaluation data: 9434 / 10000\n",
      "\n",
      "Epoch 362 training complete\n",
      "Cost on training data: 0.00501983112821\n",
      "Accuracy on evaluation data: 9433 / 10000\n",
      "\n",
      "Epoch 363 training complete\n",
      "Cost on training data: 0.00500548454586\n",
      "Accuracy on evaluation data: 9433 / 10000\n",
      "\n",
      "Epoch 364 training complete\n",
      "Cost on training data: 0.0049911967924\n",
      "Accuracy on evaluation data: 9433 / 10000\n",
      "\n",
      "Epoch 365 training complete\n",
      "Cost on training data: 0.00497720253581\n",
      "Accuracy on evaluation data: 9433 / 10000\n",
      "\n",
      "Epoch 366 training complete\n",
      "Cost on training data: 0.00496325399529\n",
      "Accuracy on evaluation data: 9433 / 10000\n",
      "\n",
      "Epoch 367 training complete\n",
      "Cost on training data: 0.00494932514826\n",
      "Accuracy on evaluation data: 9433 / 10000\n",
      "\n",
      "Epoch 368 training complete\n",
      "Cost on training data: 0.00493551500693\n",
      "Accuracy on evaluation data: 9433 / 10000\n",
      "\n",
      "Epoch 369 training complete\n",
      "Cost on training data: 0.00492196769541\n",
      "Accuracy on evaluation data: 9433 / 10000\n",
      "\n",
      "Epoch 370 training complete\n",
      "Cost on training data: 0.0049084852804\n",
      "Accuracy on evaluation data: 9432 / 10000\n",
      "\n",
      "Epoch 371 training complete\n",
      "Cost on training data: 0.00489490054742\n",
      "Accuracy on evaluation data: 9432 / 10000\n",
      "\n",
      "Epoch 372 training complete\n",
      "Cost on training data: 0.00488175822379\n",
      "Accuracy on evaluation data: 9430 / 10000\n",
      "\n",
      "Epoch 373 training complete\n",
      "Cost on training data: 0.00486849333369\n",
      "Accuracy on evaluation data: 9433 / 10000\n",
      "\n",
      "Epoch 374 training complete\n",
      "Cost on training data: 0.0048552656167\n",
      "Accuracy on evaluation data: 9433 / 10000\n",
      "\n",
      "Epoch 375 training complete\n",
      "Cost on training data: 0.00484211588481\n",
      "Accuracy on evaluation data: 9432 / 10000\n",
      "\n",
      "Epoch 376 training complete\n",
      "Cost on training data: 0.00482911934235\n",
      "Accuracy on evaluation data: 9431 / 10000\n",
      "\n",
      "Epoch 377 training complete\n",
      "Cost on training data: 0.00481616873969\n",
      "Accuracy on evaluation data: 9431 / 10000\n",
      "\n",
      "Epoch 378 training complete\n",
      "Cost on training data: 0.00480332163675\n",
      "Accuracy on evaluation data: 9431 / 10000\n",
      "\n",
      "Epoch 379 training complete\n",
      "Cost on training data: 0.00479056286892\n",
      "Accuracy on evaluation data: 9430 / 10000\n",
      "\n",
      "Epoch 380 training complete\n",
      "Cost on training data: 0.00477788955922\n",
      "Accuracy on evaluation data: 9429 / 10000\n",
      "\n",
      "Epoch 381 training complete\n",
      "Cost on training data: 0.00476531430445\n",
      "Accuracy on evaluation data: 9429 / 10000\n",
      "\n",
      "Epoch 382 training complete\n",
      "Cost on training data: 0.0047526999359\n",
      "Accuracy on evaluation data: 9431 / 10000\n",
      "\n",
      "Epoch 383 training complete\n",
      "Cost on training data: 0.00473998698429\n",
      "Accuracy on evaluation data: 9431 / 10000\n",
      "\n",
      "Epoch 384 training complete\n",
      "Cost on training data: 0.0047275940008\n",
      "Accuracy on evaluation data: 9429 / 10000\n",
      "\n",
      "Epoch 385 training complete\n",
      "Cost on training data: 0.00471501369684\n",
      "Accuracy on evaluation data: 9429 / 10000\n",
      "\n",
      "Epoch 386 training complete\n",
      "Cost on training data: 0.00470265490827\n",
      "Accuracy on evaluation data: 9430 / 10000\n",
      "\n",
      "Epoch 387 training complete\n",
      "Cost on training data: 0.00469034075659\n",
      "Accuracy on evaluation data: 9428 / 10000\n",
      "\n",
      "Epoch 388 training complete\n",
      "Cost on training data: 0.00467803423811\n",
      "Accuracy on evaluation data: 9429 / 10000\n",
      "\n",
      "Epoch 389 training complete\n",
      "Cost on training data: 0.00466580647337\n",
      "Accuracy on evaluation data: 9428 / 10000\n",
      "\n",
      "Epoch 390 training complete\n",
      "Cost on training data: 0.00465373153058\n",
      "Accuracy on evaluation data: 9427 / 10000\n",
      "\n",
      "Epoch 391 training complete\n",
      "Cost on training data: 0.00464142832711\n",
      "Accuracy on evaluation data: 9426 / 10000\n",
      "\n",
      "Epoch 392 training complete\n",
      "Cost on training data: 0.00462942739246\n",
      "Accuracy on evaluation data: 9426 / 10000\n",
      "\n",
      "Epoch 393 training complete\n",
      "Cost on training data: 0.004617252581\n",
      "Accuracy on evaluation data: 9426 / 10000\n",
      "\n",
      "Epoch 394 training complete\n",
      "Cost on training data: 0.00460524288773\n",
      "Accuracy on evaluation data: 9426 / 10000\n",
      "\n",
      "Epoch 395 training complete\n",
      "Cost on training data: 0.00459318468052\n",
      "Accuracy on evaluation data: 9426 / 10000\n",
      "\n",
      "Epoch 396 training complete\n",
      "Cost on training data: 0.00458095163742\n",
      "Accuracy on evaluation data: 9427 / 10000\n",
      "\n",
      "Epoch 397 training complete\n",
      "Cost on training data: 0.00456896668815\n",
      "Accuracy on evaluation data: 9427 / 10000\n",
      "\n",
      "Epoch 398 training complete\n",
      "Cost on training data: 0.00455716718138\n",
      "Accuracy on evaluation data: 9426 / 10000\n",
      "\n",
      "Epoch 399 training complete\n",
      "Cost on training data: 0.00454526887043\n",
      "Accuracy on evaluation data: 9427 / 10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [9490,\n",
       "  9505,\n",
       "  9503,\n",
       "  9505,\n",
       "  9500,\n",
       "  9508,\n",
       "  9490,\n",
       "  9497,\n",
       "  9496,\n",
       "  9492,\n",
       "  9495,\n",
       "  9489,\n",
       "  9498,\n",
       "  9496,\n",
       "  9489,\n",
       "  9478,\n",
       "  9485,\n",
       "  9486,\n",
       "  9492,\n",
       "  9480,\n",
       "  9484,\n",
       "  9479,\n",
       "  9487,\n",
       "  9490,\n",
       "  9493,\n",
       "  9494,\n",
       "  9488,\n",
       "  9488,\n",
       "  9482,\n",
       "  9490,\n",
       "  9482,\n",
       "  9478,\n",
       "  9480,\n",
       "  9486,\n",
       "  9478,\n",
       "  9478,\n",
       "  9476,\n",
       "  9473,\n",
       "  9481,\n",
       "  9474,\n",
       "  9472,\n",
       "  9475,\n",
       "  9474,\n",
       "  9475,\n",
       "  9476,\n",
       "  9474,\n",
       "  9466,\n",
       "  9471,\n",
       "  9476,\n",
       "  9473,\n",
       "  9474,\n",
       "  9470,\n",
       "  9469,\n",
       "  9463,\n",
       "  9469,\n",
       "  9467,\n",
       "  9469,\n",
       "  9467,\n",
       "  9465,\n",
       "  9467,\n",
       "  9466,\n",
       "  9465,\n",
       "  9465,\n",
       "  9467,\n",
       "  9468,\n",
       "  9465,\n",
       "  9466,\n",
       "  9466,\n",
       "  9463,\n",
       "  9465,\n",
       "  9468,\n",
       "  9466,\n",
       "  9463,\n",
       "  9471,\n",
       "  9465,\n",
       "  9469,\n",
       "  9465,\n",
       "  9468,\n",
       "  9467,\n",
       "  9466,\n",
       "  9467,\n",
       "  9467,\n",
       "  9466,\n",
       "  9468,\n",
       "  9465,\n",
       "  9463,\n",
       "  9463,\n",
       "  9465,\n",
       "  9465,\n",
       "  9462,\n",
       "  9464,\n",
       "  9463,\n",
       "  9462,\n",
       "  9460,\n",
       "  9460,\n",
       "  9461,\n",
       "  9460,\n",
       "  9462,\n",
       "  9463,\n",
       "  9461,\n",
       "  9463,\n",
       "  9460,\n",
       "  9463,\n",
       "  9459,\n",
       "  9459,\n",
       "  9461,\n",
       "  9460,\n",
       "  9461,\n",
       "  9462,\n",
       "  9460,\n",
       "  9459,\n",
       "  9461,\n",
       "  9457,\n",
       "  9458,\n",
       "  9456,\n",
       "  9456,\n",
       "  9456,\n",
       "  9457,\n",
       "  9454,\n",
       "  9456,\n",
       "  9453,\n",
       "  9455,\n",
       "  9454,\n",
       "  9455,\n",
       "  9454,\n",
       "  9453,\n",
       "  9458,\n",
       "  9450,\n",
       "  9452,\n",
       "  9452,\n",
       "  9456,\n",
       "  9454,\n",
       "  9452,\n",
       "  9451,\n",
       "  9454,\n",
       "  9454,\n",
       "  9455,\n",
       "  9454,\n",
       "  9453,\n",
       "  9452,\n",
       "  9453,\n",
       "  9454,\n",
       "  9456,\n",
       "  9454,\n",
       "  9452,\n",
       "  9454,\n",
       "  9454,\n",
       "  9455,\n",
       "  9453,\n",
       "  9456,\n",
       "  9455,\n",
       "  9455,\n",
       "  9455,\n",
       "  9453,\n",
       "  9452,\n",
       "  9450,\n",
       "  9456,\n",
       "  9456,\n",
       "  9453,\n",
       "  9455,\n",
       "  9454,\n",
       "  9455,\n",
       "  9454,\n",
       "  9453,\n",
       "  9454,\n",
       "  9452,\n",
       "  9452,\n",
       "  9452,\n",
       "  9452,\n",
       "  9453,\n",
       "  9450,\n",
       "  9450,\n",
       "  9450,\n",
       "  9451,\n",
       "  9450,\n",
       "  9450,\n",
       "  9450,\n",
       "  9449,\n",
       "  9448,\n",
       "  9448,\n",
       "  9450,\n",
       "  9451,\n",
       "  9450,\n",
       "  9450,\n",
       "  9449,\n",
       "  9450,\n",
       "  9448,\n",
       "  9447,\n",
       "  9446,\n",
       "  9448,\n",
       "  9445,\n",
       "  9445,\n",
       "  9445,\n",
       "  9443,\n",
       "  9443,\n",
       "  9444,\n",
       "  9444,\n",
       "  9442,\n",
       "  9440,\n",
       "  9441,\n",
       "  9441,\n",
       "  9444,\n",
       "  9441,\n",
       "  9442,\n",
       "  9442,\n",
       "  9442,\n",
       "  9440,\n",
       "  9440,\n",
       "  9440,\n",
       "  9440,\n",
       "  9438,\n",
       "  9439,\n",
       "  9438,\n",
       "  9441,\n",
       "  9440,\n",
       "  9439,\n",
       "  9440,\n",
       "  9441,\n",
       "  9441,\n",
       "  9441,\n",
       "  9441,\n",
       "  9442,\n",
       "  9440,\n",
       "  9442,\n",
       "  9442,\n",
       "  9441,\n",
       "  9440,\n",
       "  9441,\n",
       "  9441,\n",
       "  9442,\n",
       "  9443,\n",
       "  9440,\n",
       "  9440,\n",
       "  9442,\n",
       "  9440,\n",
       "  9440,\n",
       "  9440,\n",
       "  9440,\n",
       "  9439,\n",
       "  9440,\n",
       "  9439,\n",
       "  9438,\n",
       "  9438,\n",
       "  9438,\n",
       "  9438,\n",
       "  9439,\n",
       "  9439,\n",
       "  9440,\n",
       "  9440,\n",
       "  9440,\n",
       "  9442,\n",
       "  9442,\n",
       "  9439,\n",
       "  9440,\n",
       "  9439,\n",
       "  9439,\n",
       "  9439,\n",
       "  9439,\n",
       "  9439,\n",
       "  9439,\n",
       "  9440,\n",
       "  9439,\n",
       "  9438,\n",
       "  9439,\n",
       "  9439,\n",
       "  9439,\n",
       "  9439,\n",
       "  9440,\n",
       "  9440,\n",
       "  9438,\n",
       "  9440,\n",
       "  9438,\n",
       "  9438,\n",
       "  9438,\n",
       "  9437,\n",
       "  9438,\n",
       "  9438,\n",
       "  9437,\n",
       "  9437,\n",
       "  9440,\n",
       "  9440,\n",
       "  9440,\n",
       "  9440,\n",
       "  9440,\n",
       "  9439,\n",
       "  9440,\n",
       "  9438,\n",
       "  9440,\n",
       "  9440,\n",
       "  9439,\n",
       "  9438,\n",
       "  9439,\n",
       "  9439,\n",
       "  9437,\n",
       "  9439,\n",
       "  9439,\n",
       "  9439,\n",
       "  9438,\n",
       "  9438,\n",
       "  9438,\n",
       "  9438,\n",
       "  9437,\n",
       "  9437,\n",
       "  9437,\n",
       "  9437,\n",
       "  9437,\n",
       "  9437,\n",
       "  9437,\n",
       "  9436,\n",
       "  9436,\n",
       "  9436,\n",
       "  9437,\n",
       "  9435,\n",
       "  9435,\n",
       "  9435,\n",
       "  9435,\n",
       "  9435,\n",
       "  9435,\n",
       "  9435,\n",
       "  9436,\n",
       "  9435,\n",
       "  9435,\n",
       "  9435,\n",
       "  9435,\n",
       "  9435,\n",
       "  9435,\n",
       "  9435,\n",
       "  9435,\n",
       "  9436,\n",
       "  9436,\n",
       "  9436,\n",
       "  9436,\n",
       "  9435,\n",
       "  9435,\n",
       "  9435,\n",
       "  9434,\n",
       "  9433,\n",
       "  9433,\n",
       "  9433,\n",
       "  9433,\n",
       "  9433,\n",
       "  9433,\n",
       "  9433,\n",
       "  9434,\n",
       "  9433,\n",
       "  9433,\n",
       "  9433,\n",
       "  9434,\n",
       "  9434,\n",
       "  9434,\n",
       "  9434,\n",
       "  9434,\n",
       "  9434,\n",
       "  9434,\n",
       "  9434,\n",
       "  9434,\n",
       "  9434,\n",
       "  9434,\n",
       "  9434,\n",
       "  9433,\n",
       "  9434,\n",
       "  9434,\n",
       "  9433,\n",
       "  9433,\n",
       "  9433,\n",
       "  9433,\n",
       "  9433,\n",
       "  9433,\n",
       "  9433,\n",
       "  9433,\n",
       "  9432,\n",
       "  9432,\n",
       "  9430,\n",
       "  9433,\n",
       "  9433,\n",
       "  9432,\n",
       "  9431,\n",
       "  9431,\n",
       "  9431,\n",
       "  9430,\n",
       "  9429,\n",
       "  9429,\n",
       "  9431,\n",
       "  9431,\n",
       "  9429,\n",
       "  9429,\n",
       "  9430,\n",
       "  9428,\n",
       "  9429,\n",
       "  9428,\n",
       "  9427,\n",
       "  9426,\n",
       "  9426,\n",
       "  9426,\n",
       "  9426,\n",
       "  9426,\n",
       "  9427,\n",
       "  9427,\n",
       "  9426,\n",
       "  9427],\n",
       " [0.15864789320348352,\n",
       "  0.11189842884490327,\n",
       "  0.10155069615210943,\n",
       "  0.09312798071742405,\n",
       "  0.08752551051093295,\n",
       "  0.08403521470136159,\n",
       "  0.07820145308660632,\n",
       "  0.07475919110628688,\n",
       "  0.07278419140956174,\n",
       "  0.06898786783568231,\n",
       "  0.06621298682620257,\n",
       "  0.06436883581050831,\n",
       "  0.06216235272781327,\n",
       "  0.059781197776518614,\n",
       "  0.0570343132772712,\n",
       "  0.05440238788917875,\n",
       "  0.052027778473263626,\n",
       "  0.05090675896835636,\n",
       "  0.049040324687350534,\n",
       "  0.048005930814059176,\n",
       "  0.04654235652201467,\n",
       "  0.04574017597351238,\n",
       "  0.044631938461481946,\n",
       "  0.04402741577851677,\n",
       "  0.043243133804038235,\n",
       "  0.04230572790540103,\n",
       "  0.041445684854287644,\n",
       "  0.040605827218063835,\n",
       "  0.03988955919197479,\n",
       "  0.03910909938792125,\n",
       "  0.03829726819961998,\n",
       "  0.03781493601808714,\n",
       "  0.03710184879523371,\n",
       "  0.03645439199179785,\n",
       "  0.035919034588119486,\n",
       "  0.03536628057350664,\n",
       "  0.034844059134572516,\n",
       "  0.034260479323574976,\n",
       "  0.0337778045054251,\n",
       "  0.03323346721161662,\n",
       "  0.03281197212841638,\n",
       "  0.032326399068489074,\n",
       "  0.0319580167414196,\n",
       "  0.031537092292419015,\n",
       "  0.031100534412937475,\n",
       "  0.03069481931755678,\n",
       "  0.030316624252498058,\n",
       "  0.029907748635422438,\n",
       "  0.029521195155031873,\n",
       "  0.029133500503710916,\n",
       "  0.028729185490093213,\n",
       "  0.028410354321969925,\n",
       "  0.028016729924237524,\n",
       "  0.027714558358972404,\n",
       "  0.027346431290297284,\n",
       "  0.026966727812803213,\n",
       "  0.026690315642117064,\n",
       "  0.02635797109180833,\n",
       "  0.026067175363221246,\n",
       "  0.025716362639887077,\n",
       "  0.025379173233090236,\n",
       "  0.025079322090977768,\n",
       "  0.02472191021149681,\n",
       "  0.024433112704332766,\n",
       "  0.02413914260813504,\n",
       "  0.023920142699511815,\n",
       "  0.02361173811870671,\n",
       "  0.023249276279566657,\n",
       "  0.022981062247814623,\n",
       "  0.022708709307766826,\n",
       "  0.022425402574499098,\n",
       "  0.022167375742928007,\n",
       "  0.021928851372051066,\n",
       "  0.021713542475497633,\n",
       "  0.021414794726922235,\n",
       "  0.02119798971250291,\n",
       "  0.020971154074304523,\n",
       "  0.020729150736451936,\n",
       "  0.02048883529488235,\n",
       "  0.020356156587846754,\n",
       "  0.020076877251005903,\n",
       "  0.019898991761881413,\n",
       "  0.019662834367067873,\n",
       "  0.01946466103552456,\n",
       "  0.01927865679567929,\n",
       "  0.019087651080766092,\n",
       "  0.018952335432966056,\n",
       "  0.018707460252480473,\n",
       "  0.018585497297218357,\n",
       "  0.018373890447948026,\n",
       "  0.018236566535245653,\n",
       "  0.018036152713368055,\n",
       "  0.017904157756033403,\n",
       "  0.017725699782987613,\n",
       "  0.017569564134067767,\n",
       "  0.01742016838855485,\n",
       "  0.01728167031748279,\n",
       "  0.017132168733449575,\n",
       "  0.016984255045235135,\n",
       "  0.01684774050969542,\n",
       "  0.01671479703456525,\n",
       "  0.016594355955783527,\n",
       "  0.016442682398413767,\n",
       "  0.01631532144820502,\n",
       "  0.01619217624207314,\n",
       "  0.016072811927247105,\n",
       "  0.015935101464685082,\n",
       "  0.015845471338349196,\n",
       "  0.015700441619214345,\n",
       "  0.015573983484242297,\n",
       "  0.015463771452779548,\n",
       "  0.015345474262287936,\n",
       "  0.015220875366826519,\n",
       "  0.015108080004519506,\n",
       "  0.014997780061017641,\n",
       "  0.014877659083177133,\n",
       "  0.014758855040686851,\n",
       "  0.014639128455391658,\n",
       "  0.014516149305067916,\n",
       "  0.014390624366364856,\n",
       "  0.014278881079015716,\n",
       "  0.01414031214807509,\n",
       "  0.014033637953610468,\n",
       "  0.01391099449422158,\n",
       "  0.013797203794708151,\n",
       "  0.01370211132931118,\n",
       "  0.013592553674256084,\n",
       "  0.013497727828743814,\n",
       "  0.013411265304687248,\n",
       "  0.01331556796211776,\n",
       "  0.01321695962031925,\n",
       "  0.013137614684002135,\n",
       "  0.013052383956965962,\n",
       "  0.012963245461590023,\n",
       "  0.012868707512377278,\n",
       "  0.012786323954761607,\n",
       "  0.01270715924614872,\n",
       "  0.012620151814030471,\n",
       "  0.012537027917496123,\n",
       "  0.012462387310470632,\n",
       "  0.012387502264527263,\n",
       "  0.012309422665221812,\n",
       "  0.012240259811345813,\n",
       "  0.012160297206678976,\n",
       "  0.012078807899805262,\n",
       "  0.012009149188240333,\n",
       "  0.011931106549936175,\n",
       "  0.011862929674939453,\n",
       "  0.011787364001791647,\n",
       "  0.01171817555604876,\n",
       "  0.011651346066502491,\n",
       "  0.011587067338587803,\n",
       "  0.011517948687059068,\n",
       "  0.011464724488663027,\n",
       "  0.011398984202026369,\n",
       "  0.011328424801102048,\n",
       "  0.01126134014304154,\n",
       "  0.01120754157545642,\n",
       "  0.011138860362822823,\n",
       "  0.011076052718163419,\n",
       "  0.011016849701038472,\n",
       "  0.010957230235501832,\n",
       "  0.010900383252666814,\n",
       "  0.010851654386471595,\n",
       "  0.010792147543089122,\n",
       "  0.010736536000972727,\n",
       "  0.01067612129951043,\n",
       "  0.010622401468022033,\n",
       "  0.01057017073990799,\n",
       "  0.01051542537701297,\n",
       "  0.010465784055299325,\n",
       "  0.01040930085673483,\n",
       "  0.010369337384621664,\n",
       "  0.01030711508186234,\n",
       "  0.010258755445515733,\n",
       "  0.01020726057016943,\n",
       "  0.010163409075570017,\n",
       "  0.010109056082744953,\n",
       "  0.010062806018872055,\n",
       "  0.010015142108627306,\n",
       "  0.009968932102716332,\n",
       "  0.009922811226770786,\n",
       "  0.009876334313970746,\n",
       "  0.009823666006823462,\n",
       "  0.009773933226422091,\n",
       "  0.009728131918075917,\n",
       "  0.009680325999541002,\n",
       "  0.00963643957247827,\n",
       "  0.009586526147329693,\n",
       "  0.009540020451601466,\n",
       "  0.009494466486734163,\n",
       "  0.009444770767657094,\n",
       "  0.00939818081320441,\n",
       "  0.009354223452033152,\n",
       "  0.00930862722572058,\n",
       "  0.009265509148506117,\n",
       "  0.009220549144115877,\n",
       "  0.009180125915299955,\n",
       "  0.00913604776513821,\n",
       "  0.009093698743782762,\n",
       "  0.00905348329723188,\n",
       "  0.009014321748543268,\n",
       "  0.008973182867434048,\n",
       "  0.008932304461520987,\n",
       "  0.008893815925262479,\n",
       "  0.008854991908885996,\n",
       "  0.008822618855549616,\n",
       "  0.00878170810715035,\n",
       "  0.008744898982483516,\n",
       "  0.00870624428547688,\n",
       "  0.0086707357727029,\n",
       "  0.008635425920688822,\n",
       "  0.008598691397140059,\n",
       "  0.00856311109724573,\n",
       "  0.008526987303933961,\n",
       "  0.008492556740670716,\n",
       "  0.008457853755724627,\n",
       "  0.008426051602472536,\n",
       "  0.008390937132519923,\n",
       "  0.008356639557856111,\n",
       "  0.00832364059764646,\n",
       "  0.008290181366277538,\n",
       "  0.008258050254876033,\n",
       "  0.00822521690169103,\n",
       "  0.008192746672098676,\n",
       "  0.008161553888732218,\n",
       "  0.008131178840994815,\n",
       "  0.008098113474975664,\n",
       "  0.0080662995622508,\n",
       "  0.00803574447484678,\n",
       "  0.008004310358574613,\n",
       "  0.007974260677529061,\n",
       "  0.007941742200782139,\n",
       "  0.00791147886913401,\n",
       "  0.007880951664829154,\n",
       "  0.007851989561470282,\n",
       "  0.007819985506671309,\n",
       "  0.00779086937726906,\n",
       "  0.007760001411646888,\n",
       "  0.00773033346729815,\n",
       "  0.007699778785941804,\n",
       "  0.0076697375806072865,\n",
       "  0.007641010822296202,\n",
       "  0.007610657022631082,\n",
       "  0.007580691776167081,\n",
       "  0.007551067952160124,\n",
       "  0.0075208423333752794,\n",
       "  0.007491672335410506,\n",
       "  0.007461232013504497,\n",
       "  0.0074318371303761935,\n",
       "  0.007401313217375978,\n",
       "  0.007370897684498615,\n",
       "  0.007340420271203334,\n",
       "  0.007310790848490309,\n",
       "  0.007278371182483147,\n",
       "  0.007247312929224244,\n",
       "  0.00721491653813404,\n",
       "  0.007183794501806055,\n",
       "  0.007152030552373872,\n",
       "  0.007121146833644082,\n",
       "  0.007090252282211667,\n",
       "  0.007060123525517939,\n",
       "  0.007029720553334267,\n",
       "  0.007000817981511194,\n",
       "  0.006971011983995235,\n",
       "  0.006941864897590349,\n",
       "  0.006913560216196664,\n",
       "  0.006885527948678344,\n",
       "  0.006858968095205682,\n",
       "  0.0068307661371910435,\n",
       "  0.006803704900686024,\n",
       "  0.006777908054861202,\n",
       "  0.006750869077784836,\n",
       "  0.006724128520655184,\n",
       "  0.006697528667163622,\n",
       "  0.0066720368685883585,\n",
       "  0.006646673982059305,\n",
       "  0.006621690279113688,\n",
       "  0.00659653005451081,\n",
       "  0.006571347910037605,\n",
       "  0.006546318493030478,\n",
       "  0.006521564468238427,\n",
       "  0.006497360062616397,\n",
       "  0.006473490813000796,\n",
       "  0.006449346692378114,\n",
       "  0.00642642847040489,\n",
       "  0.006402552310254205,\n",
       "  0.006379428995301747,\n",
       "  0.006356762148140585,\n",
       "  0.0063338643644221615,\n",
       "  0.006311543091447233,\n",
       "  0.006289098831843204,\n",
       "  0.00626640235138515,\n",
       "  0.006245578376290987,\n",
       "  0.006222661316731969,\n",
       "  0.006201241494150034,\n",
       "  0.006179633535331143,\n",
       "  0.006158911002214962,\n",
       "  0.0061376338830594086,\n",
       "  0.0061173704581501225,\n",
       "  0.006095992211585805,\n",
       "  0.0060753005953556325,\n",
       "  0.006055245742607745,\n",
       "  0.006034538191338562,\n",
       "  0.006015034261179874,\n",
       "  0.005994353367951886,\n",
       "  0.005974564424830041,\n",
       "  0.005954656292095051,\n",
       "  0.005935153243501516,\n",
       "  0.0059156407532636405,\n",
       "  0.005896073599342309,\n",
       "  0.005877484925996264,\n",
       "  0.005858084359046528,\n",
       "  0.0058389459666600045,\n",
       "  0.005819687974501884,\n",
       "  0.005801153901876049,\n",
       "  0.0057826279959863275,\n",
       "  0.005763847849046741,\n",
       "  0.00574560755586026,\n",
       "  0.005727204027388358,\n",
       "  0.005708533256587605,\n",
       "  0.005690477012842592,\n",
       "  0.0056725742765416556,\n",
       "  0.005654504826238467,\n",
       "  0.005636759323604867,\n",
       "  0.005618999512261695,\n",
       "  0.00560148344101282,\n",
       "  0.0055845437393939245,\n",
       "  0.00556676442602636,\n",
       "  0.00554950636661,\n",
       "  0.005532258304048571,\n",
       "  0.005514983389020072,\n",
       "  0.005497968282202532,\n",
       "  0.00548108777860405,\n",
       "  0.005464345302912809,\n",
       "  0.005447958757279831,\n",
       "  0.005430956961197991,\n",
       "  0.005414052103125358,\n",
       "  0.005397494839558701,\n",
       "  0.005381189837527143,\n",
       "  0.005364578254347033,\n",
       "  0.005348357816926869,\n",
       "  0.005331775400488338,\n",
       "  0.0053153116889447585,\n",
       "  0.005298893888314483,\n",
       "  0.005282692178790538,\n",
       "  0.005266407808626072,\n",
       "  0.005250108727463982,\n",
       "  0.0052341859777587695,\n",
       "  0.005218120554182451,\n",
       "  0.005202021329408272,\n",
       "  0.005186116244778398,\n",
       "  0.005170435496849418,\n",
       "  0.0051546157664060736,\n",
       "  0.005139142876067874,\n",
       "  0.005123688778977663,\n",
       "  0.0051085031127066,\n",
       "  0.0050934954891412145,\n",
       "  0.005078370055844997,\n",
       "  0.005063757187434955,\n",
       "  0.0050488384160703465,\n",
       "  0.0050342228234414085,\n",
       "  0.005019831128212965,\n",
       "  0.005005484545864909,\n",
       "  0.004991196792396445,\n",
       "  0.004977202535812805,\n",
       "  0.004963253995293292,\n",
       "  0.004949325148255661,\n",
       "  0.004935515006934093,\n",
       "  0.004921967695409314,\n",
       "  0.004908485280404994,\n",
       "  0.004894900547424026,\n",
       "  0.004881758223792211,\n",
       "  0.004868493333694221,\n",
       "  0.004855265616696701,\n",
       "  0.004842115884805158,\n",
       "  0.0048291193423476144,\n",
       "  0.004816168739686947,\n",
       "  0.004803321636752542,\n",
       "  0.004790562868915319,\n",
       "  0.004777889559215582,\n",
       "  0.0047653143044521255,\n",
       "  0.0047526999359045865,\n",
       "  0.004739986984286317,\n",
       "  0.004727594000801349,\n",
       "  0.0047150136968426674,\n",
       "  0.004702654908265925,\n",
       "  0.004690340756585771,\n",
       "  0.004678034238106443,\n",
       "  0.004665806473372273,\n",
       "  0.004653731530584913,\n",
       "  0.004641428327108399,\n",
       "  0.004629427392459211,\n",
       "  0.004617252580998286,\n",
       "  0.004605242887732372,\n",
       "  0.0045931846805181975,\n",
       "  0.004580951637419682,\n",
       "  0.004568966688151547,\n",
       "  0.0045571671813798625,\n",
       "  0.00454526887042683],\n",
       " [])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.SGD(training_data[:1000], 400, 10, 0.5, evaluation_data=test_data, monitor_evaluation_accuracy=True, monitor_training_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on evaluation data: 9289 / 10000\n",
      "\n",
      "Epoch 1 training complete\n",
      "Accuracy on evaluation data: 9401 / 10000\n",
      "\n",
      "Epoch 2 training complete\n",
      "Accuracy on evaluation data: 9496 / 10000\n",
      "\n",
      "Epoch 3 training complete\n",
      "Accuracy on evaluation data: 9516 / 10000\n",
      "\n",
      "Epoch 4 training complete\n",
      "Accuracy on evaluation data: 9560 / 10000\n",
      "\n",
      "Epoch 5 training complete\n",
      "Accuracy on evaluation data: 9572 / 10000\n",
      "\n",
      "Epoch 6 training complete\n",
      "Accuracy on evaluation data: 9597 / 10000\n",
      "\n",
      "Epoch 7 training complete\n",
      "Accuracy on evaluation data: 9592 / 10000\n",
      "\n",
      "Epoch 8 training complete\n",
      "Accuracy on evaluation data: 9616 / 10000\n",
      "\n",
      "Epoch 9 training complete\n",
      "Accuracy on evaluation data: 9600 / 10000\n",
      "\n",
      "Epoch 10 training complete\n",
      "Accuracy on evaluation data: 9626 / 10000\n",
      "\n",
      "Epoch 11 training complete\n",
      "Accuracy on evaluation data: 9641 / 10000\n",
      "\n",
      "Epoch 12 training complete\n",
      "Accuracy on evaluation data: 9651 / 10000\n",
      "\n",
      "Epoch 13 training complete\n",
      "Accuracy on evaluation data: 9638 / 10000\n",
      "\n",
      "Epoch 14 training complete\n",
      "Accuracy on evaluation data: 9622 / 10000\n",
      "\n",
      "Epoch 15 training complete\n",
      "Accuracy on evaluation data: 9628 / 10000\n",
      "\n",
      "Epoch 16 training complete\n",
      "Accuracy on evaluation data: 9660 / 10000\n",
      "\n",
      "Epoch 17 training complete\n",
      "Accuracy on evaluation data: 9648 / 10000\n",
      "\n",
      "Epoch 18 training complete\n",
      "Accuracy on evaluation data: 9655 / 10000\n",
      "\n",
      "Epoch 19 training complete\n",
      "Accuracy on evaluation data: 9675 / 10000\n",
      "\n",
      "Epoch 20 training complete\n",
      "Accuracy on evaluation data: 9630 / 10000\n",
      "\n",
      "Epoch 21 training complete\n",
      "Accuracy on evaluation data: 9644 / 10000\n",
      "\n",
      "Epoch 22 training complete\n",
      "Accuracy on evaluation data: 9679 / 10000\n",
      "\n",
      "Epoch 23 training complete\n",
      "Accuracy on evaluation data: 9660 / 10000\n",
      "\n",
      "Epoch 24 training complete\n",
      "Accuracy on evaluation data: 9649 / 10000\n",
      "\n",
      "Epoch 25 training complete\n",
      "Accuracy on evaluation data: 9659 / 10000\n",
      "\n",
      "Epoch 26 training complete\n",
      "Accuracy on evaluation data: 9659 / 10000\n",
      "\n",
      "Epoch 27 training complete\n",
      "Accuracy on evaluation data: 9681 / 10000\n",
      "\n",
      "Epoch 28 training complete\n",
      "Accuracy on evaluation data: 9671 / 10000\n",
      "\n",
      "Epoch 29 training complete\n",
      "Accuracy on evaluation data: 9656 / 10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [9289,\n",
       "  9401,\n",
       "  9496,\n",
       "  9516,\n",
       "  9560,\n",
       "  9572,\n",
       "  9597,\n",
       "  9592,\n",
       "  9616,\n",
       "  9600,\n",
       "  9626,\n",
       "  9641,\n",
       "  9651,\n",
       "  9638,\n",
       "  9622,\n",
       "  9628,\n",
       "  9660,\n",
       "  9648,\n",
       "  9655,\n",
       "  9675,\n",
       "  9630,\n",
       "  9644,\n",
       "  9679,\n",
       "  9660,\n",
       "  9649,\n",
       "  9659,\n",
       "  9659,\n",
       "  9681,\n",
       "  9671,\n",
       "  9656],\n",
       " [],\n",
       " [])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deep network experimentations, \n",
    "# first a 1 hidden layer network with input 784 neurons, 30 neurons in hidden layer, and 10 output neurons.\n",
    "import network2\n",
    "net = network2.Network([784, 30, 10])\n",
    "net.SGD(training_data, 30, 10, 0.1, lmbda=5.0, evaluation_data=validation_data, monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on evaluation data: 9224 / 10000\n",
      "\n",
      "Epoch 1 training complete\n",
      "Accuracy on evaluation data: 9413 / 10000\n",
      "\n",
      "Epoch 2 training complete\n",
      "Accuracy on evaluation data: 9527 / 10000\n",
      "\n",
      "Epoch 3 training complete\n",
      "Accuracy on evaluation data: 9581 / 10000\n",
      "\n",
      "Epoch 4 training complete\n",
      "Accuracy on evaluation data: 9594 / 10000\n",
      "\n",
      "Epoch 5 training complete\n",
      "Accuracy on evaluation data: 9634 / 10000\n",
      "\n",
      "Epoch 6 training complete\n",
      "Accuracy on evaluation data: 9651 / 10000\n",
      "\n",
      "Epoch 7 training complete\n",
      "Accuracy on evaluation data: 9656 / 10000\n",
      "\n",
      "Epoch 8 training complete\n",
      "Accuracy on evaluation data: 9686 / 10000\n",
      "\n",
      "Epoch 9 training complete\n",
      "Accuracy on evaluation data: 9663 / 10000\n",
      "\n",
      "Epoch 10 training complete\n",
      "Accuracy on evaluation data: 9655 / 10000\n",
      "\n",
      "Epoch 11 training complete\n",
      "Accuracy on evaluation data: 9658 / 10000\n",
      "\n",
      "Epoch 12 training complete\n",
      "Accuracy on evaluation data: 9667 / 10000\n",
      "\n",
      "Epoch 13 training complete\n",
      "Accuracy on evaluation data: 9660 / 10000\n",
      "\n",
      "Epoch 14 training complete\n",
      "Accuracy on evaluation data: 9677 / 10000\n",
      "\n",
      "Epoch 15 training complete\n",
      "Accuracy on evaluation data: 9686 / 10000\n",
      "\n",
      "Epoch 16 training complete\n",
      "Accuracy on evaluation data: 9656 / 10000\n",
      "\n",
      "Epoch 17 training complete\n",
      "Accuracy on evaluation data: 9701 / 10000\n",
      "\n",
      "Epoch 18 training complete\n",
      "Accuracy on evaluation data: 9674 / 10000\n",
      "\n",
      "Epoch 19 training complete\n",
      "Accuracy on evaluation data: 9682 / 10000\n",
      "\n",
      "Epoch 20 training complete\n",
      "Accuracy on evaluation data: 9693 / 10000\n",
      "\n",
      "Epoch 21 training complete\n",
      "Accuracy on evaluation data: 9686 / 10000\n",
      "\n",
      "Epoch 22 training complete\n",
      "Accuracy on evaluation data: 9680 / 10000\n",
      "\n",
      "Epoch 23 training complete\n",
      "Accuracy on evaluation data: 9677 / 10000\n",
      "\n",
      "Epoch 24 training complete\n",
      "Accuracy on evaluation data: 9696 / 10000\n",
      "\n",
      "Epoch 25 training complete\n",
      "Accuracy on evaluation data: 9687 / 10000\n",
      "\n",
      "Epoch 26 training complete\n",
      "Accuracy on evaluation data: 9700 / 10000\n",
      "\n",
      "Epoch 27 training complete\n",
      "Accuracy on evaluation data: 9703 / 10000\n",
      "\n",
      "Epoch 28 training complete\n",
      "Accuracy on evaluation data: 9708 / 10000\n",
      "\n",
      "Epoch 29 training complete\n",
      "Accuracy on evaluation data: 9698 / 10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [9224,\n",
       "  9413,\n",
       "  9527,\n",
       "  9581,\n",
       "  9594,\n",
       "  9634,\n",
       "  9651,\n",
       "  9656,\n",
       "  9686,\n",
       "  9663,\n",
       "  9655,\n",
       "  9658,\n",
       "  9667,\n",
       "  9660,\n",
       "  9677,\n",
       "  9686,\n",
       "  9656,\n",
       "  9701,\n",
       "  9674,\n",
       "  9682,\n",
       "  9693,\n",
       "  9686,\n",
       "  9680,\n",
       "  9677,\n",
       "  9696,\n",
       "  9687,\n",
       "  9700,\n",
       "  9703,\n",
       "  9708,\n",
       "  9698],\n",
       " [],\n",
       " [])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now add another hidden layer also 30 neurons\n",
    "net = network2.Network([784, 30, 30, 10])\n",
    "net.SGD(training_data, 30, 10, 0.1, lmbda=5.0, evaluation_data=validation_data, monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add one more layer of 30 neurons helped. but adding another 1 or 2 more layers actuarlly make the predictions worse. why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to run under a GPU.  If this is not desired, then modify network3.py\n",
      "to set the GPU flag to False.\n"
     ]
    }
   ],
   "source": [
    "import network3\n",
    "from network3 import Network\n",
    "from network3 import ConvPoolLayer, FullyConnectedLayer, SoftmaxLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to run under a GPU.  If this is not desired, then modify network3.py\n",
      "to set the GPU flag to False.\n",
      "Training mini-batch number 0\n",
      "Training mini-batch number 1000\n",
      "Training mini-batch number 2000\n",
      "Training mini-batch number 3000\n",
      "Training mini-batch number 4000\n",
      "Epoch 0: validation accuracy 92.63%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 91.81%\n",
      "Training mini-batch number 5000\n",
      "Training mini-batch number 6000\n",
      "Training mini-batch number 7000\n",
      "Training mini-batch number 8000\n",
      "Training mini-batch number 9000\n",
      "Epoch 1: validation accuracy 94.60%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 93.97%\n",
      "Training mini-batch number 10000\n",
      "Training mini-batch number 11000\n",
      "Training mini-batch number 12000\n",
      "Training mini-batch number 13000\n",
      "Training mini-batch number 14000\n",
      "Epoch 2: validation accuracy 95.62%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 95.12%\n",
      "Training mini-batch number 15000\n",
      "Training mini-batch number 16000\n",
      "Training mini-batch number 17000\n",
      "Training mini-batch number 18000\n",
      "Training mini-batch number 19000\n",
      "Epoch 3: validation accuracy 96.20%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 95.64%\n",
      "Training mini-batch number 20000\n",
      "Training mini-batch number 21000\n",
      "Training mini-batch number 22000\n",
      "Training mini-batch number 23000\n",
      "Training mini-batch number 24000\n",
      "Epoch 4: validation accuracy 96.57%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 96.19%\n",
      "Training mini-batch number 25000\n",
      "Training mini-batch number 26000\n",
      "Training mini-batch number 27000\n",
      "Training mini-batch number 28000\n",
      "Training mini-batch number 29000\n",
      "Epoch 5: validation accuracy 96.80%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 96.62%\n",
      "Training mini-batch number 30000\n",
      "Training mini-batch number 31000\n",
      "Training mini-batch number 32000\n",
      "Training mini-batch number 33000\n",
      "Training mini-batch number 34000\n",
      "Epoch 6: validation accuracy 96.99%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 96.82%\n",
      "Training mini-batch number 35000\n",
      "Training mini-batch number 36000\n",
      "Training mini-batch number 37000\n",
      "Training mini-batch number 38000\n",
      "Training mini-batch number 39000\n",
      "Epoch 7: validation accuracy 97.15%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 96.98%\n",
      "Training mini-batch number 40000\n",
      "Training mini-batch number 41000\n",
      "Training mini-batch number 42000\n",
      "Training mini-batch number 43000\n",
      "Training mini-batch number 44000\n",
      "Epoch 8: validation accuracy 97.32%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.13%\n",
      "Training mini-batch number 45000\n",
      "Training mini-batch number 46000\n",
      "Training mini-batch number 47000\n",
      "Training mini-batch number 48000\n",
      "Training mini-batch number 49000\n",
      "Epoch 9: validation accuracy 97.33%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.26%\n",
      "Training mini-batch number 50000\n",
      "Training mini-batch number 51000\n",
      "Training mini-batch number 52000\n",
      "Training mini-batch number 53000\n",
      "Training mini-batch number 54000\n",
      "Epoch 10: validation accuracy 97.41%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.37%\n",
      "Training mini-batch number 55000\n",
      "Training mini-batch number 56000\n",
      "Training mini-batch number 57000\n",
      "Training mini-batch number 58000\n",
      "Training mini-batch number 59000\n",
      "Epoch 11: validation accuracy 97.48%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.43%\n",
      "Training mini-batch number 60000\n",
      "Training mini-batch number 61000\n",
      "Training mini-batch number 62000\n",
      "Training mini-batch number 63000\n",
      "Training mini-batch number 64000\n",
      "Epoch 12: validation accuracy 97.50%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.50%\n",
      "Training mini-batch number 65000\n",
      "Training mini-batch number 66000\n",
      "Training mini-batch number 67000\n",
      "Training mini-batch number 68000\n",
      "Training mini-batch number 69000\n",
      "Epoch 13: validation accuracy 97.56%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.53%\n",
      "Training mini-batch number 70000\n",
      "Training mini-batch number 71000\n",
      "Training mini-batch number 72000\n",
      "Training mini-batch number 73000\n",
      "Training mini-batch number 74000\n",
      "Epoch 14: validation accuracy 97.62%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.54%\n",
      "Training mini-batch number 75000\n",
      "Training mini-batch number 76000\n",
      "Training mini-batch number 77000\n",
      "Training mini-batch number 78000\n",
      "Training mini-batch number 79000\n",
      "Epoch 15: validation accuracy 97.67%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.55%\n",
      "Training mini-batch number 80000\n",
      "Training mini-batch number 81000\n",
      "Training mini-batch number 82000\n",
      "Training mini-batch number 83000\n",
      "Training mini-batch number 84000\n",
      "Epoch 16: validation accuracy 97.73%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.60%\n",
      "Training mini-batch number 85000\n",
      "Training mini-batch number 86000\n",
      "Training mini-batch number 87000\n",
      "Training mini-batch number 88000\n",
      "Training mini-batch number 89000\n",
      "Epoch 17: validation accuracy 97.76%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.61%\n",
      "Training mini-batch number 90000\n",
      "Training mini-batch number 91000\n",
      "Training mini-batch number 92000\n",
      "Training mini-batch number 93000\n",
      "Training mini-batch number 94000\n",
      "Epoch 18: validation accuracy 97.80%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.64%\n",
      "Training mini-batch number 95000\n",
      "Training mini-batch number 96000\n",
      "Training mini-batch number 97000\n",
      "Training mini-batch number 98000\n",
      "Training mini-batch number 99000\n",
      "Epoch 19: validation accuracy 97.83%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.65%\n",
      "Training mini-batch number 100000\n",
      "Training mini-batch number 101000\n",
      "Training mini-batch number 102000\n",
      "Training mini-batch number 103000\n",
      "Training mini-batch number 104000\n",
      "Epoch 20: validation accuracy 97.86%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.68%\n",
      "Training mini-batch number 105000\n",
      "Training mini-batch number 106000\n",
      "Training mini-batch number 107000\n",
      "Training mini-batch number 108000\n",
      "Training mini-batch number 109000\n",
      "Epoch 21: validation accuracy 97.86%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.68%\n",
      "Training mini-batch number 110000\n",
      "Training mini-batch number 111000\n",
      "Training mini-batch number 112000\n",
      "Training mini-batch number 113000\n",
      "Training mini-batch number 114000\n",
      "Epoch 22: validation accuracy 97.85%\n",
      "Training mini-batch number 115000\n",
      "Training mini-batch number 116000\n",
      "Training mini-batch number 117000\n",
      "Training mini-batch number 118000\n",
      "Training mini-batch number 119000\n",
      "Epoch 23: validation accuracy 97.86%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.69%\n",
      "Training mini-batch number 120000\n",
      "Training mini-batch number 121000\n",
      "Training mini-batch number 122000\n",
      "Training mini-batch number 123000\n",
      "Training mini-batch number 124000\n",
      "Epoch 24: validation accuracy 97.83%\n",
      "Training mini-batch number 125000\n",
      "Training mini-batch number 126000\n",
      "Training mini-batch number 127000\n",
      "Training mini-batch number 128000\n",
      "Training mini-batch number 129000\n",
      "Epoch 25: validation accuracy 97.86%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.71%\n",
      "Training mini-batch number 130000\n",
      "Training mini-batch number 131000\n",
      "Training mini-batch number 132000\n",
      "Training mini-batch number 133000\n",
      "Training mini-batch number 134000\n",
      "Epoch 26: validation accuracy 97.85%\n",
      "Training mini-batch number 135000\n",
      "Training mini-batch number 136000\n",
      "Training mini-batch number 137000\n",
      "Training mini-batch number 138000\n",
      "Training mini-batch number 139000\n",
      "Epoch 27: validation accuracy 97.85%\n",
      "Training mini-batch number 140000\n",
      "Training mini-batch number 141000\n",
      "Training mini-batch number 142000\n",
      "Training mini-batch number 143000\n",
      "Training mini-batch number 144000\n",
      "Epoch 28: validation accuracy 97.86%\n",
      "Training mini-batch number 145000\n",
      "Training mini-batch number 146000\n",
      "Training mini-batch number 147000\n",
      "Training mini-batch number 148000\n",
      "Training mini-batch number 149000\n",
      "Epoch 29: validation accuracy 97.84%\n",
      "Training mini-batch number 150000\n",
      "Training mini-batch number 151000\n",
      "Training mini-batch number 152000\n",
      "Training mini-batch number 153000\n",
      "Training mini-batch number 154000\n",
      "Epoch 30: validation accuracy 97.83%\n",
      "Training mini-batch number 155000\n",
      "Training mini-batch number 156000\n",
      "Training mini-batch number 157000\n",
      "Training mini-batch number 158000\n",
      "Training mini-batch number 159000\n",
      "Epoch 31: validation accuracy 97.82%\n",
      "Training mini-batch number 160000\n",
      "Training mini-batch number 161000\n",
      "Training mini-batch number 162000\n",
      "Training mini-batch number 163000\n",
      "Training mini-batch number 164000\n",
      "Epoch 32: validation accuracy 97.82%\n",
      "Training mini-batch number 165000\n",
      "Training mini-batch number 166000\n",
      "Training mini-batch number 167000\n",
      "Training mini-batch number 168000\n",
      "Training mini-batch number 169000\n",
      "Epoch 33: validation accuracy 97.83%\n",
      "Training mini-batch number 170000\n",
      "Training mini-batch number 171000\n",
      "Training mini-batch number 172000\n",
      "Training mini-batch number 173000\n",
      "Training mini-batch number 174000\n",
      "Epoch 34: validation accuracy 97.86%\n",
      "Training mini-batch number 175000\n",
      "Training mini-batch number 176000\n",
      "Training mini-batch number 177000\n",
      "Training mini-batch number 178000\n",
      "Training mini-batch number 179000\n",
      "Epoch 35: validation accuracy 97.85%\n",
      "Training mini-batch number 180000\n",
      "Training mini-batch number 181000\n",
      "Training mini-batch number 182000\n",
      "Training mini-batch number 183000\n",
      "Training mini-batch number 184000\n",
      "Epoch 36: validation accuracy 97.85%\n",
      "Training mini-batch number 185000\n",
      "Training mini-batch number 186000\n",
      "Training mini-batch number 187000\n",
      "Training mini-batch number 188000\n",
      "Training mini-batch number 189000\n",
      "Epoch 37: validation accuracy 97.84%\n",
      "Training mini-batch number 190000\n",
      "Training mini-batch number 191000\n",
      "Training mini-batch number 192000\n",
      "Training mini-batch number 193000\n",
      "Training mini-batch number 194000\n",
      "Epoch 38: validation accuracy 97.83%\n",
      "Training mini-batch number 195000\n",
      "Training mini-batch number 196000\n",
      "Training mini-batch number 197000\n",
      "Training mini-batch number 198000\n",
      "Training mini-batch number 199000\n",
      "Epoch 39: validation accuracy 97.83%\n",
      "Training mini-batch number 200000\n",
      "Training mini-batch number 201000\n",
      "Training mini-batch number 202000\n",
      "Training mini-batch number 203000\n",
      "Training mini-batch number 204000\n",
      "Epoch 40: validation accuracy 97.86%\n",
      "Training mini-batch number 205000\n",
      "Training mini-batch number 206000\n",
      "Training mini-batch number 207000\n",
      "Training mini-batch number 208000\n",
      "Training mini-batch number 209000\n",
      "Epoch 41: validation accuracy 97.86%\n",
      "Training mini-batch number 210000\n",
      "Training mini-batch number 211000\n",
      "Training mini-batch number 212000\n",
      "Training mini-batch number 213000\n",
      "Training mini-batch number 214000\n",
      "Epoch 42: validation accuracy 97.87%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.76%\n",
      "Training mini-batch number 215000\n",
      "Training mini-batch number 216000\n",
      "Training mini-batch number 217000\n",
      "Training mini-batch number 218000\n",
      "Training mini-batch number 219000\n",
      "Epoch 43: validation accuracy 97.86%\n",
      "Training mini-batch number 220000\n",
      "Training mini-batch number 221000\n",
      "Training mini-batch number 222000\n",
      "Training mini-batch number 223000\n",
      "Training mini-batch number 224000\n",
      "Epoch 44: validation accuracy 97.85%\n",
      "Training mini-batch number 225000\n",
      "Training mini-batch number 226000\n",
      "Training mini-batch number 227000\n",
      "Training mini-batch number 228000\n",
      "Training mini-batch number 229000\n",
      "Epoch 45: validation accuracy 97.85%\n",
      "Training mini-batch number 230000\n",
      "Training mini-batch number 231000\n",
      "Training mini-batch number 232000\n",
      "Training mini-batch number 233000\n",
      "Training mini-batch number 234000\n",
      "Epoch 46: validation accuracy 97.84%\n",
      "Training mini-batch number 235000\n",
      "Training mini-batch number 236000\n",
      "Training mini-batch number 237000\n",
      "Training mini-batch number 238000\n",
      "Training mini-batch number 239000\n",
      "Epoch 47: validation accuracy 97.85%\n",
      "Training mini-batch number 240000\n",
      "Training mini-batch number 241000\n",
      "Training mini-batch number 242000\n",
      "Training mini-batch number 243000\n",
      "Training mini-batch number 244000\n",
      "Epoch 48: validation accuracy 97.85%\n",
      "Training mini-batch number 245000\n",
      "Training mini-batch number 246000\n",
      "Training mini-batch number 247000\n",
      "Training mini-batch number 248000\n",
      "Training mini-batch number 249000\n",
      "Epoch 49: validation accuracy 97.85%\n",
      "Training mini-batch number 250000\n",
      "Training mini-batch number 251000\n",
      "Training mini-batch number 252000\n",
      "Training mini-batch number 253000\n",
      "Training mini-batch number 254000\n",
      "Epoch 50: validation accuracy 97.85%\n",
      "Training mini-batch number 255000\n",
      "Training mini-batch number 256000\n",
      "Training mini-batch number 257000\n",
      "Training mini-batch number 258000\n",
      "Training mini-batch number 259000\n",
      "Epoch 51: validation accuracy 97.84%\n",
      "Training mini-batch number 260000\n",
      "Training mini-batch number 261000\n",
      "Training mini-batch number 262000\n",
      "Training mini-batch number 263000\n",
      "Training mini-batch number 264000\n",
      "Epoch 52: validation accuracy 97.84%\n",
      "Training mini-batch number 265000\n",
      "Training mini-batch number 266000\n",
      "Training mini-batch number 267000\n",
      "Training mini-batch number 268000\n",
      "Training mini-batch number 269000\n",
      "Epoch 53: validation accuracy 97.84%\n",
      "Training mini-batch number 270000\n",
      "Training mini-batch number 271000\n",
      "Training mini-batch number 272000\n",
      "Training mini-batch number 273000\n",
      "Training mini-batch number 274000\n",
      "Epoch 54: validation accuracy 97.84%\n",
      "Training mini-batch number 275000\n",
      "Training mini-batch number 276000\n",
      "Training mini-batch number 277000\n",
      "Training mini-batch number 278000\n",
      "Training mini-batch number 279000\n",
      "Epoch 55: validation accuracy 97.84%\n",
      "Training mini-batch number 280000\n",
      "Training mini-batch number 281000\n",
      "Training mini-batch number 282000\n",
      "Training mini-batch number 283000\n",
      "Training mini-batch number 284000\n",
      "Epoch 56: validation accuracy 97.82%\n",
      "Training mini-batch number 285000\n",
      "Training mini-batch number 286000\n",
      "Training mini-batch number 287000\n",
      "Training mini-batch number 288000\n",
      "Training mini-batch number 289000\n",
      "Epoch 57: validation accuracy 97.82%\n",
      "Training mini-batch number 290000\n",
      "Training mini-batch number 291000\n",
      "Training mini-batch number 292000\n",
      "Training mini-batch number 293000\n",
      "Training mini-batch number 294000\n",
      "Epoch 58: validation accuracy 97.82%\n",
      "Training mini-batch number 295000\n",
      "Training mini-batch number 296000\n",
      "Training mini-batch number 297000\n",
      "Training mini-batch number 298000\n",
      "Training mini-batch number 299000\n",
      "Epoch 59: validation accuracy 97.81%\n",
      "Finished training network.\n",
      "Best validation accuracy of 97.87% obtained at iteration 214999\n",
      "Corresponding test accuracy of 97.76%\n"
     ]
    }
   ],
   "source": [
    "training_data, validation_data, test_data = network3.load_data_shared()\n",
    "mini_batch_size = 10\n",
    "net = Network([FullyConnectedLayer(n_in=784, n_out=100), SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "net.SGD(training_data, 60, mini_batch_size, 0.1, validation_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 0\n",
      "Training mini-batch number 1000\n",
      "Training mini-batch number 2000\n",
      "Training mini-batch number 3000\n",
      "Training mini-batch number 4000\n",
      "Epoch 0: validation accuracy 94.22%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 93.67%\n",
      "Training mini-batch number 5000\n",
      "Training mini-batch number 6000\n",
      "Training mini-batch number 7000\n",
      "Training mini-batch number 8000\n",
      "Training mini-batch number 9000\n",
      "Epoch 1: validation accuracy 96.28%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 95.56%\n",
      "Training mini-batch number 10000\n",
      "Training mini-batch number 11000\n",
      "Training mini-batch number 12000\n",
      "Training mini-batch number 13000\n",
      "Training mini-batch number 14000\n",
      "Epoch 2: validation accuracy 96.96%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 96.51%\n",
      "Training mini-batch number 15000\n",
      "Training mini-batch number 16000\n",
      "Training mini-batch number 17000\n",
      "Training mini-batch number 18000\n",
      "Training mini-batch number 19000\n",
      "Epoch 3: validation accuracy 97.36%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.06%\n",
      "Training mini-batch number 20000\n",
      "Training mini-batch number 21000\n",
      "Training mini-batch number 22000\n",
      "Training mini-batch number 23000\n",
      "Training mini-batch number 24000\n",
      "Epoch 4: validation accuracy 97.60%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.40%\n",
      "Training mini-batch number 25000\n",
      "Training mini-batch number 26000\n",
      "Training mini-batch number 27000\n",
      "Training mini-batch number 28000\n",
      "Training mini-batch number 29000\n",
      "Epoch 5: validation accuracy 97.81%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.70%\n",
      "Training mini-batch number 30000\n",
      "Training mini-batch number 31000\n",
      "Training mini-batch number 32000\n",
      "Training mini-batch number 33000\n",
      "Training mini-batch number 34000\n",
      "Epoch 6: validation accuracy 98.04%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.89%\n",
      "Training mini-batch number 35000\n",
      "Training mini-batch number 36000\n",
      "Training mini-batch number 37000\n",
      "Training mini-batch number 38000\n",
      "Training mini-batch number 39000\n",
      "Epoch 7: validation accuracy 98.25%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.94%\n",
      "Training mini-batch number 40000\n",
      "Training mini-batch number 41000\n",
      "Training mini-batch number 42000\n",
      "Training mini-batch number 43000\n",
      "Training mini-batch number 44000\n",
      "Epoch 8: validation accuracy 98.33%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.09%\n",
      "Training mini-batch number 45000\n",
      "Training mini-batch number 46000\n",
      "Training mini-batch number 47000\n",
      "Training mini-batch number 48000\n",
      "Training mini-batch number 49000\n",
      "Epoch 9: validation accuracy 98.35%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.16%\n",
      "Training mini-batch number 50000\n",
      "Training mini-batch number 51000\n",
      "Training mini-batch number 52000\n",
      "Training mini-batch number 53000\n",
      "Training mini-batch number 54000\n",
      "Epoch 10: validation accuracy 98.35%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.17%\n",
      "Training mini-batch number 55000\n",
      "Training mini-batch number 56000\n",
      "Training mini-batch number 57000\n",
      "Training mini-batch number 58000\n",
      "Training mini-batch number 59000\n",
      "Epoch 11: validation accuracy 98.40%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.22%\n",
      "Training mini-batch number 60000\n",
      "Training mini-batch number 61000\n",
      "Training mini-batch number 62000\n",
      "Training mini-batch number 63000\n",
      "Training mini-batch number 64000\n",
      "Epoch 12: validation accuracy 98.42%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.32%\n",
      "Training mini-batch number 65000\n",
      "Training mini-batch number 66000\n",
      "Training mini-batch number 67000\n",
      "Training mini-batch number 68000\n",
      "Training mini-batch number 69000\n",
      "Epoch 13: validation accuracy 98.46%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.36%\n",
      "Training mini-batch number 70000\n",
      "Training mini-batch number 71000\n",
      "Training mini-batch number 72000\n",
      "Training mini-batch number 73000\n",
      "Training mini-batch number 74000\n",
      "Epoch 14: validation accuracy 98.49%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.46%\n",
      "Training mini-batch number 75000\n",
      "Training mini-batch number 76000\n",
      "Training mini-batch number 77000\n",
      "Training mini-batch number 78000\n",
      "Training mini-batch number 79000\n",
      "Epoch 15: validation accuracy 98.52%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.53%\n",
      "Training mini-batch number 80000\n",
      "Training mini-batch number 81000\n",
      "Training mini-batch number 82000\n",
      "Training mini-batch number 83000\n",
      "Training mini-batch number 84000\n",
      "Epoch 16: validation accuracy 98.51%\n",
      "Training mini-batch number 85000\n",
      "Training mini-batch number 86000\n",
      "Training mini-batch number 87000\n",
      "Training mini-batch number 88000\n",
      "Training mini-batch number 89000\n",
      "Epoch 17: validation accuracy 98.48%\n",
      "Training mini-batch number 90000\n",
      "Training mini-batch number 91000\n",
      "Training mini-batch number 92000\n",
      "Training mini-batch number 93000\n",
      "Training mini-batch number 94000\n",
      "Epoch 18: validation accuracy 98.51%\n",
      "Training mini-batch number 95000\n",
      "Training mini-batch number 96000\n",
      "Training mini-batch number 97000\n",
      "Training mini-batch number 98000\n",
      "Training mini-batch number 99000\n",
      "Epoch 19: validation accuracy 98.53%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.61%\n",
      "Training mini-batch number 100000\n",
      "Training mini-batch number 101000\n",
      "Training mini-batch number 102000\n",
      "Training mini-batch number 103000\n",
      "Training mini-batch number 104000\n",
      "Epoch 20: validation accuracy 98.53%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.62%\n",
      "Training mini-batch number 105000\n",
      "Training mini-batch number 106000\n",
      "Training mini-batch number 107000\n",
      "Training mini-batch number 108000\n",
      "Training mini-batch number 109000\n",
      "Epoch 21: validation accuracy 98.56%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.65%\n",
      "Training mini-batch number 110000\n",
      "Training mini-batch number 111000\n",
      "Training mini-batch number 112000\n",
      "Training mini-batch number 113000\n",
      "Training mini-batch number 114000\n",
      "Epoch 22: validation accuracy 98.58%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.66%\n",
      "Training mini-batch number 115000\n",
      "Training mini-batch number 116000\n",
      "Training mini-batch number 117000\n",
      "Training mini-batch number 118000\n",
      "Training mini-batch number 119000\n",
      "Epoch 23: validation accuracy 98.60%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.64%\n",
      "Training mini-batch number 120000\n",
      "Training mini-batch number 121000\n",
      "Training mini-batch number 122000\n",
      "Training mini-batch number 123000\n",
      "Training mini-batch number 124000\n",
      "Epoch 24: validation accuracy 98.61%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.63%\n",
      "Training mini-batch number 125000\n",
      "Training mini-batch number 126000\n",
      "Training mini-batch number 127000\n",
      "Training mini-batch number 128000\n",
      "Training mini-batch number 129000\n",
      "Epoch 25: validation accuracy 98.59%\n",
      "Training mini-batch number 130000\n",
      "Training mini-batch number 131000\n",
      "Training mini-batch number 132000\n",
      "Training mini-batch number 133000\n",
      "Training mini-batch number 134000\n",
      "Epoch 26: validation accuracy 98.61%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.66%\n",
      "Training mini-batch number 135000\n",
      "Training mini-batch number 136000\n",
      "Training mini-batch number 137000\n",
      "Training mini-batch number 138000\n",
      "Training mini-batch number 139000\n",
      "Epoch 27: validation accuracy 98.63%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.66%\n",
      "Training mini-batch number 140000\n",
      "Training mini-batch number 141000\n",
      "Training mini-batch number 142000\n",
      "Training mini-batch number 143000\n",
      "Training mini-batch number 144000\n",
      "Epoch 28: validation accuracy 98.62%\n",
      "Training mini-batch number 145000\n",
      "Training mini-batch number 146000\n",
      "Training mini-batch number 147000\n",
      "Training mini-batch number 148000\n",
      "Training mini-batch number 149000\n",
      "Epoch 29: validation accuracy 98.61%\n",
      "Training mini-batch number 150000\n",
      "Training mini-batch number 151000\n",
      "Training mini-batch number 152000\n",
      "Training mini-batch number 153000\n",
      "Training mini-batch number 154000\n",
      "Epoch 30: validation accuracy 98.62%\n",
      "Training mini-batch number 155000\n",
      "Training mini-batch number 156000\n",
      "Training mini-batch number 157000\n",
      "Training mini-batch number 158000\n",
      "Training mini-batch number 159000\n",
      "Epoch 31: validation accuracy 98.63%\n",
      "Training mini-batch number 160000\n",
      "Training mini-batch number 161000\n",
      "Training mini-batch number 162000\n",
      "Training mini-batch number 163000\n",
      "Training mini-batch number 164000\n",
      "Epoch 32: validation accuracy 98.65%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.63%\n",
      "Training mini-batch number 165000\n",
      "Training mini-batch number 166000\n",
      "Training mini-batch number 167000\n",
      "Training mini-batch number 168000\n",
      "Training mini-batch number 169000\n",
      "Epoch 33: validation accuracy 98.66%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.63%\n",
      "Training mini-batch number 170000\n",
      "Training mini-batch number 171000\n",
      "Training mini-batch number 172000\n",
      "Training mini-batch number 173000\n",
      "Training mini-batch number 174000\n",
      "Epoch 34: validation accuracy 98.66%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.65%\n",
      "Training mini-batch number 175000\n",
      "Training mini-batch number 176000\n",
      "Training mini-batch number 177000\n",
      "Training mini-batch number 178000\n",
      "Training mini-batch number 179000\n",
      "Epoch 35: validation accuracy 98.66%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.65%\n",
      "Training mini-batch number 180000\n",
      "Training mini-batch number 181000\n",
      "Training mini-batch number 182000\n",
      "Training mini-batch number 183000\n",
      "Training mini-batch number 184000\n",
      "Epoch 36: validation accuracy 98.66%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.65%\n",
      "Training mini-batch number 185000\n",
      "Training mini-batch number 186000\n",
      "Training mini-batch number 187000\n",
      "Training mini-batch number 188000\n",
      "Training mini-batch number 189000\n",
      "Epoch 37: validation accuracy 98.64%\n",
      "Training mini-batch number 190000\n",
      "Training mini-batch number 191000\n",
      "Training mini-batch number 192000\n",
      "Training mini-batch number 193000\n",
      "Training mini-batch number 194000\n",
      "Epoch 38: validation accuracy 98.65%\n",
      "Training mini-batch number 195000\n",
      "Training mini-batch number 196000\n",
      "Training mini-batch number 197000\n",
      "Training mini-batch number 198000\n",
      "Training mini-batch number 199000\n",
      "Epoch 39: validation accuracy 98.65%\n",
      "Training mini-batch number 200000\n",
      "Training mini-batch number 201000\n",
      "Training mini-batch number 202000\n",
      "Training mini-batch number 203000\n",
      "Training mini-batch number 204000\n",
      "Epoch 40: validation accuracy 98.65%\n",
      "Training mini-batch number 205000\n",
      "Training mini-batch number 206000\n",
      "Training mini-batch number 207000\n",
      "Training mini-batch number 208000\n",
      "Training mini-batch number 209000\n",
      "Epoch 41: validation accuracy 98.65%\n",
      "Training mini-batch number 210000\n",
      "Training mini-batch number 211000\n",
      "Training mini-batch number 212000\n",
      "Training mini-batch number 213000\n",
      "Training mini-batch number 214000\n",
      "Epoch 42: validation accuracy 98.64%\n",
      "Training mini-batch number 215000\n",
      "Training mini-batch number 216000\n",
      "Training mini-batch number 217000\n",
      "Training mini-batch number 218000\n",
      "Training mini-batch number 219000\n",
      "Epoch 43: validation accuracy 98.67%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.67%\n",
      "Training mini-batch number 220000\n",
      "Training mini-batch number 221000\n",
      "Training mini-batch number 222000\n",
      "Training mini-batch number 223000\n",
      "Training mini-batch number 224000\n",
      "Epoch 44: validation accuracy 98.68%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.66%\n",
      "Training mini-batch number 225000\n",
      "Training mini-batch number 226000\n",
      "Training mini-batch number 227000\n",
      "Training mini-batch number 228000\n",
      "Training mini-batch number 229000\n",
      "Epoch 45: validation accuracy 98.68%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.67%\n",
      "Training mini-batch number 230000\n",
      "Training mini-batch number 231000\n",
      "Training mini-batch number 232000\n",
      "Training mini-batch number 233000\n",
      "Training mini-batch number 234000\n",
      "Epoch 46: validation accuracy 98.66%\n",
      "Training mini-batch number 235000\n",
      "Training mini-batch number 236000\n",
      "Training mini-batch number 237000\n",
      "Training mini-batch number 238000\n",
      "Training mini-batch number 239000\n",
      "Epoch 47: validation accuracy 98.67%\n",
      "Training mini-batch number 240000\n",
      "Training mini-batch number 241000\n",
      "Training mini-batch number 242000\n",
      "Training mini-batch number 243000\n",
      "Training mini-batch number 244000\n",
      "Epoch 48: validation accuracy 98.67%\n",
      "Training mini-batch number 245000\n",
      "Training mini-batch number 246000\n",
      "Training mini-batch number 247000\n",
      "Training mini-batch number 248000\n",
      "Training mini-batch number 249000\n",
      "Epoch 49: validation accuracy 98.68%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.68%\n",
      "Training mini-batch number 250000\n",
      "Training mini-batch number 251000\n",
      "Training mini-batch number 252000\n",
      "Training mini-batch number 253000\n",
      "Training mini-batch number 254000\n",
      "Epoch 50: validation accuracy 98.68%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.68%\n",
      "Training mini-batch number 255000\n",
      "Training mini-batch number 256000\n",
      "Training mini-batch number 257000\n",
      "Training mini-batch number 258000\n",
      "Training mini-batch number 259000\n",
      "Epoch 51: validation accuracy 98.68%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.69%\n",
      "Training mini-batch number 260000\n",
      "Training mini-batch number 261000\n",
      "Training mini-batch number 262000\n",
      "Training mini-batch number 263000\n",
      "Training mini-batch number 264000\n",
      "Epoch 52: validation accuracy 98.67%\n",
      "Training mini-batch number 265000\n",
      "Training mini-batch number 266000\n",
      "Training mini-batch number 267000\n",
      "Training mini-batch number 268000\n",
      "Training mini-batch number 269000\n",
      "Epoch 53: validation accuracy 98.67%\n",
      "Training mini-batch number 270000\n",
      "Training mini-batch number 271000\n",
      "Training mini-batch number 272000\n",
      "Training mini-batch number 273000\n",
      "Training mini-batch number 274000\n",
      "Epoch 54: validation accuracy 98.67%\n",
      "Training mini-batch number 275000\n",
      "Training mini-batch number 276000\n",
      "Training mini-batch number 277000\n",
      "Training mini-batch number 278000\n",
      "Training mini-batch number 279000\n",
      "Epoch 55: validation accuracy 98.67%\n",
      "Training mini-batch number 280000\n",
      "Training mini-batch number 281000\n",
      "Training mini-batch number 282000\n",
      "Training mini-batch number 283000\n",
      "Training mini-batch number 284000\n",
      "Epoch 56: validation accuracy 98.67%\n",
      "Training mini-batch number 285000\n",
      "Training mini-batch number 286000\n",
      "Training mini-batch number 287000\n",
      "Training mini-batch number 288000\n",
      "Training mini-batch number 289000\n",
      "Epoch 57: validation accuracy 98.67%\n",
      "Training mini-batch number 290000\n",
      "Training mini-batch number 291000\n",
      "Training mini-batch number 292000\n",
      "Training mini-batch number 293000\n",
      "Training mini-batch number 294000\n",
      "Epoch 58: validation accuracy 98.68%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.68%\n",
      "Training mini-batch number 295000\n",
      "Training mini-batch number 296000\n",
      "Training mini-batch number 297000\n",
      "Training mini-batch number 298000\n",
      "Training mini-batch number 299000\n",
      "Epoch 59: validation accuracy 98.68%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.68%\n",
      "Finished training network.\n",
      "Best validation accuracy of 98.68% obtained at iteration 299999\n",
      "Corresponding test accuracy of 98.68%\n"
     ]
    }
   ],
   "source": [
    "# add a convolution layer use 5x5 filters, 20 features, 24x24 and a maxpooling layer \n",
    "training_data, validation_data, test_data = network3.load_data_shared()\n",
    "mini_batch_size = 10\n",
    "net = Network([\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                      filter_shape=(20, 1, 5, 5), \n",
    "                      poolsize=(2, 2)),\n",
    "        FullyConnectedLayer(n_in=20*12*12, n_out=100),\n",
    "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "net.SGD(training_data, 60, mini_batch_size, 0.1, \n",
    "            validation_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 0\n",
      "Training mini-batch number 1000\n",
      "Training mini-batch number 2000\n",
      "Training mini-batch number 3000\n",
      "Training mini-batch number 4000\n",
      "Epoch 0: validation accuracy 86.55%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 85.52%\n",
      "Training mini-batch number 5000\n",
      "Training mini-batch number 6000\n",
      "Training mini-batch number 7000\n",
      "Training mini-batch number 8000\n",
      "Training mini-batch number 9000\n",
      "Epoch 1: validation accuracy 96.50%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 96.42%\n",
      "Training mini-batch number 10000\n",
      "Training mini-batch number 11000\n",
      "Training mini-batch number 12000\n",
      "Training mini-batch number 13000\n",
      "Training mini-batch number 14000\n",
      "Epoch 2: validation accuracy 97.60%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.52%\n",
      "Training mini-batch number 15000\n",
      "Training mini-batch number 16000\n",
      "Training mini-batch number 17000\n",
      "Training mini-batch number 18000\n",
      "Training mini-batch number 19000\n",
      "Epoch 3: validation accuracy 97.98%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.91%\n",
      "Training mini-batch number 20000\n",
      "Training mini-batch number 21000\n",
      "Training mini-batch number 22000\n",
      "Training mini-batch number 23000\n",
      "Training mini-batch number 24000\n",
      "Epoch 4: validation accuracy 98.24%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.09%\n",
      "Training mini-batch number 25000\n",
      "Training mini-batch number 26000\n",
      "Training mini-batch number 27000\n",
      "Training mini-batch number 28000\n",
      "Training mini-batch number 29000\n",
      "Epoch 5: validation accuracy 98.42%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.31%\n",
      "Training mini-batch number 30000\n",
      "Training mini-batch number 31000\n",
      "Training mini-batch number 32000\n",
      "Training mini-batch number 33000\n",
      "Training mini-batch number 34000\n",
      "Epoch 6: validation accuracy 98.52%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.40%\n",
      "Training mini-batch number 35000\n",
      "Training mini-batch number 36000\n",
      "Training mini-batch number 37000\n",
      "Training mini-batch number 38000\n",
      "Training mini-batch number 39000\n",
      "Epoch 7: validation accuracy 98.60%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.50%\n",
      "Training mini-batch number 40000\n",
      "Training mini-batch number 41000\n",
      "Training mini-batch number 42000\n",
      "Training mini-batch number 43000\n",
      "Training mini-batch number 44000\n",
      "Epoch 8: validation accuracy 98.67%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.54%\n",
      "Training mini-batch number 45000\n",
      "Training mini-batch number 46000\n",
      "Training mini-batch number 47000\n",
      "Training mini-batch number 48000\n",
      "Training mini-batch number 49000\n",
      "Epoch 9: validation accuracy 98.73%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.59%\n",
      "Training mini-batch number 50000\n",
      "Training mini-batch number 51000\n",
      "Training mini-batch number 52000\n",
      "Training mini-batch number 53000\n",
      "Training mini-batch number 54000\n",
      "Epoch 10: validation accuracy 98.75%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.62%\n",
      "Training mini-batch number 55000\n",
      "Training mini-batch number 56000\n",
      "Training mini-batch number 57000\n",
      "Training mini-batch number 58000\n",
      "Training mini-batch number 59000\n",
      "Epoch 11: validation accuracy 98.81%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.64%\n",
      "Training mini-batch number 60000\n",
      "Training mini-batch number 61000\n",
      "Training mini-batch number 62000\n",
      "Training mini-batch number 63000\n",
      "Training mini-batch number 64000\n",
      "Epoch 12: validation accuracy 98.84%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.62%\n",
      "Training mini-batch number 65000\n",
      "Training mini-batch number 66000\n",
      "Training mini-batch number 67000\n",
      "Training mini-batch number 68000\n",
      "Training mini-batch number 69000\n",
      "Epoch 13: validation accuracy 98.83%\n",
      "Training mini-batch number 70000\n",
      "Training mini-batch number 71000\n",
      "Training mini-batch number 72000\n",
      "Training mini-batch number 73000\n",
      "Training mini-batch number 74000\n",
      "Epoch 14: validation accuracy 98.86%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.64%\n",
      "Training mini-batch number 75000\n",
      "Training mini-batch number 76000\n",
      "Training mini-batch number 77000\n",
      "Training mini-batch number 78000\n",
      "Training mini-batch number 79000\n",
      "Epoch 15: validation accuracy 98.86%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.69%\n",
      "Training mini-batch number 80000\n",
      "Training mini-batch number 81000\n",
      "Training mini-batch number 82000\n",
      "Training mini-batch number 83000\n",
      "Training mini-batch number 84000\n",
      "Epoch 16: validation accuracy 98.90%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.74%\n",
      "Training mini-batch number 85000\n",
      "Training mini-batch number 86000\n",
      "Training mini-batch number 87000\n",
      "Training mini-batch number 88000\n",
      "Training mini-batch number 89000\n",
      "Epoch 17: validation accuracy 98.88%\n",
      "Training mini-batch number 90000\n",
      "Training mini-batch number 91000\n",
      "Training mini-batch number 92000\n",
      "Training mini-batch number 93000\n",
      "Training mini-batch number 94000\n",
      "Epoch 18: validation accuracy 98.91%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.79%\n",
      "Training mini-batch number 95000\n",
      "Training mini-batch number 96000\n",
      "Training mini-batch number 97000\n",
      "Training mini-batch number 98000\n",
      "Training mini-batch number 99000\n",
      "Epoch 19: validation accuracy 98.92%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.79%\n",
      "Training mini-batch number 100000\n",
      "Training mini-batch number 101000\n",
      "Training mini-batch number 102000\n",
      "Training mini-batch number 103000\n",
      "Training mini-batch number 104000\n",
      "Epoch 20: validation accuracy 98.93%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.84%\n",
      "Training mini-batch number 105000\n",
      "Training mini-batch number 106000\n",
      "Training mini-batch number 107000\n",
      "Training mini-batch number 108000\n",
      "Training mini-batch number 109000\n",
      "Epoch 21: validation accuracy 98.96%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.85%\n",
      "Training mini-batch number 110000\n",
      "Training mini-batch number 111000\n",
      "Training mini-batch number 112000\n",
      "Training mini-batch number 113000\n",
      "Training mini-batch number 114000\n",
      "Epoch 22: validation accuracy 98.95%\n",
      "Training mini-batch number 115000\n",
      "Training mini-batch number 116000\n",
      "Training mini-batch number 117000\n",
      "Training mini-batch number 118000\n",
      "Training mini-batch number 119000\n",
      "Epoch 23: validation accuracy 98.99%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.85%\n",
      "Training mini-batch number 120000\n",
      "Training mini-batch number 121000\n",
      "Training mini-batch number 122000\n",
      "Training mini-batch number 123000\n",
      "Training mini-batch number 124000\n",
      "Epoch 24: validation accuracy 99.00%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.85%\n",
      "Training mini-batch number 125000\n",
      "Training mini-batch number 126000\n",
      "Training mini-batch number 127000\n",
      "Training mini-batch number 128000\n",
      "Training mini-batch number 129000\n",
      "Epoch 25: validation accuracy 99.01%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.85%\n",
      "Training mini-batch number 130000\n",
      "Training mini-batch number 131000\n",
      "Training mini-batch number 132000\n",
      "Training mini-batch number 133000\n",
      "Training mini-batch number 134000\n",
      "Epoch 26: validation accuracy 99.05%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.84%\n",
      "Training mini-batch number 135000\n",
      "Training mini-batch number 136000\n",
      "Training mini-batch number 137000\n",
      "Training mini-batch number 138000\n",
      "Training mini-batch number 139000\n",
      "Epoch 27: validation accuracy 99.06%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.85%\n",
      "Training mini-batch number 140000\n",
      "Training mini-batch number 141000\n",
      "Training mini-batch number 142000\n",
      "Training mini-batch number 143000\n",
      "Training mini-batch number 144000\n",
      "Epoch 28: validation accuracy 99.07%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.87%\n",
      "Training mini-batch number 145000\n",
      "Training mini-batch number 146000\n",
      "Training mini-batch number 147000\n",
      "Training mini-batch number 148000\n",
      "Training mini-batch number 149000\n",
      "Epoch 29: validation accuracy 99.08%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.90%\n",
      "Training mini-batch number 150000\n",
      "Training mini-batch number 151000\n",
      "Training mini-batch number 152000\n",
      "Training mini-batch number 153000\n",
      "Training mini-batch number 154000\n",
      "Epoch 30: validation accuracy 99.06%\n",
      "Training mini-batch number 155000\n",
      "Training mini-batch number 156000\n",
      "Training mini-batch number 157000\n",
      "Training mini-batch number 158000\n",
      "Training mini-batch number 159000\n",
      "Epoch 31: validation accuracy 99.06%\n",
      "Training mini-batch number 160000\n",
      "Training mini-batch number 161000\n",
      "Training mini-batch number 162000\n",
      "Training mini-batch number 163000\n",
      "Training mini-batch number 164000\n",
      "Epoch 32: validation accuracy 99.04%\n",
      "Training mini-batch number 165000\n",
      "Training mini-batch number 166000\n",
      "Training mini-batch number 167000\n",
      "Training mini-batch number 168000\n",
      "Training mini-batch number 169000\n",
      "Epoch 33: validation accuracy 99.04%\n",
      "Training mini-batch number 170000\n",
      "Training mini-batch number 171000\n",
      "Training mini-batch number 172000\n",
      "Training mini-batch number 173000\n",
      "Training mini-batch number 174000\n",
      "Epoch 34: validation accuracy 99.06%\n",
      "Training mini-batch number 175000\n",
      "Training mini-batch number 176000\n",
      "Training mini-batch number 177000\n",
      "Training mini-batch number 178000\n",
      "Training mini-batch number 179000\n",
      "Epoch 35: validation accuracy 99.06%\n",
      "Training mini-batch number 180000\n",
      "Training mini-batch number 181000\n",
      "Training mini-batch number 182000\n",
      "Training mini-batch number 183000\n",
      "Training mini-batch number 184000\n",
      "Epoch 36: validation accuracy 99.07%\n",
      "Training mini-batch number 185000\n",
      "Training mini-batch number 186000\n",
      "Training mini-batch number 187000\n",
      "Training mini-batch number 188000\n",
      "Training mini-batch number 189000\n",
      "Epoch 37: validation accuracy 99.08%\n",
      "Training mini-batch number 190000\n",
      "Training mini-batch number 191000\n",
      "Training mini-batch number 192000\n",
      "Training mini-batch number 193000\n",
      "Training mini-batch number 194000\n",
      "Epoch 38: validation accuracy 99.07%\n",
      "Training mini-batch number 195000\n",
      "Training mini-batch number 196000\n",
      "Training mini-batch number 197000\n",
      "Training mini-batch number 198000\n",
      "Training mini-batch number 199000\n",
      "Epoch 39: validation accuracy 99.06%\n",
      "Training mini-batch number 200000\n",
      "Training mini-batch number 201000\n",
      "Training mini-batch number 202000\n",
      "Training mini-batch number 203000\n",
      "Training mini-batch number 204000\n",
      "Epoch 40: validation accuracy 99.07%\n",
      "Training mini-batch number 205000\n",
      "Training mini-batch number 206000\n",
      "Training mini-batch number 207000\n",
      "Training mini-batch number 208000\n",
      "Training mini-batch number 209000\n",
      "Epoch 41: validation accuracy 99.06%\n",
      "Training mini-batch number 210000\n",
      "Training mini-batch number 211000\n",
      "Training mini-batch number 212000\n",
      "Training mini-batch number 213000\n",
      "Training mini-batch number 214000\n",
      "Epoch 42: validation accuracy 99.05%\n",
      "Training mini-batch number 215000\n",
      "Training mini-batch number 216000\n",
      "Training mini-batch number 217000\n",
      "Training mini-batch number 218000\n",
      "Training mini-batch number 219000\n",
      "Epoch 43: validation accuracy 99.05%\n",
      "Training mini-batch number 220000\n",
      "Training mini-batch number 221000\n",
      "Training mini-batch number 222000\n",
      "Training mini-batch number 223000\n",
      "Training mini-batch number 224000\n",
      "Epoch 44: validation accuracy 99.04%\n",
      "Training mini-batch number 225000\n",
      "Training mini-batch number 226000\n",
      "Training mini-batch number 227000\n",
      "Training mini-batch number 228000\n",
      "Training mini-batch number 229000\n",
      "Epoch 45: validation accuracy 99.05%\n",
      "Training mini-batch number 230000\n",
      "Training mini-batch number 231000\n",
      "Training mini-batch number 232000\n",
      "Training mini-batch number 233000\n",
      "Training mini-batch number 234000\n",
      "Epoch 46: validation accuracy 99.05%\n",
      "Training mini-batch number 235000\n",
      "Training mini-batch number 236000\n",
      "Training mini-batch number 237000\n",
      "Training mini-batch number 238000\n",
      "Training mini-batch number 239000\n",
      "Epoch 47: validation accuracy 99.06%\n",
      "Training mini-batch number 240000\n",
      "Training mini-batch number 241000\n",
      "Training mini-batch number 242000\n",
      "Training mini-batch number 243000\n",
      "Training mini-batch number 244000\n",
      "Epoch 48: validation accuracy 99.09%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.95%\n",
      "Training mini-batch number 245000\n",
      "Training mini-batch number 246000\n",
      "Training mini-batch number 247000\n",
      "Training mini-batch number 248000\n",
      "Training mini-batch number 249000\n",
      "Epoch 49: validation accuracy 99.10%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.96%\n",
      "Training mini-batch number 250000\n",
      "Training mini-batch number 251000\n",
      "Training mini-batch number 252000\n",
      "Training mini-batch number 253000\n",
      "Training mini-batch number 254000\n",
      "Epoch 50: validation accuracy 99.10%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.96%\n",
      "Training mini-batch number 255000\n",
      "Training mini-batch number 256000\n",
      "Training mini-batch number 257000\n",
      "Training mini-batch number 258000\n",
      "Training mini-batch number 259000\n",
      "Epoch 51: validation accuracy 99.09%\n",
      "Training mini-batch number 260000\n",
      "Training mini-batch number 261000\n",
      "Training mini-batch number 262000\n",
      "Training mini-batch number 263000\n",
      "Training mini-batch number 264000\n",
      "Epoch 52: validation accuracy 99.09%\n",
      "Training mini-batch number 265000\n",
      "Training mini-batch number 266000\n",
      "Training mini-batch number 267000\n",
      "Training mini-batch number 268000\n",
      "Training mini-batch number 269000\n",
      "Epoch 53: validation accuracy 99.10%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.96%\n",
      "Training mini-batch number 270000\n",
      "Training mini-batch number 271000\n",
      "Training mini-batch number 272000\n",
      "Training mini-batch number 273000\n",
      "Training mini-batch number 274000\n",
      "Epoch 54: validation accuracy 99.10%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.96%\n",
      "Training mini-batch number 275000\n",
      "Training mini-batch number 276000\n",
      "Training mini-batch number 277000\n",
      "Training mini-batch number 278000\n",
      "Training mini-batch number 279000\n",
      "Epoch 55: validation accuracy 99.10%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.97%\n",
      "Training mini-batch number 280000\n",
      "Training mini-batch number 281000\n",
      "Training mini-batch number 282000\n",
      "Training mini-batch number 283000\n",
      "Training mini-batch number 284000\n",
      "Epoch 56: validation accuracy 99.10%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.98%\n",
      "Training mini-batch number 285000\n",
      "Training mini-batch number 286000\n",
      "Training mini-batch number 287000\n",
      "Training mini-batch number 288000\n",
      "Training mini-batch number 289000\n",
      "Epoch 57: validation accuracy 99.11%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.98%\n",
      "Training mini-batch number 290000\n",
      "Training mini-batch number 291000\n",
      "Training mini-batch number 292000\n",
      "Training mini-batch number 293000\n",
      "Training mini-batch number 294000\n",
      "Epoch 58: validation accuracy 99.11%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.99%\n",
      "Training mini-batch number 295000\n",
      "Training mini-batch number 296000\n",
      "Training mini-batch number 297000\n",
      "Training mini-batch number 298000\n",
      "Training mini-batch number 299000\n",
      "Epoch 59: validation accuracy 99.11%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.97%\n",
      "Finished training network.\n",
      "Best validation accuracy of 99.11% obtained at iteration 299999\n",
      "Corresponding test accuracy of 98.97%\n"
     ]
    }
   ],
   "source": [
    "# add in a second convolution layer\n",
    "net = Network([\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                      filter_shape=(20, 1, 5, 5), \n",
    "                      poolsize=(2, 2)),\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n",
    "                      filter_shape=(40, 20, 5, 5), \n",
    "                      poolsize=(2, 2)),\n",
    "        FullyConnectedLayer(n_in=40*4*4, n_out=100),\n",
    "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "net.SGD(training_data, 60, mini_batch_size, 0.1, \n",
    "            validation_data, test_data)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 0\n",
      "Training mini-batch number 1000\n",
      "Training mini-batch number 2000\n",
      "Training mini-batch number 3000\n",
      "Training mini-batch number 4000\n",
      "Epoch 0: validation accuracy 97.32%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 96.68%\n",
      "Training mini-batch number 5000\n",
      "Training mini-batch number 6000\n",
      "Training mini-batch number 7000\n",
      "Training mini-batch number 8000\n",
      "Training mini-batch number 9000\n",
      "Epoch 1: validation accuracy 97.92%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.65%\n",
      "Training mini-batch number 10000\n",
      "Training mini-batch number 11000\n",
      "Training mini-batch number 12000\n",
      "Training mini-batch number 13000\n",
      "Training mini-batch number 14000\n",
      "Epoch 2: validation accuracy 98.14%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.17%\n",
      "Training mini-batch number 15000\n",
      "Training mini-batch number 16000\n",
      "Training mini-batch number 17000\n",
      "Training mini-batch number 18000\n",
      "Training mini-batch number 19000\n",
      "Epoch 3: validation accuracy 98.28%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.24%\n",
      "Training mini-batch number 20000\n",
      "Training mini-batch number 21000\n",
      "Training mini-batch number 22000\n",
      "Training mini-batch number 23000\n",
      "Training mini-batch number 24000\n",
      "Epoch 4: validation accuracy 98.31%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.40%\n",
      "Training mini-batch number 25000\n",
      "Training mini-batch number 26000\n",
      "Training mini-batch number 27000\n",
      "Training mini-batch number 28000\n",
      "Training mini-batch number 29000\n",
      "Epoch 5: validation accuracy 98.53%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.54%\n",
      "Training mini-batch number 30000\n",
      "Training mini-batch number 31000\n",
      "Training mini-batch number 32000\n",
      "Training mini-batch number 33000\n",
      "Training mini-batch number 34000\n",
      "Epoch 6: validation accuracy 98.47%\n",
      "Training mini-batch number 35000\n",
      "Training mini-batch number 36000\n",
      "Training mini-batch number 37000\n",
      "Training mini-batch number 38000\n",
      "Training mini-batch number 39000\n",
      "Epoch 7: validation accuracy 98.49%\n",
      "Training mini-batch number 40000\n",
      "Training mini-batch number 41000\n",
      "Training mini-batch number 42000\n",
      "Training mini-batch number 43000\n",
      "Training mini-batch number 44000\n",
      "Epoch 8: validation accuracy 98.63%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.64%\n",
      "Training mini-batch number 45000\n",
      "Training mini-batch number 46000\n",
      "Training mini-batch number 47000\n",
      "Training mini-batch number 48000\n",
      "Training mini-batch number 49000\n",
      "Epoch 9: validation accuracy 98.39%\n",
      "Training mini-batch number 50000\n",
      "Training mini-batch number 51000\n",
      "Training mini-batch number 52000\n",
      "Training mini-batch number 53000\n",
      "Training mini-batch number 54000\n",
      "Epoch 10: validation accuracy 98.67%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.78%\n",
      "Training mini-batch number 55000\n",
      "Training mini-batch number 56000\n",
      "Training mini-batch number 57000\n",
      "Training mini-batch number 58000\n",
      "Training mini-batch number 59000\n",
      "Epoch 11: validation accuracy 98.51%\n",
      "Training mini-batch number 60000\n",
      "Training mini-batch number 61000\n",
      "Training mini-batch number 62000\n",
      "Training mini-batch number 63000\n",
      "Training mini-batch number 64000\n",
      "Epoch 12: validation accuracy 98.87%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.80%\n",
      "Training mini-batch number 65000\n",
      "Training mini-batch number 66000\n",
      "Training mini-batch number 67000\n",
      "Training mini-batch number 68000\n",
      "Training mini-batch number 69000\n",
      "Epoch 13: validation accuracy 98.61%\n",
      "Training mini-batch number 70000\n",
      "Training mini-batch number 71000\n",
      "Training mini-batch number 72000\n",
      "Training mini-batch number 73000\n",
      "Training mini-batch number 74000\n",
      "Epoch 14: validation accuracy 98.75%\n",
      "Training mini-batch number 75000\n",
      "Training mini-batch number 76000\n",
      "Training mini-batch number 77000\n",
      "Training mini-batch number 78000\n",
      "Training mini-batch number 79000\n",
      "Epoch 15: validation accuracy 98.74%\n",
      "Training mini-batch number 80000\n",
      "Training mini-batch number 81000\n",
      "Training mini-batch number 82000\n",
      "Training mini-batch number 83000\n",
      "Training mini-batch number 84000\n",
      "Epoch 16: validation accuracy 98.31%\n",
      "Training mini-batch number 85000\n",
      "Training mini-batch number 86000\n",
      "Training mini-batch number 87000\n",
      "Training mini-batch number 88000\n",
      "Training mini-batch number 89000\n",
      "Epoch 17: validation accuracy 98.83%\n",
      "Training mini-batch number 90000\n",
      "Training mini-batch number 91000\n",
      "Training mini-batch number 92000\n",
      "Training mini-batch number 93000\n",
      "Training mini-batch number 94000\n",
      "Epoch 18: validation accuracy 98.59%\n",
      "Training mini-batch number 95000\n",
      "Training mini-batch number 96000\n",
      "Training mini-batch number 97000\n",
      "Training mini-batch number 98000\n",
      "Training mini-batch number 99000\n",
      "Epoch 19: validation accuracy 98.73%\n",
      "Training mini-batch number 100000\n",
      "Training mini-batch number 101000\n",
      "Training mini-batch number 102000\n",
      "Training mini-batch number 103000\n",
      "Training mini-batch number 104000\n",
      "Epoch 20: validation accuracy 98.88%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.95%\n",
      "Training mini-batch number 105000\n",
      "Training mini-batch number 106000\n",
      "Training mini-batch number 107000\n",
      "Training mini-batch number 108000\n",
      "Training mini-batch number 109000\n",
      "Epoch 21: validation accuracy 98.92%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.92%\n",
      "Training mini-batch number 110000\n",
      "Training mini-batch number 111000\n",
      "Training mini-batch number 112000\n",
      "Training mini-batch number 113000\n",
      "Training mini-batch number 114000\n",
      "Epoch 22: validation accuracy 98.77%\n",
      "Training mini-batch number 115000\n",
      "Training mini-batch number 116000\n",
      "Training mini-batch number 117000\n",
      "Training mini-batch number 118000\n",
      "Training mini-batch number 119000\n",
      "Epoch 23: validation accuracy 98.68%\n",
      "Training mini-batch number 120000\n",
      "Training mini-batch number 121000\n",
      "Training mini-batch number 122000\n",
      "Training mini-batch number 123000\n",
      "Training mini-batch number 124000\n",
      "Epoch 24: validation accuracy 98.79%\n",
      "Training mini-batch number 125000\n",
      "Training mini-batch number 126000\n",
      "Training mini-batch number 127000\n",
      "Training mini-batch number 128000\n",
      "Training mini-batch number 129000\n",
      "Epoch 25: validation accuracy 98.74%\n",
      "Training mini-batch number 130000\n",
      "Training mini-batch number 131000\n",
      "Training mini-batch number 132000\n",
      "Training mini-batch number 133000\n",
      "Training mini-batch number 134000\n",
      "Epoch 26: validation accuracy 98.90%\n",
      "Training mini-batch number 135000\n",
      "Training mini-batch number 136000\n",
      "Training mini-batch number 137000\n",
      "Training mini-batch number 138000\n",
      "Training mini-batch number 139000\n",
      "Epoch 27: validation accuracy 98.95%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.04%\n",
      "Training mini-batch number 140000\n",
      "Training mini-batch number 141000\n",
      "Training mini-batch number 142000\n",
      "Training mini-batch number 143000\n",
      "Training mini-batch number 144000\n",
      "Epoch 28: validation accuracy 99.01%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.09%\n",
      "Training mini-batch number 145000\n",
      "Training mini-batch number 146000\n",
      "Training mini-batch number 147000\n",
      "Training mini-batch number 148000\n",
      "Training mini-batch number 149000\n",
      "Epoch 29: validation accuracy 98.97%\n",
      "Training mini-batch number 150000\n",
      "Training mini-batch number 151000\n",
      "Training mini-batch number 152000\n",
      "Training mini-batch number 153000\n",
      "Training mini-batch number 154000\n",
      "Epoch 30: validation accuracy 98.95%\n",
      "Training mini-batch number 155000\n",
      "Training mini-batch number 156000\n",
      "Training mini-batch number 157000\n",
      "Training mini-batch number 158000\n",
      "Training mini-batch number 159000\n",
      "Epoch 31: validation accuracy 98.91%\n",
      "Training mini-batch number 160000\n",
      "Training mini-batch number 161000\n",
      "Training mini-batch number 162000\n",
      "Training mini-batch number 163000\n",
      "Training mini-batch number 164000\n",
      "Epoch 32: validation accuracy 98.96%\n",
      "Training mini-batch number 165000\n",
      "Training mini-batch number 166000\n",
      "Training mini-batch number 167000\n",
      "Training mini-batch number 168000\n",
      "Training mini-batch number 169000\n",
      "Epoch 33: validation accuracy 98.95%\n",
      "Training mini-batch number 170000\n",
      "Training mini-batch number 171000\n",
      "Training mini-batch number 172000\n",
      "Training mini-batch number 173000\n",
      "Training mini-batch number 174000\n",
      "Epoch 34: validation accuracy 98.99%\n",
      "Training mini-batch number 175000\n",
      "Training mini-batch number 176000\n",
      "Training mini-batch number 177000\n",
      "Training mini-batch number 178000\n",
      "Training mini-batch number 179000\n",
      "Epoch 35: validation accuracy 98.99%\n",
      "Training mini-batch number 180000\n",
      "Training mini-batch number 181000\n",
      "Training mini-batch number 182000\n",
      "Training mini-batch number 183000\n",
      "Training mini-batch number 184000\n",
      "Epoch 36: validation accuracy 98.99%\n",
      "Training mini-batch number 185000\n",
      "Training mini-batch number 186000\n",
      "Training mini-batch number 187000\n",
      "Training mini-batch number 188000\n",
      "Training mini-batch number 189000\n",
      "Epoch 37: validation accuracy 98.98%\n",
      "Training mini-batch number 190000\n",
      "Training mini-batch number 191000\n",
      "Training mini-batch number 192000\n",
      "Training mini-batch number 193000\n",
      "Training mini-batch number 194000\n",
      "Epoch 38: validation accuracy 98.97%\n",
      "Training mini-batch number 195000\n",
      "Training mini-batch number 196000\n",
      "Training mini-batch number 197000\n",
      "Training mini-batch number 198000\n",
      "Training mini-batch number 199000\n",
      "Epoch 39: validation accuracy 98.97%\n",
      "Training mini-batch number 200000\n",
      "Training mini-batch number 201000\n",
      "Training mini-batch number 202000\n",
      "Training mini-batch number 203000\n",
      "Training mini-batch number 204000\n",
      "Epoch 40: validation accuracy 98.97%\n",
      "Training mini-batch number 205000\n",
      "Training mini-batch number 206000\n",
      "Training mini-batch number 207000\n",
      "Training mini-batch number 208000\n",
      "Training mini-batch number 209000\n",
      "Epoch 41: validation accuracy 98.97%\n",
      "Training mini-batch number 210000\n",
      "Training mini-batch number 211000\n",
      "Training mini-batch number 212000\n",
      "Training mini-batch number 213000\n",
      "Training mini-batch number 214000\n",
      "Epoch 42: validation accuracy 98.98%\n",
      "Training mini-batch number 215000\n",
      "Training mini-batch number 216000\n",
      "Training mini-batch number 217000\n",
      "Training mini-batch number 218000\n",
      "Training mini-batch number 219000\n",
      "Epoch 43: validation accuracy 98.97%\n",
      "Training mini-batch number 220000\n",
      "Training mini-batch number 221000\n",
      "Training mini-batch number 222000\n",
      "Training mini-batch number 223000\n",
      "Training mini-batch number 224000\n",
      "Epoch 44: validation accuracy 98.98%\n",
      "Training mini-batch number 225000\n",
      "Training mini-batch number 226000\n",
      "Training mini-batch number 227000\n",
      "Training mini-batch number 228000\n",
      "Training mini-batch number 229000\n",
      "Epoch 45: validation accuracy 98.97%\n",
      "Training mini-batch number 230000\n",
      "Training mini-batch number 231000\n",
      "Training mini-batch number 232000\n",
      "Training mini-batch number 233000\n",
      "Training mini-batch number 234000\n",
      "Epoch 46: validation accuracy 98.98%\n",
      "Training mini-batch number 235000\n",
      "Training mini-batch number 236000\n",
      "Training mini-batch number 237000\n",
      "Training mini-batch number 238000\n",
      "Training mini-batch number 239000\n",
      "Epoch 47: validation accuracy 98.97%\n",
      "Training mini-batch number 240000\n",
      "Training mini-batch number 241000\n",
      "Training mini-batch number 242000\n",
      "Training mini-batch number 243000\n",
      "Training mini-batch number 244000\n",
      "Epoch 48: validation accuracy 98.99%\n",
      "Training mini-batch number 245000\n",
      "Training mini-batch number 246000\n",
      "Training mini-batch number 247000\n",
      "Training mini-batch number 248000\n",
      "Training mini-batch number 249000\n",
      "Epoch 49: validation accuracy 98.99%\n",
      "Training mini-batch number 250000\n",
      "Training mini-batch number 251000\n",
      "Training mini-batch number 252000\n",
      "Training mini-batch number 253000\n",
      "Training mini-batch number 254000\n",
      "Epoch 50: validation accuracy 98.99%\n",
      "Training mini-batch number 255000\n",
      "Training mini-batch number 256000\n",
      "Training mini-batch number 257000\n",
      "Training mini-batch number 258000\n",
      "Training mini-batch number 259000\n",
      "Epoch 51: validation accuracy 98.99%\n",
      "Training mini-batch number 260000\n",
      "Training mini-batch number 261000\n",
      "Training mini-batch number 262000\n",
      "Training mini-batch number 263000\n",
      "Training mini-batch number 264000\n",
      "Epoch 52: validation accuracy 99.00%\n",
      "Training mini-batch number 265000\n",
      "Training mini-batch number 266000\n",
      "Training mini-batch number 267000\n",
      "Training mini-batch number 268000\n",
      "Training mini-batch number 269000\n",
      "Epoch 53: validation accuracy 98.99%\n",
      "Training mini-batch number 270000\n",
      "Training mini-batch number 271000\n",
      "Training mini-batch number 272000\n",
      "Training mini-batch number 273000\n",
      "Training mini-batch number 274000\n",
      "Epoch 54: validation accuracy 98.98%\n",
      "Training mini-batch number 275000\n",
      "Training mini-batch number 276000\n",
      "Training mini-batch number 277000\n",
      "Training mini-batch number 278000\n",
      "Training mini-batch number 279000\n",
      "Epoch 55: validation accuracy 99.01%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.09%\n",
      "Training mini-batch number 280000\n",
      "Training mini-batch number 281000\n",
      "Training mini-batch number 282000\n",
      "Training mini-batch number 283000\n",
      "Training mini-batch number 284000\n",
      "Epoch 56: validation accuracy 99.00%\n",
      "Training mini-batch number 285000\n",
      "Training mini-batch number 286000\n",
      "Training mini-batch number 287000\n",
      "Training mini-batch number 288000\n",
      "Training mini-batch number 289000\n",
      "Epoch 57: validation accuracy 99.01%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.09%\n",
      "Training mini-batch number 290000\n",
      "Training mini-batch number 291000\n",
      "Training mini-batch number 292000\n",
      "Training mini-batch number 293000\n",
      "Training mini-batch number 294000\n",
      "Epoch 58: validation accuracy 99.00%\n",
      "Training mini-batch number 295000\n",
      "Training mini-batch number 296000\n",
      "Training mini-batch number 297000\n",
      "Training mini-batch number 298000\n",
      "Training mini-batch number 299000\n",
      "Epoch 59: validation accuracy 99.01%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.09%\n",
      "Finished training network.\n",
      "Best validation accuracy of 99.01% obtained at iteration 299999\n",
      "Corresponding test accuracy of 99.09%\n"
     ]
    }
   ],
   "source": [
    "# use rectified linear unit instead of sigmoid activation function or tanh function, achieved better accuracy\n",
    "from network3 import ReLU\n",
    "net = Network([\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                      filter_shape=(20, 1, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n",
    "                      filter_shape=(40, 20, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        FullyConnectedLayer(n_in=40*4*4, n_out=100, activation_fn=ReLU),\n",
    "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "net.SGD(training_data, 60, mini_batch_size, 0.03, \n",
    "            validation_data, test_data, lmbda=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 0\n",
      "Training mini-batch number 1000\n",
      "Training mini-batch number 2000\n",
      "Training mini-batch number 3000\n",
      "Training mini-batch number 4000\n",
      "Epoch 0: validation accuracy 97.19%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 96.89%\n",
      "Training mini-batch number 5000\n",
      "Training mini-batch number 6000\n",
      "Training mini-batch number 7000\n",
      "Training mini-batch number 8000\n",
      "Training mini-batch number 9000\n",
      "Epoch 1: validation accuracy 97.92%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.91%\n",
      "Training mini-batch number 10000\n",
      "Training mini-batch number 11000\n",
      "Training mini-batch number 12000\n",
      "Training mini-batch number 13000\n",
      "Training mini-batch number 14000\n",
      "Epoch 2: validation accuracy 98.24%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.35%\n",
      "Training mini-batch number 15000\n",
      "Training mini-batch number 16000\n",
      "Training mini-batch number 17000\n",
      "Training mini-batch number 18000\n",
      "Training mini-batch number 19000\n",
      "Epoch 3: validation accuracy 98.50%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.54%\n",
      "Training mini-batch number 20000\n",
      "Training mini-batch number 21000\n",
      "Training mini-batch number 22000\n",
      "Training mini-batch number 23000\n",
      "Training mini-batch number 24000\n",
      "Epoch 4: validation accuracy 98.58%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.67%\n",
      "Training mini-batch number 25000\n",
      "Training mini-batch number 26000\n",
      "Training mini-batch number 27000\n",
      "Training mini-batch number 28000\n",
      "Training mini-batch number 29000\n",
      "Epoch 5: validation accuracy 98.70%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.66%\n",
      "Training mini-batch number 30000\n",
      "Training mini-batch number 31000\n",
      "Training mini-batch number 32000\n",
      "Training mini-batch number 33000\n",
      "Training mini-batch number 34000\n",
      "Epoch 6: validation accuracy 98.63%\n",
      "Training mini-batch number 35000\n",
      "Training mini-batch number 36000\n",
      "Training mini-batch number 37000\n",
      "Training mini-batch number 38000\n",
      "Training mini-batch number 39000\n",
      "Epoch 7: validation accuracy 98.49%\n",
      "Training mini-batch number 40000\n",
      "Training mini-batch number 41000\n",
      "Training mini-batch number 42000\n",
      "Training mini-batch number 43000\n",
      "Training mini-batch number 44000\n",
      "Epoch 8: validation accuracy 98.35%\n",
      "Training mini-batch number 45000\n",
      "Training mini-batch number 46000\n",
      "Training mini-batch number 47000\n",
      "Training mini-batch number 48000\n",
      "Training mini-batch number 49000\n",
      "Epoch 9: validation accuracy 98.53%\n",
      "Training mini-batch number 50000\n",
      "Training mini-batch number 51000\n",
      "Training mini-batch number 52000\n",
      "Training mini-batch number 53000\n",
      "Training mini-batch number 54000\n",
      "Epoch 10: validation accuracy 98.52%\n",
      "Training mini-batch number 55000\n",
      "Training mini-batch number 56000\n",
      "Training mini-batch number 57000\n",
      "Training mini-batch number 58000\n",
      "Training mini-batch number 59000\n",
      "Epoch 11: validation accuracy 98.48%\n",
      "Training mini-batch number 60000\n",
      "Training mini-batch number 61000\n",
      "Training mini-batch number 62000\n",
      "Training mini-batch number 63000\n",
      "Training mini-batch number 64000\n",
      "Epoch 12: validation accuracy 98.70%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.70%\n",
      "Training mini-batch number 65000\n",
      "Training mini-batch number 66000\n",
      "Training mini-batch number 67000\n",
      "Training mini-batch number 68000\n",
      "Training mini-batch number 69000\n",
      "Epoch 13: validation accuracy 98.78%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.69%\n",
      "Training mini-batch number 70000\n",
      "Training mini-batch number 71000\n",
      "Training mini-batch number 72000\n",
      "Training mini-batch number 73000\n",
      "Training mini-batch number 74000\n",
      "Epoch 14: validation accuracy 98.68%\n",
      "Training mini-batch number 75000\n",
      "Training mini-batch number 76000\n",
      "Training mini-batch number 77000\n",
      "Training mini-batch number 78000\n",
      "Training mini-batch number 79000\n",
      "Epoch 15: validation accuracy 98.78%\n",
      "Training mini-batch number 80000\n",
      "Training mini-batch number 81000\n",
      "Training mini-batch number 82000\n",
      "Training mini-batch number 83000\n",
      "Training mini-batch number 84000\n",
      "Epoch 16: validation accuracy 98.65%\n",
      "Training mini-batch number 85000\n",
      "Training mini-batch number 86000\n",
      "Training mini-batch number 87000\n",
      "Training mini-batch number 88000\n",
      "Training mini-batch number 89000\n",
      "Epoch 17: validation accuracy 98.59%\n",
      "Training mini-batch number 90000\n",
      "Training mini-batch number 91000\n",
      "Training mini-batch number 92000\n",
      "Training mini-batch number 93000\n",
      "Training mini-batch number 94000\n",
      "Epoch 18: validation accuracy 98.83%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.88%\n",
      "Training mini-batch number 95000\n",
      "Training mini-batch number 96000\n",
      "Training mini-batch number 97000\n",
      "Training mini-batch number 98000\n",
      "Training mini-batch number 99000\n",
      "Epoch 19: validation accuracy 98.85%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.89%\n",
      "Training mini-batch number 100000\n",
      "Training mini-batch number 101000\n",
      "Training mini-batch number 102000\n",
      "Training mini-batch number 103000\n",
      "Training mini-batch number 104000\n",
      "Epoch 20: validation accuracy 98.82%\n",
      "Training mini-batch number 105000\n",
      "Training mini-batch number 106000\n",
      "Training mini-batch number 107000\n",
      "Training mini-batch number 108000\n",
      "Training mini-batch number 109000\n",
      "Epoch 21: validation accuracy 98.94%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.99%\n",
      "Training mini-batch number 110000\n",
      "Training mini-batch number 111000\n",
      "Training mini-batch number 112000\n",
      "Training mini-batch number 113000\n",
      "Training mini-batch number 114000\n",
      "Epoch 22: validation accuracy 98.93%\n",
      "Training mini-batch number 115000\n",
      "Training mini-batch number 116000\n",
      "Training mini-batch number 117000\n",
      "Training mini-batch number 118000\n",
      "Training mini-batch number 119000\n",
      "Epoch 23: validation accuracy 98.96%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.05%\n",
      "Training mini-batch number 120000\n",
      "Training mini-batch number 121000\n",
      "Training mini-batch number 122000\n",
      "Training mini-batch number 123000\n",
      "Training mini-batch number 124000\n",
      "Epoch 24: validation accuracy 99.00%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.06%\n",
      "Training mini-batch number 125000\n",
      "Training mini-batch number 126000\n",
      "Training mini-batch number 127000\n",
      "Training mini-batch number 128000\n",
      "Training mini-batch number 129000\n",
      "Epoch 25: validation accuracy 99.01%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.07%\n",
      "Training mini-batch number 130000\n",
      "Training mini-batch number 131000\n",
      "Training mini-batch number 132000\n",
      "Training mini-batch number 133000\n",
      "Training mini-batch number 134000\n",
      "Epoch 26: validation accuracy 99.02%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.06%\n",
      "Training mini-batch number 135000\n",
      "Training mini-batch number 136000\n",
      "Training mini-batch number 137000\n",
      "Training mini-batch number 138000\n",
      "Training mini-batch number 139000\n",
      "Epoch 27: validation accuracy 99.02%\n",
      "Training mini-batch number 140000\n",
      "Training mini-batch number 141000\n",
      "Training mini-batch number 142000\n",
      "Training mini-batch number 143000\n",
      "Training mini-batch number 144000\n",
      "Epoch 28: validation accuracy 99.02%\n",
      "Training mini-batch number 145000\n",
      "Training mini-batch number 146000\n",
      "Training mini-batch number 147000\n",
      "Training mini-batch number 148000\n",
      "Training mini-batch number 149000\n",
      "Epoch 29: validation accuracy 99.02%\n",
      "Training mini-batch number 150000\n",
      "Training mini-batch number 151000\n",
      "Training mini-batch number 152000\n",
      "Training mini-batch number 153000\n",
      "Training mini-batch number 154000\n",
      "Epoch 30: validation accuracy 99.02%\n",
      "Training mini-batch number 155000\n",
      "Training mini-batch number 156000\n",
      "Training mini-batch number 157000\n",
      "Training mini-batch number 158000\n",
      "Training mini-batch number 159000\n",
      "Epoch 31: validation accuracy 99.01%\n",
      "Training mini-batch number 160000\n",
      "Training mini-batch number 161000\n",
      "Training mini-batch number 162000\n",
      "Training mini-batch number 163000\n",
      "Training mini-batch number 164000\n",
      "Epoch 32: validation accuracy 99.00%\n",
      "Training mini-batch number 165000\n",
      "Training mini-batch number 166000\n",
      "Training mini-batch number 167000\n",
      "Training mini-batch number 168000\n",
      "Training mini-batch number 169000\n",
      "Epoch 33: validation accuracy 99.00%\n",
      "Training mini-batch number 170000\n",
      "Training mini-batch number 171000\n",
      "Training mini-batch number 172000\n",
      "Training mini-batch number 173000\n",
      "Training mini-batch number 174000\n",
      "Epoch 34: validation accuracy 99.00%\n",
      "Training mini-batch number 175000\n",
      "Training mini-batch number 176000\n",
      "Training mini-batch number 177000\n",
      "Training mini-batch number 178000\n",
      "Training mini-batch number 179000\n",
      "Epoch 35: validation accuracy 99.00%\n",
      "Training mini-batch number 180000\n",
      "Training mini-batch number 181000\n",
      "Training mini-batch number 182000\n",
      "Training mini-batch number 183000\n",
      "Training mini-batch number 184000\n",
      "Epoch 36: validation accuracy 98.99%\n",
      "Training mini-batch number 185000\n",
      "Training mini-batch number 186000\n",
      "Training mini-batch number 187000\n",
      "Training mini-batch number 188000\n",
      "Training mini-batch number 189000\n",
      "Epoch 37: validation accuracy 99.00%\n",
      "Training mini-batch number 190000\n",
      "Training mini-batch number 191000\n",
      "Training mini-batch number 192000\n",
      "Training mini-batch number 193000\n",
      "Training mini-batch number 194000\n",
      "Epoch 38: validation accuracy 99.00%\n",
      "Training mini-batch number 195000\n",
      "Training mini-batch number 196000\n",
      "Training mini-batch number 197000\n",
      "Training mini-batch number 198000\n",
      "Training mini-batch number 199000\n",
      "Epoch 39: validation accuracy 99.01%\n",
      "Training mini-batch number 200000\n",
      "Training mini-batch number 201000\n",
      "Training mini-batch number 202000\n",
      "Training mini-batch number 203000\n",
      "Training mini-batch number 204000\n",
      "Epoch 40: validation accuracy 99.00%\n",
      "Training mini-batch number 205000\n",
      "Training mini-batch number 206000\n",
      "Training mini-batch number 207000\n",
      "Training mini-batch number 208000\n",
      "Training mini-batch number 209000\n",
      "Epoch 41: validation accuracy 99.01%\n",
      "Training mini-batch number 210000\n",
      "Training mini-batch number 211000\n",
      "Training mini-batch number 212000\n",
      "Training mini-batch number 213000\n",
      "Training mini-batch number 214000\n",
      "Epoch 42: validation accuracy 99.01%\n",
      "Training mini-batch number 215000\n",
      "Training mini-batch number 216000\n",
      "Training mini-batch number 217000\n",
      "Training mini-batch number 218000\n",
      "Training mini-batch number 219000\n",
      "Epoch 43: validation accuracy 99.02%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.10%\n",
      "Training mini-batch number 220000\n",
      "Training mini-batch number 221000\n",
      "Training mini-batch number 222000\n",
      "Training mini-batch number 223000\n",
      "Training mini-batch number 224000\n",
      "Epoch 44: validation accuracy 99.02%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.08%\n",
      "Training mini-batch number 225000\n",
      "Training mini-batch number 226000\n",
      "Training mini-batch number 227000\n",
      "Training mini-batch number 228000\n",
      "Training mini-batch number 229000\n",
      "Epoch 45: validation accuracy 99.01%\n",
      "Training mini-batch number 230000\n",
      "Training mini-batch number 231000\n",
      "Training mini-batch number 232000\n",
      "Training mini-batch number 233000\n",
      "Training mini-batch number 234000\n",
      "Epoch 46: validation accuracy 99.02%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.08%\n",
      "Training mini-batch number 235000\n",
      "Training mini-batch number 236000\n",
      "Training mini-batch number 237000\n",
      "Training mini-batch number 238000\n",
      "Training mini-batch number 239000\n",
      "Epoch 47: validation accuracy 99.02%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.08%\n",
      "Training mini-batch number 240000\n",
      "Training mini-batch number 241000\n",
      "Training mini-batch number 242000\n",
      "Training mini-batch number 243000\n",
      "Training mini-batch number 244000\n",
      "Epoch 48: validation accuracy 99.02%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.07%\n",
      "Training mini-batch number 245000\n",
      "Training mini-batch number 246000\n",
      "Training mini-batch number 247000\n",
      "Training mini-batch number 248000\n",
      "Training mini-batch number 249000\n",
      "Epoch 49: validation accuracy 99.02%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.07%\n",
      "Training mini-batch number 250000\n",
      "Training mini-batch number 251000\n",
      "Training mini-batch number 252000\n",
      "Training mini-batch number 253000\n",
      "Training mini-batch number 254000\n",
      "Epoch 50: validation accuracy 99.01%\n",
      "Training mini-batch number 255000\n",
      "Training mini-batch number 256000\n",
      "Training mini-batch number 257000\n",
      "Training mini-batch number 258000\n",
      "Training mini-batch number 259000\n",
      "Epoch 51: validation accuracy 99.02%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.07%\n",
      "Training mini-batch number 260000\n",
      "Training mini-batch number 261000\n",
      "Training mini-batch number 262000\n",
      "Training mini-batch number 263000\n",
      "Training mini-batch number 264000\n",
      "Epoch 52: validation accuracy 99.02%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.08%\n",
      "Training mini-batch number 265000\n",
      "Training mini-batch number 266000\n",
      "Training mini-batch number 267000\n",
      "Training mini-batch number 268000\n",
      "Training mini-batch number 269000\n",
      "Epoch 53: validation accuracy 99.03%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.08%\n",
      "Training mini-batch number 270000\n",
      "Training mini-batch number 271000\n",
      "Training mini-batch number 272000\n",
      "Training mini-batch number 273000\n",
      "Training mini-batch number 274000\n",
      "Epoch 54: validation accuracy 99.02%\n",
      "Training mini-batch number 275000\n",
      "Training mini-batch number 276000\n",
      "Training mini-batch number 277000\n",
      "Training mini-batch number 278000\n",
      "Training mini-batch number 279000\n",
      "Epoch 55: validation accuracy 99.03%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.07%\n",
      "Training mini-batch number 280000\n",
      "Training mini-batch number 281000\n",
      "Training mini-batch number 282000\n",
      "Training mini-batch number 283000\n",
      "Training mini-batch number 284000\n",
      "Epoch 56: validation accuracy 99.03%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.06%\n",
      "Training mini-batch number 285000\n",
      "Training mini-batch number 286000\n",
      "Training mini-batch number 287000\n",
      "Training mini-batch number 288000\n",
      "Training mini-batch number 289000\n",
      "Epoch 57: validation accuracy 99.03%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.06%\n",
      "Training mini-batch number 290000\n",
      "Training mini-batch number 291000\n",
      "Training mini-batch number 292000\n",
      "Training mini-batch number 293000\n",
      "Training mini-batch number 294000\n",
      "Epoch 58: validation accuracy 99.03%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.06%\n",
      "Training mini-batch number 295000\n",
      "Training mini-batch number 296000\n",
      "Training mini-batch number 297000\n",
      "Training mini-batch number 298000\n",
      "Training mini-batch number 299000\n",
      "Epoch 59: validation accuracy 99.03%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.06%\n",
      "Finished training network.\n",
      "Best validation accuracy of 99.03% obtained at iteration 299999\n",
      "Corresponding test accuracy of 99.06%\n"
     ]
    }
   ],
   "source": [
    "f = '/projects/trans_scratch/validations/workspace/szong/deep_learning/neural-networks-and-deep-learning/data/mnist.pkl.gz'\n",
    "mini_batch_size = 10\n",
    "expanded_training_data, _, _ = network3.load_data_shared(f)\n",
    "net = Network([\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                      filter_shape=(20, 1, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n",
    "                      filter_shape=(40, 20, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        FullyConnectedLayer(n_in=40*4*4, n_out=100, activation_fn=ReLU),\n",
    "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "net.SGD(expanded_training_data, 60, mini_batch_size, 0.03, \n",
    "            validation_data, test_data, lmbda=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 0\n",
      "Training mini-batch number 1000\n",
      "Training mini-batch number 2000\n",
      "Training mini-batch number 3000\n",
      "Training mini-batch number 4000\n",
      "Epoch 0: validation accuracy 97.73%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.48%\n",
      "Training mini-batch number 5000\n",
      "Training mini-batch number 6000\n",
      "Training mini-batch number 7000\n",
      "Training mini-batch number 8000\n",
      "Training mini-batch number 9000\n",
      "Epoch 1: validation accuracy 98.14%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.04%\n",
      "Training mini-batch number 10000\n",
      "Training mini-batch number 11000\n",
      "Training mini-batch number 12000\n",
      "Training mini-batch number 13000\n",
      "Training mini-batch number 14000\n",
      "Epoch 2: validation accuracy 98.45%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.53%\n",
      "Training mini-batch number 15000\n",
      "Training mini-batch number 16000\n",
      "Training mini-batch number 17000\n",
      "Training mini-batch number 18000\n",
      "Training mini-batch number 19000\n",
      "Epoch 3: validation accuracy 98.63%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.50%\n",
      "Training mini-batch number 20000\n",
      "Training mini-batch number 21000\n",
      "Training mini-batch number 22000\n",
      "Training mini-batch number 23000\n",
      "Training mini-batch number 24000\n",
      "Epoch 4: validation accuracy 98.74%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.81%\n",
      "Training mini-batch number 25000\n",
      "Training mini-batch number 26000\n",
      "Training mini-batch number 27000\n",
      "Training mini-batch number 28000\n",
      "Training mini-batch number 29000\n",
      "Epoch 5: validation accuracy 98.51%\n",
      "Training mini-batch number 30000\n",
      "Training mini-batch number 31000\n",
      "Training mini-batch number 32000\n",
      "Training mini-batch number 33000\n",
      "Training mini-batch number 34000\n",
      "Epoch 6: validation accuracy 98.60%\n",
      "Training mini-batch number 35000\n",
      "Training mini-batch number 36000\n",
      "Training mini-batch number 37000\n",
      "Training mini-batch number 38000\n",
      "Training mini-batch number 39000\n",
      "Epoch 7: validation accuracy 98.84%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.76%\n",
      "Training mini-batch number 40000\n",
      "Training mini-batch number 41000\n",
      "Training mini-batch number 42000\n",
      "Training mini-batch number 43000\n",
      "Training mini-batch number 44000\n",
      "Epoch 8: validation accuracy 98.89%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.86%\n",
      "Training mini-batch number 45000\n",
      "Training mini-batch number 46000\n",
      "Training mini-batch number 47000\n",
      "Training mini-batch number 48000\n",
      "Training mini-batch number 49000\n",
      "Epoch 9: validation accuracy 98.84%\n",
      "Training mini-batch number 50000\n",
      "Training mini-batch number 51000\n",
      "Training mini-batch number 52000\n",
      "Training mini-batch number 53000\n",
      "Training mini-batch number 54000\n",
      "Epoch 10: validation accuracy 98.73%\n",
      "Training mini-batch number 55000\n",
      "Training mini-batch number 56000\n",
      "Training mini-batch number 57000\n",
      "Training mini-batch number 58000\n",
      "Training mini-batch number 59000\n",
      "Epoch 11: validation accuracy 98.88%\n",
      "Training mini-batch number 60000\n",
      "Training mini-batch number 61000\n",
      "Training mini-batch number 62000\n",
      "Training mini-batch number 63000\n",
      "Training mini-batch number 64000\n",
      "Epoch 12: validation accuracy 98.37%\n",
      "Training mini-batch number 65000\n",
      "Training mini-batch number 66000\n",
      "Training mini-batch number 67000\n",
      "Training mini-batch number 68000\n",
      "Training mini-batch number 69000\n",
      "Epoch 13: validation accuracy 98.83%\n",
      "Training mini-batch number 70000\n",
      "Training mini-batch number 71000\n",
      "Training mini-batch number 72000\n",
      "Training mini-batch number 73000\n",
      "Training mini-batch number 74000\n",
      "Epoch 14: validation accuracy 98.83%\n",
      "Training mini-batch number 75000\n",
      "Training mini-batch number 76000\n",
      "Training mini-batch number 77000\n",
      "Training mini-batch number 78000\n",
      "Training mini-batch number 79000\n",
      "Epoch 15: validation accuracy 98.80%\n",
      "Training mini-batch number 80000\n",
      "Training mini-batch number 81000\n",
      "Training mini-batch number 82000\n",
      "Training mini-batch number 83000\n",
      "Training mini-batch number 84000\n",
      "Epoch 16: validation accuracy 98.74%\n",
      "Training mini-batch number 85000\n",
      "Training mini-batch number 86000\n",
      "Training mini-batch number 87000\n",
      "Training mini-batch number 88000\n",
      "Training mini-batch number 89000\n",
      "Epoch 17: validation accuracy 98.64%\n",
      "Training mini-batch number 90000\n",
      "Training mini-batch number 91000\n",
      "Training mini-batch number 92000\n",
      "Training mini-batch number 93000\n",
      "Training mini-batch number 94000\n",
      "Epoch 18: validation accuracy 98.87%\n",
      "Training mini-batch number 95000\n",
      "Training mini-batch number 96000\n",
      "Training mini-batch number 97000\n",
      "Training mini-batch number 98000\n",
      "Training mini-batch number 99000\n",
      "Epoch 19: validation accuracy 98.84%\n",
      "Training mini-batch number 100000\n",
      "Training mini-batch number 101000\n",
      "Training mini-batch number 102000\n",
      "Training mini-batch number 103000\n",
      "Training mini-batch number 104000\n",
      "Epoch 20: validation accuracy 98.78%\n",
      "Training mini-batch number 105000\n",
      "Training mini-batch number 106000\n",
      "Training mini-batch number 107000\n",
      "Training mini-batch number 108000\n",
      "Training mini-batch number 109000\n",
      "Epoch 21: validation accuracy 98.75%\n",
      "Training mini-batch number 110000\n",
      "Training mini-batch number 111000\n",
      "Training mini-batch number 112000\n",
      "Training mini-batch number 113000\n",
      "Training mini-batch number 114000\n",
      "Epoch 22: validation accuracy 98.91%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.89%\n",
      "Training mini-batch number 115000\n",
      "Training mini-batch number 116000\n",
      "Training mini-batch number 117000\n",
      "Training mini-batch number 118000\n",
      "Training mini-batch number 119000\n",
      "Epoch 23: validation accuracy 98.88%\n",
      "Training mini-batch number 120000\n",
      "Training mini-batch number 121000\n",
      "Training mini-batch number 122000\n",
      "Training mini-batch number 123000\n",
      "Training mini-batch number 124000\n",
      "Epoch 24: validation accuracy 98.82%\n",
      "Training mini-batch number 125000\n",
      "Training mini-batch number 126000\n",
      "Training mini-batch number 127000\n",
      "Training mini-batch number 128000\n",
      "Training mini-batch number 129000\n",
      "Epoch 25: validation accuracy 98.89%\n",
      "Training mini-batch number 130000\n",
      "Training mini-batch number 131000\n",
      "Training mini-batch number 132000\n",
      "Training mini-batch number 133000\n",
      "Training mini-batch number 134000\n",
      "Epoch 26: validation accuracy 99.03%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.17%\n",
      "Training mini-batch number 135000\n",
      "Training mini-batch number 136000\n",
      "Training mini-batch number 137000\n",
      "Training mini-batch number 138000\n",
      "Training mini-batch number 139000\n",
      "Epoch 27: validation accuracy 99.05%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.18%\n",
      "Training mini-batch number 140000\n",
      "Training mini-batch number 141000\n",
      "Training mini-batch number 142000\n",
      "Training mini-batch number 143000\n",
      "Training mini-batch number 144000\n",
      "Epoch 28: validation accuracy 99.09%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.23%\n",
      "Training mini-batch number 145000\n",
      "Training mini-batch number 146000\n",
      "Training mini-batch number 147000\n",
      "Training mini-batch number 148000\n",
      "Training mini-batch number 149000\n",
      "Epoch 29: validation accuracy 99.10%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.25%\n",
      "Training mini-batch number 150000\n",
      "Training mini-batch number 151000\n",
      "Training mini-batch number 152000\n",
      "Training mini-batch number 153000\n",
      "Training mini-batch number 154000\n",
      "Epoch 30: validation accuracy 99.10%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.25%\n",
      "Training mini-batch number 155000\n",
      "Training mini-batch number 156000\n",
      "Training mini-batch number 157000\n",
      "Training mini-batch number 158000\n",
      "Training mini-batch number 159000\n",
      "Epoch 31: validation accuracy 99.10%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.27%\n",
      "Training mini-batch number 160000\n",
      "Training mini-batch number 161000\n",
      "Training mini-batch number 162000\n",
      "Training mini-batch number 163000\n",
      "Training mini-batch number 164000\n",
      "Epoch 32: validation accuracy 99.09%\n",
      "Training mini-batch number 165000\n",
      "Training mini-batch number 166000\n",
      "Training mini-batch number 167000\n",
      "Training mini-batch number 168000\n",
      "Training mini-batch number 169000\n",
      "Epoch 33: validation accuracy 99.11%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.28%\n",
      "Training mini-batch number 170000\n",
      "Training mini-batch number 171000\n",
      "Training mini-batch number 172000\n",
      "Training mini-batch number 173000\n",
      "Training mini-batch number 174000\n",
      "Epoch 34: validation accuracy 99.12%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.29%\n",
      "Training mini-batch number 175000\n",
      "Training mini-batch number 176000\n",
      "Training mini-batch number 177000\n",
      "Training mini-batch number 178000\n",
      "Training mini-batch number 179000\n",
      "Epoch 35: validation accuracy 99.12%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.29%\n",
      "Training mini-batch number 180000\n",
      "Training mini-batch number 181000\n",
      "Training mini-batch number 182000\n",
      "Training mini-batch number 183000\n",
      "Training mini-batch number 184000\n",
      "Epoch 36: validation accuracy 99.11%\n",
      "Training mini-batch number 185000\n",
      "Training mini-batch number 186000\n",
      "Training mini-batch number 187000\n",
      "Training mini-batch number 188000\n",
      "Training mini-batch number 189000\n",
      "Epoch 37: validation accuracy 99.12%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.25%\n",
      "Training mini-batch number 190000\n",
      "Training mini-batch number 191000\n",
      "Training mini-batch number 192000\n",
      "Training mini-batch number 193000\n",
      "Training mini-batch number 194000\n",
      "Epoch 38: validation accuracy 99.13%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.25%\n",
      "Training mini-batch number 195000\n",
      "Training mini-batch number 196000\n",
      "Training mini-batch number 197000\n",
      "Training mini-batch number 198000\n",
      "Training mini-batch number 199000\n",
      "Epoch 39: validation accuracy 99.13%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.24%\n",
      "Training mini-batch number 200000\n",
      "Training mini-batch number 201000\n",
      "Training mini-batch number 202000\n",
      "Training mini-batch number 203000\n",
      "Training mini-batch number 204000\n",
      "Epoch 40: validation accuracy 99.13%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.25%\n",
      "Training mini-batch number 205000\n",
      "Training mini-batch number 206000\n",
      "Training mini-batch number 207000\n",
      "Training mini-batch number 208000\n",
      "Training mini-batch number 209000\n",
      "Epoch 41: validation accuracy 99.12%\n",
      "Training mini-batch number 210000\n",
      "Training mini-batch number 211000\n",
      "Training mini-batch number 212000\n",
      "Training mini-batch number 213000\n",
      "Training mini-batch number 214000\n",
      "Epoch 42: validation accuracy 99.12%\n",
      "Training mini-batch number 215000\n",
      "Training mini-batch number 216000\n",
      "Training mini-batch number 217000\n",
      "Training mini-batch number 218000\n",
      "Training mini-batch number 219000\n",
      "Epoch 43: validation accuracy 99.13%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.27%\n",
      "Training mini-batch number 220000\n",
      "Training mini-batch number 221000\n",
      "Training mini-batch number 222000\n",
      "Training mini-batch number 223000\n",
      "Training mini-batch number 224000\n",
      "Epoch 44: validation accuracy 99.13%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.27%\n",
      "Training mini-batch number 225000\n",
      "Training mini-batch number 226000\n",
      "Training mini-batch number 227000\n",
      "Training mini-batch number 228000\n",
      "Training mini-batch number 229000\n",
      "Epoch 45: validation accuracy 99.12%\n",
      "Training mini-batch number 230000\n",
      "Training mini-batch number 231000\n",
      "Training mini-batch number 232000\n",
      "Training mini-batch number 233000\n",
      "Training mini-batch number 234000\n",
      "Epoch 46: validation accuracy 99.12%\n",
      "Training mini-batch number 235000\n",
      "Training mini-batch number 236000\n",
      "Training mini-batch number 237000\n",
      "Training mini-batch number 238000\n",
      "Training mini-batch number 239000\n",
      "Epoch 47: validation accuracy 99.12%\n",
      "Training mini-batch number 240000\n",
      "Training mini-batch number 241000\n",
      "Training mini-batch number 242000\n",
      "Training mini-batch number 243000\n",
      "Training mini-batch number 244000\n",
      "Epoch 48: validation accuracy 99.12%\n",
      "Training mini-batch number 245000\n",
      "Training mini-batch number 246000\n",
      "Training mini-batch number 247000\n",
      "Training mini-batch number 248000\n",
      "Training mini-batch number 249000\n",
      "Epoch 49: validation accuracy 99.12%\n",
      "Training mini-batch number 250000\n",
      "Training mini-batch number 251000\n",
      "Training mini-batch number 252000\n",
      "Training mini-batch number 253000\n",
      "Training mini-batch number 254000\n",
      "Epoch 50: validation accuracy 99.12%\n",
      "Training mini-batch number 255000\n",
      "Training mini-batch number 256000\n",
      "Training mini-batch number 257000\n",
      "Training mini-batch number 258000\n",
      "Training mini-batch number 259000\n",
      "Epoch 51: validation accuracy 99.13%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.28%\n",
      "Training mini-batch number 260000\n",
      "Training mini-batch number 261000\n",
      "Training mini-batch number 262000\n",
      "Training mini-batch number 263000\n",
      "Training mini-batch number 264000\n",
      "Epoch 52: validation accuracy 99.13%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.28%\n",
      "Training mini-batch number 265000\n",
      "Training mini-batch number 266000\n",
      "Training mini-batch number 267000\n",
      "Training mini-batch number 268000\n",
      "Training mini-batch number 269000\n",
      "Epoch 53: validation accuracy 99.12%\n",
      "Training mini-batch number 270000\n",
      "Training mini-batch number 271000\n",
      "Training mini-batch number 272000\n",
      "Training mini-batch number 273000\n",
      "Training mini-batch number 274000\n",
      "Epoch 54: validation accuracy 99.12%\n",
      "Training mini-batch number 275000\n",
      "Training mini-batch number 276000\n",
      "Training mini-batch number 277000\n",
      "Training mini-batch number 278000\n",
      "Training mini-batch number 279000\n",
      "Epoch 55: validation accuracy 99.13%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.28%\n",
      "Training mini-batch number 280000\n",
      "Training mini-batch number 281000\n",
      "Training mini-batch number 282000\n",
      "Training mini-batch number 283000\n",
      "Training mini-batch number 284000\n",
      "Epoch 56: validation accuracy 99.13%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.28%\n",
      "Training mini-batch number 285000\n",
      "Training mini-batch number 286000\n",
      "Training mini-batch number 287000\n",
      "Training mini-batch number 288000\n",
      "Training mini-batch number 289000\n",
      "Epoch 57: validation accuracy 99.13%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.28%\n",
      "Training mini-batch number 290000\n",
      "Training mini-batch number 291000\n",
      "Training mini-batch number 292000\n",
      "Training mini-batch number 293000\n",
      "Training mini-batch number 294000\n",
      "Epoch 58: validation accuracy 99.13%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.29%\n",
      "Training mini-batch number 295000\n",
      "Training mini-batch number 296000\n",
      "Training mini-batch number 297000\n",
      "Training mini-batch number 298000\n",
      "Training mini-batch number 299000\n",
      "Epoch 59: validation accuracy 99.14%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.29%\n",
      "Finished training network.\n",
      "Best validation accuracy of 99.14% obtained at iteration 299999\n",
      "Corresponding test accuracy of 99.29%\n",
      "Training mini-batch number 0\n",
      "Training mini-batch number 1000\n",
      "Training mini-batch number 2000\n",
      "Training mini-batch number 3000\n",
      "Training mini-batch number 4000\n",
      "Epoch 0: validation accuracy 99.14%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.29%\n",
      "Training mini-batch number 5000\n",
      "Training mini-batch number 6000\n",
      "Training mini-batch number 7000\n",
      "Training mini-batch number 8000\n",
      "Training mini-batch number 9000\n",
      "Epoch 1: validation accuracy 99.13%\n",
      "Training mini-batch number 10000\n",
      "Training mini-batch number 11000\n",
      "Training mini-batch number 12000\n",
      "Training mini-batch number 13000\n",
      "Training mini-batch number 14000\n",
      "Epoch 2: validation accuracy 99.14%\n",
      "Training mini-batch number 15000\n",
      "Training mini-batch number 16000\n",
      "Training mini-batch number 17000\n",
      "Training mini-batch number 18000\n",
      "Training mini-batch number 19000\n",
      "Epoch 3: validation accuracy 99.14%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.29%\n",
      "Training mini-batch number 20000\n",
      "Training mini-batch number 21000\n",
      "Training mini-batch number 22000\n",
      "Training mini-batch number 23000\n",
      "Training mini-batch number 24000\n",
      "Epoch 4: validation accuracy 99.14%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.29%\n",
      "Training mini-batch number 25000\n",
      "Training mini-batch number 26000\n",
      "Training mini-batch number 27000\n",
      "Training mini-batch number 28000\n",
      "Training mini-batch number 29000\n",
      "Epoch 5: validation accuracy 99.14%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.29%\n",
      "Training mini-batch number 30000\n",
      "Training mini-batch number 31000\n",
      "Training mini-batch number 32000\n",
      "Training mini-batch number 33000\n",
      "Training mini-batch number 34000\n",
      "Epoch 6: validation accuracy 99.14%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.28%\n",
      "Training mini-batch number 35000\n",
      "Training mini-batch number 36000\n",
      "Training mini-batch number 37000\n",
      "Training mini-batch number 38000\n",
      "Training mini-batch number 39000\n",
      "Epoch 7: validation accuracy 99.15%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.28%\n",
      "Training mini-batch number 40000\n",
      "Training mini-batch number 41000\n",
      "Training mini-batch number 42000\n",
      "Training mini-batch number 43000\n",
      "Training mini-batch number 44000\n",
      "Epoch 8: validation accuracy 99.15%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.28%\n",
      "Training mini-batch number 45000\n",
      "Training mini-batch number 46000\n",
      "Training mini-batch number 47000\n",
      "Training mini-batch number 48000\n",
      "Training mini-batch number 49000\n",
      "Epoch 9: validation accuracy 99.14%\n",
      "Training mini-batch number 50000\n",
      "Training mini-batch number 51000\n",
      "Training mini-batch number 52000\n",
      "Training mini-batch number 53000\n",
      "Training mini-batch number 54000\n",
      "Epoch 10: validation accuracy 99.14%\n",
      "Training mini-batch number 55000\n",
      "Training mini-batch number 56000\n",
      "Training mini-batch number 57000\n",
      "Training mini-batch number 58000\n",
      "Training mini-batch number 59000\n",
      "Epoch 11: validation accuracy 99.14%\n",
      "Training mini-batch number 60000\n",
      "Training mini-batch number 61000\n",
      "Training mini-batch number 62000\n",
      "Training mini-batch number 63000\n",
      "Training mini-batch number 64000\n",
      "Epoch 12: validation accuracy 99.14%\n",
      "Training mini-batch number 65000\n",
      "Training mini-batch number 66000\n",
      "Training mini-batch number 67000\n",
      "Training mini-batch number 68000\n",
      "Training mini-batch number 69000\n",
      "Epoch 13: validation accuracy 99.15%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.26%\n",
      "Training mini-batch number 70000\n",
      "Training mini-batch number 71000\n",
      "Training mini-batch number 72000\n",
      "Training mini-batch number 73000\n",
      "Training mini-batch number 74000\n",
      "Epoch 14: validation accuracy 99.15%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.26%\n",
      "Training mini-batch number 75000\n",
      "Training mini-batch number 76000\n",
      "Training mini-batch number 77000\n",
      "Training mini-batch number 78000\n",
      "Training mini-batch number 79000\n",
      "Epoch 15: validation accuracy 99.15%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.25%\n",
      "Training mini-batch number 80000\n",
      "Training mini-batch number 81000\n",
      "Training mini-batch number 82000\n",
      "Training mini-batch number 83000\n",
      "Training mini-batch number 84000\n",
      "Epoch 16: validation accuracy 99.15%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.25%\n",
      "Training mini-batch number 85000\n",
      "Training mini-batch number 86000\n",
      "Training mini-batch number 87000\n",
      "Training mini-batch number 88000\n",
      "Training mini-batch number 89000\n",
      "Epoch 17: validation accuracy 99.15%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.25%\n",
      "Training mini-batch number 90000\n",
      "Training mini-batch number 91000\n",
      "Training mini-batch number 92000\n",
      "Training mini-batch number 93000\n",
      "Training mini-batch number 94000\n",
      "Epoch 18: validation accuracy 99.15%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.25%\n",
      "Training mini-batch number 95000\n",
      "Training mini-batch number 96000\n",
      "Training mini-batch number 97000\n",
      "Training mini-batch number 98000\n",
      "Training mini-batch number 99000\n",
      "Epoch 19: validation accuracy 99.15%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.25%\n",
      "Training mini-batch number 100000\n",
      "Training mini-batch number 101000\n",
      "Training mini-batch number 102000\n",
      "Training mini-batch number 103000\n",
      "Training mini-batch number 104000\n",
      "Epoch 20: validation accuracy 99.16%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.25%\n",
      "Training mini-batch number 105000\n",
      "Training mini-batch number 106000\n",
      "Training mini-batch number 107000\n",
      "Training mini-batch number 108000\n",
      "Training mini-batch number 109000\n",
      "Epoch 21: validation accuracy 99.17%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.25%\n",
      "Training mini-batch number 110000\n",
      "Training mini-batch number 111000\n",
      "Training mini-batch number 112000\n",
      "Training mini-batch number 113000\n",
      "Training mini-batch number 114000\n",
      "Epoch 22: validation accuracy 99.17%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.25%\n",
      "Training mini-batch number 115000\n",
      "Training mini-batch number 116000\n",
      "Training mini-batch number 117000\n",
      "Training mini-batch number 118000\n",
      "Training mini-batch number 119000\n",
      "Epoch 23: validation accuracy 99.18%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.26%\n",
      "Training mini-batch number 120000\n",
      "Training mini-batch number 121000\n",
      "Training mini-batch number 122000\n",
      "Training mini-batch number 123000\n",
      "Training mini-batch number 124000\n",
      "Epoch 24: validation accuracy 99.18%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.26%\n",
      "Training mini-batch number 125000\n",
      "Training mini-batch number 126000\n",
      "Training mini-batch number 127000\n",
      "Training mini-batch number 128000\n",
      "Training mini-batch number 129000\n",
      "Epoch 25: validation accuracy 99.18%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.27%\n",
      "Training mini-batch number 130000\n",
      "Training mini-batch number 131000\n",
      "Training mini-batch number 132000\n",
      "Training mini-batch number 133000\n",
      "Training mini-batch number 134000\n",
      "Epoch 26: validation accuracy 99.19%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.27%\n",
      "Training mini-batch number 135000\n",
      "Training mini-batch number 136000\n",
      "Training mini-batch number 137000\n",
      "Training mini-batch number 138000\n",
      "Training mini-batch number 139000\n",
      "Epoch 27: validation accuracy 99.19%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.27%\n",
      "Training mini-batch number 140000\n",
      "Training mini-batch number 141000\n",
      "Training mini-batch number 142000\n",
      "Training mini-batch number 143000\n",
      "Training mini-batch number 144000\n",
      "Epoch 28: validation accuracy 99.19%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.27%\n",
      "Training mini-batch number 145000\n",
      "Training mini-batch number 146000\n",
      "Training mini-batch number 147000\n",
      "Training mini-batch number 148000\n",
      "Training mini-batch number 149000\n",
      "Epoch 29: validation accuracy 99.19%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.27%\n",
      "Training mini-batch number 150000\n",
      "Training mini-batch number 151000\n",
      "Training mini-batch number 152000\n",
      "Training mini-batch number 153000\n",
      "Training mini-batch number 154000\n",
      "Epoch 30: validation accuracy 99.18%\n",
      "Training mini-batch number 155000\n",
      "Training mini-batch number 156000\n",
      "Training mini-batch number 157000\n",
      "Training mini-batch number 158000\n",
      "Training mini-batch number 159000\n",
      "Epoch 31: validation accuracy 99.18%\n",
      "Training mini-batch number 160000\n",
      "Training mini-batch number 161000\n",
      "Training mini-batch number 162000\n",
      "Training mini-batch number 163000\n",
      "Training mini-batch number 164000\n",
      "Epoch 32: validation accuracy 99.18%\n",
      "Training mini-batch number 165000\n",
      "Training mini-batch number 166000\n",
      "Training mini-batch number 167000\n",
      "Training mini-batch number 168000\n",
      "Training mini-batch number 169000\n",
      "Epoch 33: validation accuracy 99.19%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.26%\n",
      "Training mini-batch number 170000\n",
      "Training mini-batch number 171000\n",
      "Training mini-batch number 172000\n",
      "Training mini-batch number 173000\n",
      "Training mini-batch number 174000\n",
      "Epoch 34: validation accuracy 99.19%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.26%\n",
      "Training mini-batch number 175000\n",
      "Training mini-batch number 176000\n",
      "Training mini-batch number 177000\n",
      "Training mini-batch number 178000\n",
      "Training mini-batch number 179000\n",
      "Epoch 35: validation accuracy 99.18%\n",
      "Training mini-batch number 180000\n",
      "Training mini-batch number 181000\n",
      "Training mini-batch number 182000\n",
      "Training mini-batch number 183000\n",
      "Training mini-batch number 184000\n",
      "Epoch 36: validation accuracy 99.18%\n",
      "Training mini-batch number 185000\n",
      "Training mini-batch number 186000\n",
      "Training mini-batch number 187000\n",
      "Training mini-batch number 188000\n",
      "Training mini-batch number 189000\n",
      "Epoch 37: validation accuracy 99.19%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.26%\n",
      "Training mini-batch number 190000\n",
      "Training mini-batch number 191000\n",
      "Training mini-batch number 192000\n",
      "Training mini-batch number 193000\n",
      "Training mini-batch number 194000\n",
      "Epoch 38: validation accuracy 99.20%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.26%\n",
      "Training mini-batch number 195000\n",
      "Training mini-batch number 196000\n",
      "Training mini-batch number 197000\n",
      "Training mini-batch number 198000\n",
      "Training mini-batch number 199000\n",
      "Epoch 39: validation accuracy 99.20%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.25%\n",
      "Training mini-batch number 200000\n",
      "Training mini-batch number 201000\n",
      "Training mini-batch number 202000\n",
      "Training mini-batch number 203000\n",
      "Training mini-batch number 204000\n",
      "Epoch 40: validation accuracy 99.20%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.26%\n",
      "Training mini-batch number 205000\n",
      "Training mini-batch number 206000\n",
      "Training mini-batch number 207000\n",
      "Training mini-batch number 208000\n",
      "Training mini-batch number 209000\n",
      "Epoch 41: validation accuracy 99.20%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.25%\n",
      "Training mini-batch number 210000\n",
      "Training mini-batch number 211000\n",
      "Training mini-batch number 212000\n",
      "Training mini-batch number 213000\n",
      "Training mini-batch number 214000\n",
      "Epoch 42: validation accuracy 99.21%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.25%\n",
      "Training mini-batch number 215000\n",
      "Training mini-batch number 216000\n",
      "Training mini-batch number 217000\n",
      "Training mini-batch number 218000\n",
      "Training mini-batch number 219000\n",
      "Epoch 43: validation accuracy 99.21%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.25%\n",
      "Training mini-batch number 220000\n",
      "Training mini-batch number 221000\n",
      "Training mini-batch number 222000\n",
      "Training mini-batch number 223000\n",
      "Training mini-batch number 224000\n",
      "Epoch 44: validation accuracy 99.21%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.24%\n",
      "Training mini-batch number 225000\n",
      "Training mini-batch number 226000\n",
      "Training mini-batch number 227000\n",
      "Training mini-batch number 228000\n",
      "Training mini-batch number 229000\n",
      "Epoch 45: validation accuracy 99.20%\n",
      "Training mini-batch number 230000\n",
      "Training mini-batch number 231000\n",
      "Training mini-batch number 232000\n",
      "Training mini-batch number 233000\n",
      "Training mini-batch number 234000\n",
      "Epoch 46: validation accuracy 99.19%\n",
      "Training mini-batch number 235000\n",
      "Training mini-batch number 236000\n",
      "Training mini-batch number 237000\n",
      "Training mini-batch number 238000\n",
      "Training mini-batch number 239000\n",
      "Epoch 47: validation accuracy 99.19%\n",
      "Training mini-batch number 240000\n",
      "Training mini-batch number 241000\n",
      "Training mini-batch number 242000\n",
      "Training mini-batch number 243000\n",
      "Training mini-batch number 244000\n",
      "Epoch 48: validation accuracy 99.20%\n",
      "Training mini-batch number 245000\n",
      "Training mini-batch number 246000\n",
      "Training mini-batch number 247000\n",
      "Training mini-batch number 248000\n",
      "Training mini-batch number 249000\n",
      "Epoch 49: validation accuracy 99.20%\n",
      "Training mini-batch number 250000\n",
      "Training mini-batch number 251000\n",
      "Training mini-batch number 252000\n",
      "Training mini-batch number 253000\n",
      "Training mini-batch number 254000\n",
      "Epoch 50: validation accuracy 99.19%\n",
      "Training mini-batch number 255000\n",
      "Training mini-batch number 256000\n",
      "Training mini-batch number 257000\n",
      "Training mini-batch number 258000\n",
      "Training mini-batch number 259000\n",
      "Epoch 51: validation accuracy 99.20%\n",
      "Training mini-batch number 260000\n",
      "Training mini-batch number 261000\n",
      "Training mini-batch number 262000\n",
      "Training mini-batch number 263000\n",
      "Training mini-batch number 264000\n",
      "Epoch 52: validation accuracy 99.21%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.27%\n",
      "Training mini-batch number 265000\n",
      "Training mini-batch number 266000\n",
      "Training mini-batch number 267000\n",
      "Training mini-batch number 268000\n",
      "Training mini-batch number 269000\n",
      "Epoch 53: validation accuracy 99.18%\n",
      "Training mini-batch number 270000\n",
      "Training mini-batch number 271000\n",
      "Training mini-batch number 272000\n",
      "Training mini-batch number 273000\n",
      "Training mini-batch number 274000\n",
      "Epoch 54: validation accuracy 99.18%\n",
      "Training mini-batch number 275000\n",
      "Training mini-batch number 276000\n",
      "Training mini-batch number 277000\n",
      "Training mini-batch number 278000\n",
      "Training mini-batch number 279000\n",
      "Epoch 55: validation accuracy 99.18%\n",
      "Training mini-batch number 280000\n",
      "Training mini-batch number 281000\n",
      "Training mini-batch number 282000\n",
      "Training mini-batch number 283000\n",
      "Training mini-batch number 284000\n",
      "Epoch 56: validation accuracy 99.18%\n",
      "Training mini-batch number 285000\n",
      "Training mini-batch number 286000\n",
      "Training mini-batch number 287000\n",
      "Training mini-batch number 288000\n",
      "Training mini-batch number 289000\n",
      "Epoch 57: validation accuracy 99.17%\n",
      "Training mini-batch number 290000\n",
      "Training mini-batch number 291000\n",
      "Training mini-batch number 292000\n",
      "Training mini-batch number 293000\n",
      "Training mini-batch number 294000\n",
      "Epoch 58: validation accuracy 99.18%\n",
      "Training mini-batch number 295000\n",
      "Training mini-batch number 296000\n",
      "Training mini-batch number 297000\n",
      "Training mini-batch number 298000\n",
      "Training mini-batch number 299000\n",
      "Epoch 59: validation accuracy 99.17%\n",
      "Finished training network.\n",
      "Best validation accuracy of 99.21% obtained at iteration 264999\n",
      "Corresponding test accuracy of 99.27%\n",
      "Training mini-batch number 0\n",
      "Training mini-batch number 1000\n",
      "Training mini-batch number 2000\n",
      "Training mini-batch number 3000\n",
      "Training mini-batch number 4000\n",
      "Epoch 0: validation accuracy 99.16%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.26%\n",
      "Training mini-batch number 5000\n",
      "Training mini-batch number 6000\n",
      "Training mini-batch number 7000\n",
      "Training mini-batch number 8000\n",
      "Training mini-batch number 9000\n",
      "Epoch 1: validation accuracy 99.16%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.26%\n",
      "Training mini-batch number 10000\n",
      "Training mini-batch number 11000\n",
      "Training mini-batch number 12000\n",
      "Training mini-batch number 13000\n",
      "Training mini-batch number 14000\n",
      "Epoch 2: validation accuracy 99.17%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.26%\n",
      "Training mini-batch number 15000\n",
      "Training mini-batch number 16000\n",
      "Training mini-batch number 17000\n",
      "Training mini-batch number 18000\n",
      "Training mini-batch number 19000\n",
      "Epoch 3: validation accuracy 99.18%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.27%\n",
      "Training mini-batch number 20000\n",
      "Training mini-batch number 21000\n",
      "Training mini-batch number 22000\n",
      "Training mini-batch number 23000\n",
      "Training mini-batch number 24000\n",
      "Epoch 4: validation accuracy 99.18%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.26%\n",
      "Training mini-batch number 25000\n",
      "Training mini-batch number 26000\n",
      "Training mini-batch number 27000\n",
      "Training mini-batch number 28000\n",
      "Training mini-batch number 29000\n",
      "Epoch 5: validation accuracy 99.17%\n",
      "Training mini-batch number 30000\n",
      "Training mini-batch number 31000\n",
      "Training mini-batch number 32000\n",
      "Training mini-batch number 33000\n",
      "Training mini-batch number 34000\n",
      "Epoch 6: validation accuracy 99.17%\n",
      "Training mini-batch number 35000\n",
      "Training mini-batch number 36000\n",
      "Training mini-batch number 37000\n",
      "Training mini-batch number 38000\n",
      "Training mini-batch number 39000\n",
      "Epoch 7: validation accuracy 99.18%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.28%\n",
      "Training mini-batch number 40000\n",
      "Training mini-batch number 41000\n",
      "Training mini-batch number 42000\n",
      "Training mini-batch number 43000\n",
      "Training mini-batch number 44000\n",
      "Epoch 8: validation accuracy 99.16%\n",
      "Training mini-batch number 45000\n",
      "Training mini-batch number 46000\n",
      "Training mini-batch number 47000\n",
      "Training mini-batch number 48000\n",
      "Training mini-batch number 49000\n",
      "Epoch 9: validation accuracy 99.17%\n",
      "Training mini-batch number 50000\n",
      "Training mini-batch number 51000\n",
      "Training mini-batch number 52000\n",
      "Training mini-batch number 53000\n",
      "Training mini-batch number 54000\n",
      "Epoch 10: validation accuracy 99.16%\n",
      "Training mini-batch number 55000\n",
      "Training mini-batch number 56000\n",
      "Training mini-batch number 57000\n",
      "Training mini-batch number 58000\n",
      "Training mini-batch number 59000\n",
      "Epoch 11: validation accuracy 99.15%\n",
      "Training mini-batch number 60000\n",
      "Training mini-batch number 61000\n",
      "Training mini-batch number 62000\n",
      "Training mini-batch number 63000\n",
      "Training mini-batch number 64000\n",
      "Epoch 12: validation accuracy 99.16%\n",
      "Training mini-batch number 65000\n",
      "Training mini-batch number 66000\n",
      "Training mini-batch number 67000\n",
      "Training mini-batch number 68000\n",
      "Training mini-batch number 69000\n",
      "Epoch 13: validation accuracy 99.16%\n",
      "Training mini-batch number 70000\n",
      "Training mini-batch number 71000\n",
      "Training mini-batch number 72000\n",
      "Training mini-batch number 73000\n",
      "Training mini-batch number 74000\n",
      "Epoch 14: validation accuracy 99.16%\n",
      "Training mini-batch number 75000\n",
      "Training mini-batch number 76000\n",
      "Training mini-batch number 77000\n",
      "Training mini-batch number 78000\n",
      "Training mini-batch number 79000\n",
      "Epoch 15: validation accuracy 99.16%\n",
      "Training mini-batch number 80000\n",
      "Training mini-batch number 81000\n",
      "Training mini-batch number 82000\n",
      "Training mini-batch number 83000\n",
      "Training mini-batch number 84000\n",
      "Epoch 16: validation accuracy 99.15%\n",
      "Training mini-batch number 85000\n",
      "Training mini-batch number 86000\n",
      "Training mini-batch number 87000\n",
      "Training mini-batch number 88000\n",
      "Training mini-batch number 89000\n",
      "Epoch 17: validation accuracy 99.15%\n",
      "Training mini-batch number 90000\n",
      "Training mini-batch number 91000\n",
      "Training mini-batch number 92000\n",
      "Training mini-batch number 93000\n",
      "Training mini-batch number 94000\n",
      "Epoch 18: validation accuracy 99.15%\n",
      "Training mini-batch number 95000\n",
      "Training mini-batch number 96000\n",
      "Training mini-batch number 97000\n",
      "Training mini-batch number 98000\n",
      "Training mini-batch number 99000\n",
      "Epoch 19: validation accuracy 99.14%\n",
      "Training mini-batch number 100000\n",
      "Training mini-batch number 101000\n",
      "Training mini-batch number 102000\n",
      "Training mini-batch number 103000\n",
      "Training mini-batch number 104000\n",
      "Epoch 20: validation accuracy 99.14%\n",
      "Training mini-batch number 105000\n",
      "Training mini-batch number 106000\n",
      "Training mini-batch number 107000\n",
      "Training mini-batch number 108000\n",
      "Training mini-batch number 109000\n",
      "Epoch 21: validation accuracy 99.14%\n",
      "Training mini-batch number 110000\n",
      "Training mini-batch number 111000\n",
      "Training mini-batch number 112000\n",
      "Training mini-batch number 113000\n",
      "Training mini-batch number 114000\n",
      "Epoch 22: validation accuracy 99.14%\n",
      "Training mini-batch number 115000\n",
      "Training mini-batch number 116000\n",
      "Training mini-batch number 117000\n",
      "Training mini-batch number 118000\n",
      "Training mini-batch number 119000\n",
      "Epoch 23: validation accuracy 99.14%\n",
      "Training mini-batch number 120000\n",
      "Training mini-batch number 121000\n",
      "Training mini-batch number 122000\n",
      "Training mini-batch number 123000\n",
      "Training mini-batch number 124000\n",
      "Epoch 24: validation accuracy 99.14%\n",
      "Training mini-batch number 125000\n",
      "Training mini-batch number 126000\n",
      "Training mini-batch number 127000\n",
      "Training mini-batch number 128000\n",
      "Training mini-batch number 129000\n",
      "Epoch 25: validation accuracy 99.14%\n",
      "Training mini-batch number 130000\n",
      "Training mini-batch number 131000\n",
      "Training mini-batch number 132000\n",
      "Training mini-batch number 133000\n",
      "Training mini-batch number 134000\n",
      "Epoch 26: validation accuracy 99.14%\n",
      "Training mini-batch number 135000\n",
      "Training mini-batch number 136000\n",
      "Training mini-batch number 137000\n",
      "Training mini-batch number 138000\n",
      "Training mini-batch number 139000\n",
      "Epoch 27: validation accuracy 99.14%\n",
      "Training mini-batch number 140000\n",
      "Training mini-batch number 141000\n",
      "Training mini-batch number 142000\n",
      "Training mini-batch number 143000\n",
      "Training mini-batch number 144000\n",
      "Epoch 28: validation accuracy 99.14%\n",
      "Training mini-batch number 145000\n",
      "Training mini-batch number 146000\n",
      "Training mini-batch number 147000\n",
      "Training mini-batch number 148000\n",
      "Training mini-batch number 149000\n",
      "Epoch 29: validation accuracy 99.14%\n",
      "Training mini-batch number 150000\n",
      "Training mini-batch number 151000\n",
      "Training mini-batch number 152000\n",
      "Training mini-batch number 153000\n",
      "Training mini-batch number 154000\n",
      "Epoch 30: validation accuracy 99.15%\n",
      "Training mini-batch number 155000\n",
      "Training mini-batch number 156000\n",
      "Training mini-batch number 157000\n",
      "Training mini-batch number 158000\n",
      "Training mini-batch number 159000\n",
      "Epoch 31: validation accuracy 99.15%\n",
      "Training mini-batch number 160000\n",
      "Training mini-batch number 161000\n",
      "Training mini-batch number 162000\n",
      "Training mini-batch number 163000\n",
      "Training mini-batch number 164000\n",
      "Epoch 32: validation accuracy 99.15%\n",
      "Training mini-batch number 165000\n",
      "Training mini-batch number 166000\n",
      "Training mini-batch number 167000\n",
      "Training mini-batch number 168000\n",
      "Training mini-batch number 169000\n",
      "Epoch 33: validation accuracy 99.15%\n",
      "Training mini-batch number 170000\n",
      "Training mini-batch number 171000\n",
      "Training mini-batch number 172000\n",
      "Training mini-batch number 173000\n",
      "Training mini-batch number 174000\n",
      "Epoch 34: validation accuracy 99.15%\n",
      "Training mini-batch number 175000\n",
      "Training mini-batch number 176000\n",
      "Training mini-batch number 177000\n",
      "Training mini-batch number 178000\n",
      "Training mini-batch number 179000\n",
      "Epoch 35: validation accuracy 99.15%\n",
      "Training mini-batch number 180000\n",
      "Training mini-batch number 181000\n",
      "Training mini-batch number 182000\n",
      "Training mini-batch number 183000\n",
      "Training mini-batch number 184000\n",
      "Epoch 36: validation accuracy 99.16%\n",
      "Training mini-batch number 185000\n",
      "Training mini-batch number 186000\n",
      "Training mini-batch number 187000\n",
      "Training mini-batch number 188000\n",
      "Training mini-batch number 189000\n",
      "Epoch 37: validation accuracy 99.15%\n",
      "Training mini-batch number 190000\n",
      "Training mini-batch number 191000\n",
      "Training mini-batch number 192000\n",
      "Training mini-batch number 193000\n",
      "Training mini-batch number 194000\n",
      "Epoch 38: validation accuracy 99.15%\n",
      "Training mini-batch number 195000\n",
      "Training mini-batch number 196000\n",
      "Training mini-batch number 197000\n",
      "Training mini-batch number 198000\n",
      "Training mini-batch number 199000\n",
      "Epoch 39: validation accuracy 99.16%\n",
      "Training mini-batch number 200000\n",
      "Training mini-batch number 201000\n",
      "Training mini-batch number 202000\n",
      "Training mini-batch number 203000\n",
      "Training mini-batch number 204000\n",
      "Epoch 40: validation accuracy 99.16%\n",
      "Training mini-batch number 205000\n",
      "Training mini-batch number 206000\n",
      "Training mini-batch number 207000\n",
      "Training mini-batch number 208000\n",
      "Training mini-batch number 209000\n",
      "Epoch 41: validation accuracy 99.16%\n",
      "Training mini-batch number 210000\n",
      "Training mini-batch number 211000\n",
      "Training mini-batch number 212000\n",
      "Training mini-batch number 213000\n",
      "Training mini-batch number 214000\n",
      "Epoch 42: validation accuracy 99.16%\n",
      "Training mini-batch number 215000\n",
      "Training mini-batch number 216000\n",
      "Training mini-batch number 217000\n",
      "Training mini-batch number 218000\n",
      "Training mini-batch number 219000\n",
      "Epoch 43: validation accuracy 99.16%\n",
      "Training mini-batch number 220000\n",
      "Training mini-batch number 221000\n",
      "Training mini-batch number 222000\n",
      "Training mini-batch number 223000\n",
      "Training mini-batch number 224000\n",
      "Epoch 44: validation accuracy 99.16%\n",
      "Training mini-batch number 225000\n",
      "Training mini-batch number 226000\n",
      "Training mini-batch number 227000\n",
      "Training mini-batch number 228000\n",
      "Training mini-batch number 229000\n",
      "Epoch 45: validation accuracy 99.15%\n",
      "Training mini-batch number 230000\n",
      "Training mini-batch number 231000\n",
      "Training mini-batch number 232000\n",
      "Training mini-batch number 233000\n",
      "Training mini-batch number 234000\n",
      "Epoch 46: validation accuracy 99.15%\n",
      "Training mini-batch number 235000\n",
      "Training mini-batch number 236000\n",
      "Training mini-batch number 237000\n",
      "Training mini-batch number 238000\n",
      "Training mini-batch number 239000\n",
      "Epoch 47: validation accuracy 99.15%\n",
      "Training mini-batch number 240000\n",
      "Training mini-batch number 241000\n",
      "Training mini-batch number 242000\n",
      "Training mini-batch number 243000\n",
      "Training mini-batch number 244000\n",
      "Epoch 48: validation accuracy 99.15%\n",
      "Training mini-batch number 245000\n",
      "Training mini-batch number 246000\n",
      "Training mini-batch number 247000\n",
      "Training mini-batch number 248000\n",
      "Training mini-batch number 249000\n",
      "Epoch 49: validation accuracy 99.15%\n",
      "Training mini-batch number 250000\n",
      "Training mini-batch number 251000\n",
      "Training mini-batch number 252000\n",
      "Training mini-batch number 253000\n",
      "Training mini-batch number 254000\n",
      "Epoch 50: validation accuracy 99.15%\n",
      "Training mini-batch number 255000\n",
      "Training mini-batch number 256000\n",
      "Training mini-batch number 257000\n",
      "Training mini-batch number 258000\n",
      "Training mini-batch number 259000\n",
      "Epoch 51: validation accuracy 99.15%\n",
      "Training mini-batch number 260000\n",
      "Training mini-batch number 261000\n",
      "Training mini-batch number 262000\n",
      "Training mini-batch number 263000\n",
      "Training mini-batch number 264000\n",
      "Epoch 52: validation accuracy 99.15%\n",
      "Training mini-batch number 265000\n",
      "Training mini-batch number 266000\n",
      "Training mini-batch number 267000\n",
      "Training mini-batch number 268000\n",
      "Training mini-batch number 269000\n",
      "Epoch 53: validation accuracy 99.15%\n",
      "Training mini-batch number 270000\n",
      "Training mini-batch number 271000\n",
      "Training mini-batch number 272000\n",
      "Training mini-batch number 273000\n",
      "Training mini-batch number 274000\n",
      "Epoch 54: validation accuracy 99.15%\n",
      "Training mini-batch number 275000\n",
      "Training mini-batch number 276000\n",
      "Training mini-batch number 277000\n",
      "Training mini-batch number 278000\n",
      "Training mini-batch number 279000\n",
      "Epoch 55: validation accuracy 99.15%\n",
      "Training mini-batch number 280000\n",
      "Training mini-batch number 281000\n",
      "Training mini-batch number 282000\n",
      "Training mini-batch number 283000\n",
      "Training mini-batch number 284000\n",
      "Epoch 56: validation accuracy 99.15%\n",
      "Training mini-batch number 285000\n",
      "Training mini-batch number 286000\n",
      "Training mini-batch number 287000\n",
      "Training mini-batch number 288000\n",
      "Training mini-batch number 289000\n",
      "Epoch 57: validation accuracy 99.15%\n",
      "Training mini-batch number 290000\n",
      "Training mini-batch number 291000\n",
      "Training mini-batch number 292000\n",
      "Training mini-batch number 293000\n",
      "Training mini-batch number 294000\n",
      "Epoch 58: validation accuracy 99.15%\n",
      "Training mini-batch number 295000\n",
      "Training mini-batch number 296000\n",
      "Training mini-batch number 297000\n",
      "Training mini-batch number 298000\n",
      "Training mini-batch number 299000\n",
      "Epoch 59: validation accuracy 99.15%\n",
      "Finished training network.\n",
      "Best validation accuracy of 99.18% obtained at iteration 39999\n",
      "Corresponding test accuracy of 99.28%\n",
      "Training mini-batch number 0\n",
      "Training mini-batch number 1000\n",
      "Training mini-batch number 2000\n",
      "Training mini-batch number 3000\n",
      "Training mini-batch number 4000\n",
      "Epoch 0: validation accuracy 99.15%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.21%\n",
      "Training mini-batch number 5000\n",
      "Training mini-batch number 6000\n",
      "Training mini-batch number 7000\n",
      "Training mini-batch number 8000\n",
      "Training mini-batch number 9000\n",
      "Epoch 1: validation accuracy 99.15%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.22%\n",
      "Training mini-batch number 10000\n",
      "Training mini-batch number 11000\n",
      "Training mini-batch number 12000\n",
      "Training mini-batch number 13000\n",
      "Training mini-batch number 14000\n",
      "Epoch 2: validation accuracy 99.15%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.21%\n",
      "Training mini-batch number 15000\n",
      "Training mini-batch number 16000\n",
      "Training mini-batch number 17000\n",
      "Training mini-batch number 18000\n",
      "Training mini-batch number 19000\n",
      "Epoch 3: validation accuracy 99.15%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.22%\n",
      "Training mini-batch number 20000\n",
      "Training mini-batch number 21000\n",
      "Training mini-batch number 22000\n",
      "Training mini-batch number 23000\n",
      "Training mini-batch number 24000\n",
      "Epoch 4: validation accuracy 99.15%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.22%\n",
      "Training mini-batch number 25000\n",
      "Training mini-batch number 26000\n",
      "Training mini-batch number 27000\n",
      "Training mini-batch number 28000\n",
      "Training mini-batch number 29000\n",
      "Epoch 5: validation accuracy 99.15%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.22%\n",
      "Training mini-batch number 30000\n",
      "Training mini-batch number 31000\n",
      "Training mini-batch number 32000\n",
      "Training mini-batch number 33000\n",
      "Training mini-batch number 34000\n",
      "Epoch 6: validation accuracy 99.15%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.22%\n",
      "Training mini-batch number 35000\n",
      "Training mini-batch number 36000\n",
      "Training mini-batch number 37000\n",
      "Training mini-batch number 38000\n",
      "Training mini-batch number 39000\n",
      "Epoch 7: validation accuracy 99.16%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.22%\n",
      "Training mini-batch number 40000\n",
      "Training mini-batch number 41000\n",
      "Training mini-batch number 42000\n",
      "Training mini-batch number 43000\n",
      "Training mini-batch number 44000\n",
      "Epoch 8: validation accuracy 99.16%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.22%\n",
      "Training mini-batch number 45000\n",
      "Training mini-batch number 46000\n",
      "Training mini-batch number 47000\n",
      "Training mini-batch number 48000\n",
      "Training mini-batch number 49000\n",
      "Epoch 9: validation accuracy 99.16%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.22%\n",
      "Training mini-batch number 50000\n",
      "Training mini-batch number 51000\n",
      "Training mini-batch number 52000\n",
      "Training mini-batch number 53000\n",
      "Training mini-batch number 54000\n",
      "Epoch 10: validation accuracy 99.16%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.22%\n",
      "Training mini-batch number 55000\n",
      "Training mini-batch number 56000\n",
      "Training mini-batch number 57000\n",
      "Training mini-batch number 58000\n",
      "Training mini-batch number 59000\n",
      "Epoch 11: validation accuracy 99.16%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.22%\n",
      "Training mini-batch number 60000\n",
      "Training mini-batch number 61000\n",
      "Training mini-batch number 62000\n",
      "Training mini-batch number 63000\n",
      "Training mini-batch number 64000\n",
      "Epoch 12: validation accuracy 99.17%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.22%\n",
      "Training mini-batch number 65000\n",
      "Training mini-batch number 66000\n",
      "Training mini-batch number 67000\n",
      "Training mini-batch number 68000\n",
      "Training mini-batch number 69000\n",
      "Epoch 13: validation accuracy 99.17%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.22%\n",
      "Training mini-batch number 70000\n",
      "Training mini-batch number 71000\n",
      "Training mini-batch number 72000\n",
      "Training mini-batch number 73000\n",
      "Training mini-batch number 74000\n",
      "Epoch 14: validation accuracy 99.17%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.22%\n",
      "Training mini-batch number 75000\n",
      "Training mini-batch number 76000\n",
      "Training mini-batch number 77000\n",
      "Training mini-batch number 78000\n",
      "Training mini-batch number 79000\n",
      "Epoch 15: validation accuracy 99.17%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.22%\n",
      "Training mini-batch number 80000\n",
      "Training mini-batch number 81000\n",
      "Training mini-batch number 82000\n",
      "Training mini-batch number 83000\n",
      "Training mini-batch number 84000\n",
      "Epoch 16: validation accuracy 99.17%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.22%\n",
      "Training mini-batch number 85000\n",
      "Training mini-batch number 86000\n",
      "Training mini-batch number 87000\n",
      "Training mini-batch number 88000\n",
      "Training mini-batch number 89000\n",
      "Epoch 17: validation accuracy 99.17%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.22%\n",
      "Training mini-batch number 90000\n",
      "Training mini-batch number 91000\n",
      "Training mini-batch number 92000\n",
      "Training mini-batch number 93000\n",
      "Training mini-batch number 94000\n",
      "Epoch 18: validation accuracy 99.17%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.22%\n",
      "Training mini-batch number 95000\n",
      "Training mini-batch number 96000\n",
      "Training mini-batch number 97000\n",
      "Training mini-batch number 98000\n",
      "Training mini-batch number 99000\n",
      "Epoch 19: validation accuracy 99.17%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.21%\n",
      "Training mini-batch number 100000\n",
      "Training mini-batch number 101000\n",
      "Training mini-batch number 102000\n",
      "Training mini-batch number 103000\n",
      "Training mini-batch number 104000\n",
      "Epoch 20: validation accuracy 99.17%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.21%\n",
      "Training mini-batch number 105000\n",
      "Training mini-batch number 106000\n",
      "Training mini-batch number 107000\n",
      "Training mini-batch number 108000\n",
      "Training mini-batch number 109000\n",
      "Epoch 21: validation accuracy 99.17%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.21%\n",
      "Training mini-batch number 110000\n",
      "Training mini-batch number 111000\n",
      "Training mini-batch number 112000\n",
      "Training mini-batch number 113000\n",
      "Training mini-batch number 114000\n",
      "Epoch 22: validation accuracy 99.17%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.21%\n",
      "Training mini-batch number 115000\n",
      "Training mini-batch number 116000\n",
      "Training mini-batch number 117000\n",
      "Training mini-batch number 118000\n",
      "Training mini-batch number 119000\n",
      "Epoch 23: validation accuracy 99.17%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.21%\n",
      "Training mini-batch number 120000\n",
      "Training mini-batch number 121000\n",
      "Training mini-batch number 122000\n",
      "Training mini-batch number 123000\n",
      "Training mini-batch number 124000\n",
      "Epoch 24: validation accuracy 99.16%\n",
      "Training mini-batch number 125000\n",
      "Training mini-batch number 126000\n",
      "Training mini-batch number 127000\n",
      "Training mini-batch number 128000\n",
      "Training mini-batch number 129000\n",
      "Epoch 25: validation accuracy 99.14%\n",
      "Training mini-batch number 130000\n",
      "Training mini-batch number 131000\n",
      "Training mini-batch number 132000\n",
      "Training mini-batch number 133000\n",
      "Training mini-batch number 134000\n",
      "Epoch 26: validation accuracy 99.13%\n",
      "Training mini-batch number 135000\n",
      "Training mini-batch number 136000\n",
      "Training mini-batch number 137000\n",
      "Training mini-batch number 138000\n",
      "Training mini-batch number 139000\n",
      "Epoch 27: validation accuracy 99.13%\n",
      "Training mini-batch number 140000\n",
      "Training mini-batch number 141000\n",
      "Training mini-batch number 142000\n",
      "Training mini-batch number 143000\n",
      "Training mini-batch number 144000\n",
      "Epoch 28: validation accuracy 99.13%\n",
      "Training mini-batch number 145000\n",
      "Training mini-batch number 146000\n",
      "Training mini-batch number 147000\n",
      "Training mini-batch number 148000\n",
      "Training mini-batch number 149000\n",
      "Epoch 29: validation accuracy 99.13%\n",
      "Training mini-batch number 150000\n",
      "Training mini-batch number 151000\n",
      "Training mini-batch number 152000\n",
      "Training mini-batch number 153000\n",
      "Training mini-batch number 154000\n",
      "Epoch 30: validation accuracy 99.12%\n",
      "Training mini-batch number 155000\n",
      "Training mini-batch number 156000\n",
      "Training mini-batch number 157000\n",
      "Training mini-batch number 158000\n",
      "Training mini-batch number 159000\n",
      "Epoch 31: validation accuracy 99.12%\n",
      "Training mini-batch number 160000\n",
      "Training mini-batch number 161000\n",
      "Training mini-batch number 162000\n",
      "Training mini-batch number 163000\n",
      "Training mini-batch number 164000\n",
      "Epoch 32: validation accuracy 99.12%\n",
      "Training mini-batch number 165000\n",
      "Training mini-batch number 166000\n",
      "Training mini-batch number 167000\n",
      "Training mini-batch number 168000\n",
      "Training mini-batch number 169000\n",
      "Epoch 33: validation accuracy 99.12%\n",
      "Training mini-batch number 170000\n",
      "Training mini-batch number 171000\n",
      "Training mini-batch number 172000\n",
      "Training mini-batch number 173000\n",
      "Training mini-batch number 174000\n",
      "Epoch 34: validation accuracy 99.12%\n",
      "Training mini-batch number 175000\n",
      "Training mini-batch number 176000\n",
      "Training mini-batch number 177000\n",
      "Training mini-batch number 178000\n",
      "Training mini-batch number 179000\n",
      "Epoch 35: validation accuracy 99.12%\n",
      "Training mini-batch number 180000\n",
      "Training mini-batch number 181000\n",
      "Training mini-batch number 182000\n",
      "Training mini-batch number 183000\n",
      "Training mini-batch number 184000\n",
      "Epoch 36: validation accuracy 99.12%\n",
      "Training mini-batch number 185000\n",
      "Training mini-batch number 186000\n",
      "Training mini-batch number 187000\n",
      "Training mini-batch number 188000\n",
      "Training mini-batch number 189000\n",
      "Epoch 37: validation accuracy 99.12%\n",
      "Training mini-batch number 190000\n",
      "Training mini-batch number 191000\n",
      "Training mini-batch number 192000\n",
      "Training mini-batch number 193000\n",
      "Training mini-batch number 194000\n",
      "Epoch 38: validation accuracy 99.12%\n",
      "Training mini-batch number 195000\n",
      "Training mini-batch number 196000\n",
      "Training mini-batch number 197000\n",
      "Training mini-batch number 198000\n",
      "Training mini-batch number 199000\n",
      "Epoch 39: validation accuracy 99.12%\n",
      "Training mini-batch number 200000\n",
      "Training mini-batch number 201000\n",
      "Training mini-batch number 202000\n",
      "Training mini-batch number 203000\n",
      "Training mini-batch number 204000\n",
      "Epoch 40: validation accuracy 99.12%\n",
      "Training mini-batch number 205000\n",
      "Training mini-batch number 206000\n",
      "Training mini-batch number 207000\n",
      "Training mini-batch number 208000\n",
      "Training mini-batch number 209000\n",
      "Epoch 41: validation accuracy 99.12%\n",
      "Training mini-batch number 210000\n",
      "Training mini-batch number 211000\n",
      "Training mini-batch number 212000\n",
      "Training mini-batch number 213000\n",
      "Training mini-batch number 214000\n",
      "Epoch 42: validation accuracy 99.12%\n",
      "Training mini-batch number 215000\n",
      "Training mini-batch number 216000\n",
      "Training mini-batch number 217000\n",
      "Training mini-batch number 218000\n",
      "Training mini-batch number 219000\n",
      "Epoch 43: validation accuracy 99.12%\n",
      "Training mini-batch number 220000\n",
      "Training mini-batch number 221000\n",
      "Training mini-batch number 222000\n",
      "Training mini-batch number 223000\n",
      "Training mini-batch number 224000\n",
      "Epoch 44: validation accuracy 99.12%\n",
      "Training mini-batch number 225000\n",
      "Training mini-batch number 226000\n",
      "Training mini-batch number 227000\n",
      "Training mini-batch number 228000\n",
      "Training mini-batch number 229000\n",
      "Epoch 45: validation accuracy 99.12%\n",
      "Training mini-batch number 230000\n",
      "Training mini-batch number 231000\n",
      "Training mini-batch number 232000\n",
      "Training mini-batch number 233000\n",
      "Training mini-batch number 234000\n",
      "Epoch 46: validation accuracy 99.12%\n",
      "Training mini-batch number 235000\n",
      "Training mini-batch number 236000\n",
      "Training mini-batch number 237000\n",
      "Training mini-batch number 238000\n",
      "Training mini-batch number 239000\n",
      "Epoch 47: validation accuracy 99.12%\n",
      "Training mini-batch number 240000\n",
      "Training mini-batch number 241000\n",
      "Training mini-batch number 242000\n",
      "Training mini-batch number 243000\n",
      "Training mini-batch number 244000\n",
      "Epoch 48: validation accuracy 99.11%\n",
      "Training mini-batch number 245000\n",
      "Training mini-batch number 246000\n",
      "Training mini-batch number 247000\n",
      "Training mini-batch number 248000\n",
      "Training mini-batch number 249000\n",
      "Epoch 49: validation accuracy 99.11%\n",
      "Training mini-batch number 250000\n",
      "Training mini-batch number 251000\n",
      "Training mini-batch number 252000\n",
      "Training mini-batch number 253000\n",
      "Training mini-batch number 254000\n",
      "Epoch 50: validation accuracy 99.11%\n",
      "Training mini-batch number 255000\n",
      "Training mini-batch number 256000\n",
      "Training mini-batch number 257000\n",
      "Training mini-batch number 258000\n",
      "Training mini-batch number 259000\n",
      "Epoch 51: validation accuracy 99.11%\n",
      "Training mini-batch number 260000\n",
      "Training mini-batch number 261000\n",
      "Training mini-batch number 262000\n",
      "Training mini-batch number 263000\n",
      "Training mini-batch number 264000\n",
      "Epoch 52: validation accuracy 99.11%\n",
      "Training mini-batch number 265000\n",
      "Training mini-batch number 266000\n",
      "Training mini-batch number 267000\n",
      "Training mini-batch number 268000\n",
      "Training mini-batch number 269000\n",
      "Epoch 53: validation accuracy 99.11%\n",
      "Training mini-batch number 270000\n",
      "Training mini-batch number 271000\n",
      "Training mini-batch number 272000\n",
      "Training mini-batch number 273000\n",
      "Training mini-batch number 274000\n",
      "Epoch 54: validation accuracy 99.11%\n",
      "Training mini-batch number 275000\n",
      "Training mini-batch number 276000\n",
      "Training mini-batch number 277000\n",
      "Training mini-batch number 278000\n",
      "Training mini-batch number 279000\n",
      "Epoch 55: validation accuracy 99.10%\n",
      "Training mini-batch number 280000\n",
      "Training mini-batch number 281000\n",
      "Training mini-batch number 282000\n",
      "Training mini-batch number 283000\n",
      "Training mini-batch number 284000\n",
      "Epoch 56: validation accuracy 99.10%\n",
      "Training mini-batch number 285000\n",
      "Training mini-batch number 286000\n",
      "Training mini-batch number 287000\n",
      "Training mini-batch number 288000\n",
      "Training mini-batch number 289000\n",
      "Epoch 57: validation accuracy 99.10%\n",
      "Training mini-batch number 290000\n",
      "Training mini-batch number 291000\n",
      "Training mini-batch number 292000\n",
      "Training mini-batch number 293000\n",
      "Training mini-batch number 294000\n",
      "Epoch 58: validation accuracy 99.10%\n",
      "Training mini-batch number 295000\n",
      "Training mini-batch number 296000\n",
      "Training mini-batch number 297000\n",
      "Training mini-batch number 298000\n",
      "Training mini-batch number 299000\n",
      "Epoch 59: validation accuracy 99.10%\n",
      "Finished training network.\n",
      "Best validation accuracy of 99.17% obtained at iteration 119999\n",
      "Corresponding test accuracy of 99.21%\n",
      "1 loop, best of 3: 1h 27min 53s per loop\n"
     ]
    }
   ],
   "source": [
    "# add in another fully connected layer\n",
    "net = Network([\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                      filter_shape=(20, 1, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n",
    "                      filter_shape=(40, 20, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        FullyConnectedLayer(n_in=40*4*4, n_out=100, activation_fn=ReLU),\n",
    "        FullyConnectedLayer(n_in=100, n_out=100, activation_fn=ReLU),\n",
    "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "%time net.SGD(expanded_training_data, 60, mini_batch_size, 0.03, validation_data, test_data, lmbda=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 0\n",
      "Training mini-batch number 1000\n",
      "Training mini-batch number 2000\n",
      "Training mini-batch number 3000\n",
      "Training mini-batch number 4000\n",
      "Epoch 0: validation accuracy 96.09%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 95.88%\n",
      "Training mini-batch number 5000\n",
      "Training mini-batch number 6000\n",
      "Training mini-batch number 7000\n",
      "Training mini-batch number 8000\n",
      "Training mini-batch number 9000\n",
      "Epoch 1: validation accuracy 97.64%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.39%\n",
      "Training mini-batch number 10000\n",
      "Training mini-batch number 11000\n",
      "Training mini-batch number 12000\n",
      "Training mini-batch number 13000\n",
      "Training mini-batch number 14000\n",
      "Epoch 2: validation accuracy 98.13%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.04%\n",
      "Training mini-batch number 15000\n",
      "Training mini-batch number 16000\n",
      "Training mini-batch number 17000\n",
      "Training mini-batch number 18000\n",
      "Training mini-batch number 19000\n",
      "Epoch 3: validation accuracy 98.39%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.39%\n",
      "Training mini-batch number 20000\n",
      "Training mini-batch number 21000\n",
      "Training mini-batch number 22000\n",
      "Training mini-batch number 23000\n",
      "Training mini-batch number 24000\n",
      "Epoch 4: validation accuracy 98.58%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.46%\n",
      "Training mini-batch number 25000\n",
      "Training mini-batch number 26000\n",
      "Training mini-batch number 27000\n",
      "Training mini-batch number 28000\n",
      "Training mini-batch number 29000\n",
      "Epoch 5: validation accuracy 98.56%\n",
      "Training mini-batch number 30000\n",
      "Training mini-batch number 31000\n",
      "Training mini-batch number 32000\n",
      "Training mini-batch number 33000\n",
      "Training mini-batch number 34000\n",
      "Epoch 6: validation accuracy 98.73%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.78%\n",
      "Training mini-batch number 35000\n",
      "Training mini-batch number 36000\n",
      "Training mini-batch number 37000\n",
      "Training mini-batch number 38000\n",
      "Training mini-batch number 39000\n",
      "Epoch 7: validation accuracy 98.91%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.03%\n",
      "Training mini-batch number 40000\n",
      "Training mini-batch number 41000\n",
      "Training mini-batch number 42000\n",
      "Training mini-batch number 43000\n",
      "Training mini-batch number 44000\n",
      "Epoch 8: validation accuracy 99.00%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.95%\n",
      "Training mini-batch number 45000\n",
      "Training mini-batch number 46000\n",
      "Training mini-batch number 47000\n",
      "Training mini-batch number 48000\n",
      "Training mini-batch number 49000\n",
      "Epoch 9: validation accuracy 99.04%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.05%\n",
      "Training mini-batch number 50000\n",
      "Training mini-batch number 51000\n",
      "Training mini-batch number 52000\n",
      "Training mini-batch number 53000\n",
      "Training mini-batch number 54000\n",
      "Epoch 10: validation accuracy 99.08%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.15%\n",
      "Training mini-batch number 55000\n",
      "Training mini-batch number 56000\n",
      "Training mini-batch number 57000\n",
      "Training mini-batch number 58000\n",
      "Training mini-batch number 59000\n",
      "Epoch 11: validation accuracy 99.10%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.19%\n",
      "Training mini-batch number 60000\n",
      "Training mini-batch number 61000\n",
      "Training mini-batch number 62000\n",
      "Training mini-batch number 63000\n",
      "Training mini-batch number 64000\n",
      "Epoch 12: validation accuracy 99.17%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.20%\n",
      "Training mini-batch number 65000\n",
      "Training mini-batch number 66000\n",
      "Training mini-batch number 67000\n",
      "Training mini-batch number 68000\n",
      "Training mini-batch number 69000\n",
      "Epoch 13: validation accuracy 99.09%\n",
      "Training mini-batch number 70000\n",
      "Training mini-batch number 71000\n",
      "Training mini-batch number 72000\n",
      "Training mini-batch number 73000\n",
      "Training mini-batch number 74000\n",
      "Epoch 14: validation accuracy 99.07%\n",
      "Training mini-batch number 75000\n",
      "Training mini-batch number 76000\n",
      "Training mini-batch number 77000\n",
      "Training mini-batch number 78000\n",
      "Training mini-batch number 79000\n",
      "Epoch 15: validation accuracy 99.15%\n",
      "Training mini-batch number 80000\n",
      "Training mini-batch number 81000\n",
      "Training mini-batch number 82000\n",
      "Training mini-batch number 83000\n",
      "Training mini-batch number 84000\n",
      "Epoch 16: validation accuracy 99.17%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.30%\n",
      "Training mini-batch number 85000\n",
      "Training mini-batch number 86000\n",
      "Training mini-batch number 87000\n",
      "Training mini-batch number 88000\n",
      "Training mini-batch number 89000\n",
      "Epoch 17: validation accuracy 99.18%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.26%\n",
      "Training mini-batch number 90000\n",
      "Training mini-batch number 91000\n",
      "Training mini-batch number 92000\n",
      "Training mini-batch number 93000\n",
      "Training mini-batch number 94000\n",
      "Epoch 18: validation accuracy 99.15%\n",
      "Training mini-batch number 95000\n",
      "Training mini-batch number 96000\n",
      "Training mini-batch number 97000\n",
      "Training mini-batch number 98000\n",
      "Training mini-batch number 99000\n",
      "Epoch 19: validation accuracy 99.21%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.34%\n",
      "Training mini-batch number 100000\n",
      "Training mini-batch number 101000\n",
      "Training mini-batch number 102000\n",
      "Training mini-batch number 103000\n",
      "Training mini-batch number 104000\n",
      "Epoch 20: validation accuracy 99.17%\n",
      "Training mini-batch number 105000\n",
      "Training mini-batch number 106000\n",
      "Training mini-batch number 107000\n",
      "Training mini-batch number 108000\n",
      "Training mini-batch number 109000\n",
      "Epoch 21: validation accuracy 99.23%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.41%\n",
      "Training mini-batch number 110000\n",
      "Training mini-batch number 111000\n",
      "Training mini-batch number 112000\n",
      "Training mini-batch number 113000\n",
      "Training mini-batch number 114000\n",
      "Epoch 22: validation accuracy 99.21%\n",
      "Training mini-batch number 115000\n",
      "Training mini-batch number 116000\n",
      "Training mini-batch number 117000\n",
      "Training mini-batch number 118000\n",
      "Training mini-batch number 119000\n",
      "Epoch 23: validation accuracy 99.29%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.46%\n",
      "Training mini-batch number 120000\n",
      "Training mini-batch number 121000\n",
      "Training mini-batch number 122000\n",
      "Training mini-batch number 123000\n",
      "Training mini-batch number 124000\n",
      "Epoch 24: validation accuracy 99.21%\n",
      "Training mini-batch number 125000\n",
      "Training mini-batch number 126000\n",
      "Training mini-batch number 127000\n",
      "Training mini-batch number 128000\n",
      "Training mini-batch number 129000\n",
      "Epoch 25: validation accuracy 99.30%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.45%\n",
      "Training mini-batch number 130000\n",
      "Training mini-batch number 131000\n",
      "Training mini-batch number 132000\n",
      "Training mini-batch number 133000\n",
      "Training mini-batch number 134000\n",
      "Epoch 26: validation accuracy 99.28%\n",
      "Training mini-batch number 135000\n",
      "Training mini-batch number 136000\n",
      "Training mini-batch number 137000\n",
      "Training mini-batch number 138000\n",
      "Training mini-batch number 139000\n",
      "Epoch 27: validation accuracy 99.31%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.50%\n",
      "Training mini-batch number 140000\n",
      "Training mini-batch number 141000\n",
      "Training mini-batch number 142000\n",
      "Training mini-batch number 143000\n",
      "Training mini-batch number 144000\n",
      "Epoch 28: validation accuracy 99.23%\n",
      "Training mini-batch number 145000\n",
      "Training mini-batch number 146000\n",
      "Training mini-batch number 147000\n",
      "Training mini-batch number 148000\n",
      "Training mini-batch number 149000\n",
      "Epoch 29: validation accuracy 99.31%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.37%\n",
      "Training mini-batch number 150000\n",
      "Training mini-batch number 151000\n",
      "Training mini-batch number 152000\n",
      "Training mini-batch number 153000\n",
      "Training mini-batch number 154000\n",
      "Epoch 30: validation accuracy 99.33%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.40%\n",
      "Training mini-batch number 155000\n",
      "Training mini-batch number 156000\n",
      "Training mini-batch number 157000\n",
      "Training mini-batch number 158000\n",
      "Training mini-batch number 159000\n",
      "Epoch 31: validation accuracy 99.35%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.49%\n",
      "Training mini-batch number 160000\n",
      "Training mini-batch number 161000\n",
      "Training mini-batch number 162000\n",
      "Training mini-batch number 163000\n",
      "Training mini-batch number 164000\n",
      "Epoch 32: validation accuracy 99.34%\n",
      "Training mini-batch number 165000\n",
      "Training mini-batch number 166000\n",
      "Training mini-batch number 167000\n",
      "Training mini-batch number 168000\n",
      "Training mini-batch number 169000\n",
      "Epoch 33: validation accuracy 99.32%\n",
      "Training mini-batch number 170000\n",
      "Training mini-batch number 171000\n",
      "Training mini-batch number 172000\n",
      "Training mini-batch number 173000\n",
      "Training mini-batch number 174000\n",
      "Epoch 34: validation accuracy 99.33%\n",
      "Training mini-batch number 175000\n",
      "Training mini-batch number 176000\n",
      "Training mini-batch number 177000\n",
      "Training mini-batch number 178000\n",
      "Training mini-batch number 179000\n",
      "Epoch 35: validation accuracy 99.20%\n",
      "Training mini-batch number 180000\n",
      "Training mini-batch number 181000\n",
      "Training mini-batch number 182000\n",
      "Training mini-batch number 183000\n",
      "Training mini-batch number 184000\n",
      "Epoch 36: validation accuracy 99.34%\n",
      "Training mini-batch number 185000\n",
      "Training mini-batch number 186000\n",
      "Training mini-batch number 187000\n",
      "Training mini-batch number 188000\n",
      "Training mini-batch number 189000\n",
      "Epoch 37: validation accuracy 99.37%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.43%\n",
      "Training mini-batch number 190000\n",
      "Training mini-batch number 191000\n",
      "Training mini-batch number 192000\n",
      "Training mini-batch number 193000\n",
      "Training mini-batch number 194000\n",
      "Epoch 38: validation accuracy 99.31%\n",
      "Training mini-batch number 195000\n",
      "Training mini-batch number 196000\n",
      "Training mini-batch number 197000\n",
      "Training mini-batch number 198000\n",
      "Training mini-batch number 199000\n",
      "Epoch 39: validation accuracy 99.37%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.50%\n",
      "Finished training network.\n",
      "Best validation accuracy of 99.37% obtained at iteration 199999\n",
      "Corresponding test accuracy of 99.50%\n",
      "CPU times: user 3d 6h 7min 13s, sys: 3h 30min 16s, total: 3d 9h 37min 29s\n",
      "Wall time: 1h 8min 18s\n"
     ]
    }
   ],
   "source": [
    "# apply dropout to avoid overfitting\n",
    "net = Network([\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                      filter_shape=(20, 1, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n",
    "                      filter_shape=(40, 20, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        FullyConnectedLayer(\n",
    "            n_in=40*4*4, n_out=1000, activation_fn=ReLU, p_dropout=0.5),\n",
    "        FullyConnectedLayer(\n",
    "            n_in=1000, n_out=1000, activation_fn=ReLU, p_dropout=0.5),\n",
    "        SoftmaxLayer(n_in=1000, n_out=10, p_dropout=0.5)], \n",
    "    mini_batch_size)\n",
    "%time net.SGD(expanded_training_data, 40, mini_batch_size, 0.03, validation_data, test_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
